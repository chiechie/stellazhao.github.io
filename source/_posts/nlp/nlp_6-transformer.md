---
title: è‡ªç„¶è¯­è¨€å¤„ç†6 Transformer
author: chiechie
mathjax: true
date: 2021-04-25 00:04:13
tags: 
- NLP
- ç¥ç»ç½‘ç»œ
- æ¨¡å‹å¯è§†åŒ–
- Transformer
- Bert
- attention
categories: 
- NLP
---


# Transformeræ€»ç»“

- Transformeræ˜¯google2016å¹´åœ¨ã€Šattention is all you needã€‹æå‡ºçš„ä¸€ä¸ªæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„seq2seqæ¶æ„ã€‚
- Transformerçš„äº®ç‚¹åœ¨äºå°†attentionå’Œself-attentionå®Œå…¨å‰¥ç¦»å¼€ä¹‹å‰rnnçš„ç»“æ„ï¼Œåªè·Ÿdenseå±‚ç»„åˆã€‚
- Transformerè·ŸRNNæ²¡æœ‰å…³ç³», åªæœ‰attentionå’Œå…¨è¿æ¥å±‚
- Transformeræ¯”æ‰€æœ‰çš„rnn+attentionæ•ˆæœéƒ½è¦å¥½ï¼Œæœºå™¨ç¿»è¯‘çš„ç‹è€…
- Transformeræ˜¯ä¸€ä¸ªç¿»è¯‘æ¨¡å‹ï¼Œåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œegå¾·è¯‘è‹±ï¼Œè¾“å…¥ä¸€ä¸ªå¾·æ–‡å¥å­ï¼Œè¾“å‡ºåä¸€å¥è‹±æ–‡ã€‚
- Transformerç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šencoderså’Œdecoders
- encodersç”±6ä¸ªencoderå †å è€Œæˆï¼Œdecodersç”±6ä¸ªdecoderå †å è€Œæˆï¼Œä¸€ä¸ªencoderæˆ–ä¸€ä¸ªdecoderå«åšä¸€ä¸ªblockã€‚
- encodersçš„æ¯ä¸ªblockæœ‰2å±‚ï¼šself-attentionå’Œdenseï¼Œæ¯ä¸ªblockç»“æ„ç›¸åŒï¼Œä½†ä¸å…±äº«æƒé‡ã€‚
- decodersçš„æ¯ä¸ªblockæœ‰3å±‚ï¼šself-attentionï¼Œattentionå’Œdenseï¼Œå…¶ä¸­attentonç”¨æ¥å…³æ³¨encoderçš„è¾“å‡ºï¼Œ
- attentionæŠ€æœ¯çš„æ¼”è¿›ï¼šattention + åŸºäºrnnçš„seq2seq --> self-attention + lstm --> attention/self attention + dense.
- "å¤šå¤´"æ³¨æ„æœºåˆ¶æ‰©å±•äº†æ¨¡å‹å…³æ³¨ä¸åŒä½ç½®çš„èƒ½åŠ›, ç»™äºˆattentionå±‚å¤šä¸ª"è¡¨ç¤ºå­ç©ºé—´", æ¯ä¸ªå¤´æœ‰è‡ªå·±çš„ä¸€ç»„query / key / value æƒé‡çŸ©é˜µï¼Œå½“äºå®¡è§†å¤šæ¬¡ä¸Šä¸‹æ–‡ï¼Œ

# é™„å½•

## è¾“å…¥å’Œä½ç½®ç¼–ç 

1. å’Œä¸€èˆ¬çš„NLPä»»åŠ¡ä¸€æ ·ï¼Œç”¨embedding algorithmå°†æ¯ä¸ªè¾“å…¥å•è¯è½¬åŒ–ä¸ºè¯å‘é‡ä¹‹åï¼Œæ‰èƒ½ä½œä¸ºTransformerçš„è¾“å…¥ä½¿ç”¨ã€‚
2. å¦‚ä¸‹å›¾ï¼Œ3ä¸ªå•è¯è¢«embeddedä¸º3ä¸ª512ç»´çš„å‘é‡
![](./transformer_embeddings.png) 
3. æ¥ä¸‹æ¥ï¼Œå°†è¿™3ä¸ª512ç»´çš„è¯å‘é‡ä¼ å…¥self-attentionå’Œdenseå±‚
![](./transformer_encoder_with_tensors.png)
4. ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰è¡¨ç¤ºåºåˆ—çš„é¡ºåº, ä¸ºäº†è®©æ¨¡å‹å­¦ä¹ åˆ°è¯çš„é¡ºåºå…³ç³»ï¼Œtransformerå‘æ¯ä¸ªè¾“å…¥embeddingå‘é‡ï¼ˆx1ï¼‰åˆåŠ ä¸Šä¸€ä¸ªä½ç½®ç¼–ç å‘é‡ï¼ˆt1ï¼‰ã€‚
![img](./transformer_positional_encoding_vectors.png)
5. å‡è®¾embeddingçš„ç»´åº¦æ˜¯4ï¼Œé‚£ä¹ˆå®é™…çš„ä½ç½®ç¼–ç çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„:
![img](./transformer_positional_encoding_example.png)


## å¤šå¤´self attention

1. æ¯ä¸ªå•å¤´self-attentionå±‚æœ‰ä¸‰ä¸ªå‚æ•°çŸ©é˜µï¼Œå•å¤´çš„context vectoræ˜¯ä¸€ä¸ªd * mç»´çš„çŸ©é˜µ
![å•å¤´self-attention](./img_6.png)
2. å¤šå¤´attentionå±‚å°±æœ‰3*lä¸ªå‚æ•°çŸ©é˜µï¼ˆlä»£è¡¨å¤´çš„ä¸ªæ•°ï¼‰ï¼Œå¤šå¤´çš„context vectoræ˜¯ä¸€ä¸ª(dl) *mç»´çš„çŸ©é˜µ
  ![å¤šå¤´self-attention](./img_7.png)
   ![img](./transformer_attention_heads_qkv.png)
3. ç±»ä¼¼ä¸Šé¢æåˆ°çš„å•å¤´self-attentionè®¡ç®—ï¼Œæˆ‘ä»¬ç°åœ¨åªæ˜¯ç”¨8ä¸ªä¸åŒçš„æƒé‡çŸ©é˜µç®—äº†8æ¬¡ï¼Œå¹¶ä¸”å¾—åˆ°äº†8ä¸ªä¸åŒçš„ z çŸ©é˜µ
![img](./transformer_attention_heads_z.png)
3. å½“è§£è¯»ä¸€ä¸ªå¥å­ä¸­çš„ä¸€ä¸ªwordæ—¶ï¼Œ Transformeä¸­çš„encoderé€šè¿‡self-attentionæ¥å›é¡¾ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ‰¾å‡ºè¾“å…¥åºåˆ—ä¸­çš„é‡è¦çš„wordï¼Œä»è€Œæ›´å…³æ³¨é‡è¦ä¿¡æ¯ï¼Œå¹¶ä¸”ä¼šæŠŠé‡è¦wordçš„value vectorç¼–ç åˆ°è‡ªå·±çš„å‘é‡é‡Œé¢å»ã€‚
RNNé€šè¿‡hidden stateç­–ç•¥ï¼Œä½¿å¾—å®ƒå°†å½“å‰è¯ä¸ä¸Šä¸‹æ–‡ï¼ˆå‡†ç¡®æ¥è¯´åªæœ‰ä¸Šæ–‡ï¼‰çš„ä¿¡æ¯è¿›è¡Œèåˆã€‚
4. self-attentionçš„è¾“å…¥æ˜¯mä¸ªè¯å‘é‡ï¼Œè¾“å‡ºæ˜¯mä¸ªcontext vectorï¼Œvectorè¡¨ç¤ºèåˆäº†ä¸Šä¸‹æ–‡ä¹‹åï¼Œå¯¹wordå†æ¬¡ç¼–ç ã€‚
![img_2.png](./img_2.png)
![img_3.png](./img_3.png)
5. å¦‚ä½•å®ç°self-attention layerï¼Ÿå³å¦‚ä½•å®ç°è®¡ç®—context vectorï¼Ÿ
- step1: å¯¹äºæ¯ä¸ªè¾“å…¥çš„wordçš„æ­¤å‘é‡åˆ†åˆ«è®¡ç®—3ä¸ªè¡¨ç¤ºå‘é‡ï¼š
  - Query vectorï¼š $q_i$, to match othersï¼›
  - Key vectorï¼š$k_i$, to be matchedï¼›
  - Value vectorï¼š$v_i$ to be weighted averaged ã€‚
  - è¿™äº›å‘é‡æ˜¯é€šè¿‡å°†è¾“å…¥çš„è¯å‘é‡åšä¸‰æ¬¡çº¿æ€§å˜æ¢å¾—åˆ°çš„ï¼Œå½“ç„¶å¯¹åº”çš„ä¸‰ä¸ªçŸ©é˜µæ˜¯éœ€è¦å­¦ä¹ çš„ã€‚
  - è¯·æ³¨æ„ï¼Œå¾—åˆ°çš„æ–°å‘é‡çš„ç»´åº¦ï¼ˆ64ï¼‰æ¯”embeddingï¼ˆ512ï¼‰å°ã€‚è¿™ä¹ˆè®¾è®¡ä¸ºäº†ä¿è¯ï¼ŒåŠ å…¥å¤šå¤´self-attentionä¹‹åï¼Œencoderçš„è¾“å‡ºå’Œè¾“å…¥ç»´åº¦ï¼ˆ512ï¼‰è¿˜èƒ½ä¿æŒä¸€è‡´ã€‚
   > 8å¤´ * 64 = 512
- step2: è®¡ç®—æƒé‡åˆ†æ•°, ç›®çš„æ˜¯é‡åŒ–å…¶ä»–å•è¯åº”è¯¥è¢«å…³æ³¨çš„ç¨‹åº¦ã€‚
   - è®¡ç®—å½“å‰å•è¯çš„query vectorå’Œå…¶ä»–å•è¯çš„key vectorçš„å†…ç§¯
- step3: æƒé‡åˆ†æ•°å½’ä¸€åŒ–ã€‚å°†ä¸Šä¸€æ­¥ç®—å‡ºæ¥çš„æƒé‡å¾—åˆ†å‘é‡ï¼ˆé•¿åº¦ä¸ºmï¼‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œç›®çš„æ˜¯è®©æƒé‡ä¸è¦å—åˆ°key vectorçš„é•¿åº¦ï¼ˆpaperé‡Œé¢æ˜¯64ï¼‰çš„å½±å“ï¼Œè¿™æ ·ç®—æ¢¯åº¦å°±æ›´ç¨³å®šã€‚
- step4ï¼šå°†å½’ä¸€åŒ–çš„æƒé‡å¾—åˆ†å‘é‡ï¼ˆé•¿åº¦ä¸ºmï¼‰é€å…¥softmaxï¼Œç›®çš„æ˜¯å¾—åˆ°ä¸€ä¸ªæ¦‚ç‡å‘é‡ï¼Œæ‰€æœ‰æ•°å€¼åŠ èµ·æ¥ä¸º1ã€‚ç¤ºæ¯ä¸ªå•è¯åº”è¯¥è¢«å½“å‰å•è¯å…³æ³¨çš„ç¨‹åº¦ï¼Œå€¼è¶Šå¤§è¶Šåº”è¯¥è¢«å…³æ³¨ã€‚ã€‚
- step5ï¼šè®¡ç®—contect vectorã€‚å°†æ¯ä¸ªå•è¯çš„value vectorä½¿ç”¨æƒé‡æ¦‚ç‡å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œä½œä¸ºå½“å‰å•è¯çš„self-attentionè¡¨è¾¾ï¼ˆè¾“å‡ºé•¿åº¦ä¸º64 * 8ä¸ªå¤´ = 512ï¼‰ã€‚
6. æŠŠåˆšåˆšçš„è¿‡ç¨‹å†åŠ å…¥ä¸€ä¸ªç»´åº¦ï¼Œä¹Ÿå°±æ˜¯ä»ä¸€ä¸ªå•è¯ å˜æˆ å¤šä¸ªå•è¯ï¼Œè®¡ç®—ä»–ä»¬å„è‡ªçš„self-attentionè¡¨ç¤ºï¼Œç”¨çŸ©é˜µè¡¨è¾¾è¯¥è®¡ç®—æµç¨‹ï¼š
- ç¬¬ä¸€æ­¥æ˜¯è®¡ç®— Queryã€ Key å’Œ Value çŸ©é˜µï¼š
   - æˆ‘ä»¬å°†embeddingså¡åˆ°ä¸€ä¸ªçŸ©é˜µxï¼šè¡Œæ•°è¡¨ç¤ºå•è¯ä¸ªæ•°ï¼Œåˆ—è¡¨ç¤ºembeddingçš„é•¿åº¦
   - æƒé‡çŸ©é˜µ(WQã€ WKã€ WVï¼‰ï¼šè¡Œä»£è¡¨embeddingå‘é‡çš„é•¿åº¦ï¼Œåˆ—åˆ†åˆ«ä»£è¡¨queryç©ºé—´ï¼Œkeyç©ºé—´ï¼Œvalueç©ºé—´çš„ç»´åº¦
   - Xåˆ†åˆ«å’Œè¿™å‡ ä¸ªçŸ©é˜µç›¸ä¹˜
   ![](./transformer_self-attention-matrix-calculation.png)
- ç¬¬äºŒæ­¥ï¼Œåˆ©ç”¨ç¬¬ä¸€æ­¥çš„ç»“æœæ¥è®¡ç®—attentionçš„è¾“å‡ºï¼Œç”¨ä¸€ä¸ªçŸ©é˜µè®¡ç®—æ¥è¡¨è¾¾ï¼Œç®€æ´ä¼˜é›…
   ![](./transformer_self-attention-matrix-calculation-2.png) 



## denseå±‚

1. åé¢æ€ä¹ˆè·Ÿdenseå±‚è¿›è¡Œè¡”æ¥å‘¢ï¼Ÿ1. å°†è¿™8ä¸ªzçŸ©é˜µè¿›è¡Œåˆ—æ‹¼æ¥ï¼ˆconcatï¼‰ï¼›2. æ‹¼æ¥åçš„çŸ©é˜µå¤§å°ä¸ºm*(8*64) = m *512ï¼Œä¸¢å…¥denseå±‚
![img](./transformer_attention_heads_weight_matrix_o.png)
2. è¿™å°±æ˜¯multi-headed self-attentionçš„å¤§éƒ¨åˆ†å†…å®¹ã€‚æŠŠæ•´ä¸ªè¿‡ç¨‹æ”¾åœ¨ä¸€ä¸ªå›¾ä¸­æè¿°ï¼š
![img](./transformer_multi-headed_self-attention-recap.png)




## encoder block = å¤šå¤´self-attention + dense layer
1. encoder block â‰ˆ å¤šå¤´self-attention + denseã€‚encoder blockçš„è¾“å…¥ç»´åº¦æ˜¯512Ã—ğ‘šï¼Œè¾“å‡ºç»´åº¦æ˜¯512Ã—ğ‘š.
2. ä»¥ä¸€ä¸ªçŸ­å¥ä¸ºä¾‹,çœ‹çœ‹encoderçš„å¤„ç†æµç¨‹:
   1. å°†[x1ï¼Œ...,xm]è¾“å…¥å¤šå¤´self-attentionå±‚, å¾—åˆ°mä¸ªcontext vector
   2. å°†mä¸ªcontext vectorè¾“å…¥dense + reluï¼Œå¾—åˆ°mä¸ªé‡æ–°ç¼–ç åçš„å‘é‡[u1,...,um]ï¼Œdenseå±‚å¯¹mä¸ªwordç”Ÿæ•ˆã€‚
   3. å°†[u1,...,um]ä¼ é€’ç»™ä¸‹ä¸€ä¸ªç¼–ç å™¨encoder2ä½œä¸ºè¾“å…¥ã€‚
      ![img_9.png](./img_9.png)
      ![img_10.png](./img_10.png)


## æ®‹å·®è¿æ¥å’Œlayer-normalization

1. æ¯ä¸ªencoder blockä¸­ï¼Œself-attentionå’Œdenseéƒ½æœ‰ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œç„¶åæ¥ä¸€ä¸ªå±‚æ ‡å‡†åŒ–ï¼ˆlayer-normalizationï¼‰ã€‚
![img](./transformer_resideual_layer_norm.png)
2. å¦‚æœæˆ‘ä»¬å°†æ®‹å·®è¿æ¥å’Œlayer normalizationç”¨çŸ©é˜µè¡¨ç¤ºï¼Œå°±æ˜¯ä¸‹å›¾ï¼š
![img](./transformer_resideual_layer_norm_2.png)
3. decoderçš„sub-layers ä¹ŸåŒæ ·ç”¨åˆ°äº†add & normalizationçš„è®¾è®¡ã€‚
ä¸‹å›¾æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆçš„Transformeræ¶æ„ï¼šç”±2ä¸ªstacked encoderå’Œ2ä¸ªstacked decoderç»„æˆã€‚
![img](./transformer_resideual_layer_norm_3.png)
4. æ›´å‡†ç¡®æ¥è¯´ encoder block = positional codeing + å¤šå¤´self-attention + add & normalizatioin + dense layer + add & normalizatioin


## encoder network = 6 * encoder block 

encoder network is a stack of 6 encoder blocks.

![img_11.png](./img_11.png)


## å¤šå¤´attention

1. å•å¤´attentionå±‚ï¼Œè¦è®¡ç®—3ä¸ªå‘é‡ï¼Œå…ˆè®¡ç®—qè·Ÿæ¯ä¸ªkçš„ç›¸å…³æ€§ï¼ˆæ±‚å†…ç§¯ï¼‰ï¼Œç„¶ååšsoftmaxå˜æ¢å¾—åˆ°æƒé‡å¾—åˆ†ï¼Œå¯¹æ‰€æœ‰çš„vä½¿ç”¨è¯¥æƒé‡æ±‚å’Œï¼Œå¾—åˆ°decoderçš„è¿™ä¸ªè¯ç›¸å¯¹encoderçš„è¡¨ç¤ºï¼Œä¹Ÿå°±æ˜¯context vectorã€‚
![å•å¤´atttion](./img.png)
2. decoderä¸­çš„attentionï¼Œqæ¥è‡ªä¸¤éƒ¨åˆ†ï¼šä¸‹é¢çš„decoderçš„è¾“å‡ºå’Œæœ€ä¸Šé¢encoderä¸­çš„KeysçŸ©é˜µå’ŒValuesçŸ©é˜µ ã€‚
   ![img_17.png](img_17.png)
   ![img_18.png](img_18.png)
1. Attention å±‚çš„Queries 

![img_1.png](./img_1.png)
![img_5.png](./img_5.png)   
![img_8.png](./img_8.png)


## decoder block = å¤šå¤´self-attention +  å¤šå¤´attention +  dense layer

![img_13.png](./img_13.png)
1. 1ä¸ªdecoder block â‰ˆ å¤šå¤´self-attention + å¤šå¤´attention + denseã€‚decoder blockçš„è¾“å…¥æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯encoderçš„è¾“å‡ºï¼ˆ512Ã—mï¼‰ï¼Œ ä¸€ä¸ªæ¥è‡ªdecoderå½“å‰çš„çš„è¾“å‡ºï¼ˆ512Ã—t ï¼‰.
2. encodingé˜¶æ®µï¼ˆphaseï¼‰å®Œæˆåï¼Œæˆ‘ä»¬å¼€å§‹decodingé˜¶æ®µï¼Œdecodingçš„æ¯ä¸ªstepæè¿°å¦‚ä¸‹ï¼š
    ![img](./transformer_decoding_1.gif)
   ![img](./transformer_decoding_2.png)
    1. æ¯ä¸ªæ—¶åˆ»ï¼Œè¾“å…¥ç¬¬6ä¸ªencoderäº§ç”Ÿçš„mä¸ªkeys vectorså’Œvalue vectorsï¼Œè¾“å‡ºä¸€ä¸ªelementçš„æ¦‚ç‡åˆ†å¸ƒpdfã€‚
    2. ä»pdfä¸­æŠ½æ ·å‡ºwordï¼ˆæˆ–è€…ç›´æ¥é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„wordï¼‰ï¼Œä½œä¸ºdecoderçš„è¾“å…¥ã€‚
    3. é‡å¤step1ï¼Œç›´åˆ°äº§ç”Ÿç»“æŸç¬¦ã€‚
3. decoderä¹Ÿä¼šç”¨åˆ°ä½ç½®ç¼–ç .
4. decoderä¸­çš„self attention layers:ä¸encoderçš„è¿ä½œæ–¹å¼ç•¥æœ‰ä¸åŒ,åœ¨decoderä¸­ï¼Œself-attention layeråªèƒ½æ¥è§¦åˆ°è¾“å‡ºåºåˆ—ä¸­çš„å‰åŠéƒ¨åˆ†ã€‚æ€ä¹ˆåšåˆ°å‘¢ï¼Ÿåœ¨softmaxæ“ä½œä¹‹å‰ï¼Œmaskingåºåˆ—ååŠéƒ¨åˆ†(è®¾ä¸º -inf)


## decoder network = 6 * decoder block 

1. Decoder network is a stack of 6 decoder blocks.

    ![](./img_12.png)
    ![](./Transformer_decoder.png)
2. stack decodersè¾“å‡ºä¸€ä¸ªæ•°å€¼å‘é‡ã€‚ æˆ‘ä»¬æ€ä¹ˆæŠŠå®ƒå˜æˆä¸€ä¸ªè¯å‘¢ï¼Ÿ è¿™æ˜¯æœ€åçš„denseå±‚+softmaxåœ¨åšçš„äº‹æƒ…ã€‚å®ƒå°†stack of decodersçš„è¾“å‡ºæ˜ å°„ä¸ºä¸€ä¸ªæƒé‡å‘é‡ã€‚ï¼ˆé•¿åº¦å°±æ˜¯è¾“å‡ºè¯æ±‡è¡¨çš„å¤§å°ï¼‰
3. è¿™ä¸ªå›¾ä»åº•éƒ¨å¼€å§‹ï¼Œç”Ÿæˆä¸€ä¸ªvectorä½œä¸ºdecoder stackçš„è¾“å‡ºã€‚ ç„¶åå®ƒè¢«è½¬æ¢æˆä¸€ä¸ªè¾“å‡ºå•è¯ã€‚
![img](./transformer_decoder_output_softmax.gif) 


## Transformer = encoder network+ decoder network

![img_14.png](./img_14.png)
![img_15.png](./img_15.png)
![Transformer=encoders+decoders](./transformer_encoders_decoders.png)
![](./transformer_encoder_decoder_stack.png)


## è®­ç»ƒ

å­¦ä¹ çš„ç›®æ ‡ï¼Ÿ å°†æ¨¡å‹è¾“å‡ºä¸ç›®æ ‡è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œç„¶åä½¿ç”¨åå‘ä¼ æ’­æ–¹æ³•è°ƒæ•´æ¨¡å‹çš„æƒé‡ï¼Œä½¿æ¨¡å‹è¾“å‡ºæ›´æ¥è¿‘ç›®æ ‡è¾“å‡ºã€‚

å¦‚ä½•æ¯”è¾ƒä¸¤ç§æ¦‚ç‡åˆ†å¸ƒï¼Ÿ å¯æŸ¥çœ‹ [cross-entropy](https://colah.github.io/posts/2015-09-Visual-Information/)å’Œ [Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained). ã€‚

ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒï¼š

![img](./output_target_probability_distributions.png)

æ¨¡å‹è¾“å‡ºï¼š

![img](./transformer_output_trained_model_probability_distributions.png)


## åº”ç”¨çš„ä¸€ä¸ªä¾‹å­

![img_20.png](img_20.png)

# å‚è€ƒ

1. Bahdanau, Cho, & Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.
2. Cheng, Dong, & Lapata. Long Short-Term Memory-Networks for Machine Reading. In EMNLP, 2016.
3. Vaswani et al. Attention Is All You Need. In NIPS, 2017.
4. [Transformeræ¨¡å‹(2/2): ä»Attentionå±‚åˆ°Transformerç½‘ç»œ](https://www.youtube.com/watch?v=aJRsr39F4dI)