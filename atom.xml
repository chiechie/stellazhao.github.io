<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chiechie&#39;s Mini World</title>
  
  <subtitle>Set your course by the stars, not by the lights of passing ships. —— Omar Bradley</subtitle>
  <link href="https://chiechie.github.io/atom.xml" rel="self"/>
  
  <link href="https://chiechie.github.io/"/>
  <updated>2021-07-26T15:25:30.501Z</updated>
  <id>https://chiechie.github.io/</id>
  
  <author>
    <name>Chiechie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于tensorflow构建时间序列模型</title>
    <link href="https://chiechie.github.io/2021/07/26/probability-tensorflow/"/>
    <id>https://chiechie.github.io/2021/07/26/probability-tensorflow/</id>
    <published>2021-07-26T14:10:33.000Z</published>
    <updated>2021-07-26T15:25:30.501Z</updated>
    
    <content type="html"><![CDATA[<p>下面介绍一种基于tensorflow的概率编程框架TensorFlow Probability，可用于对时间序列构建概率模型。</p><ol type="1"><li><p>2018年谷歌在tf开发者峰会上，宣布了新工具--tensorFlow Probability，用于构建贝叶斯模型，可分布式部署，对于大规模的时间序列的场景优势明显。</p></li><li><p>贝叶斯概率模型虽然在tfp中被看作一种新的建模范式，依然遵循经典的时序模型建模原理，如时序的季节性，增长趋势。</p></li><li><p>从整体上看看TensorFlow Probability主要包含：分布、模型构建层/损失函数、马尔可夫概率推断、优化。通过 Bijectors 和 TransformedDistribution计算复杂的分布，使用tfp.mcmc，tfp.vi进行概率推断。建模部分正主要分为以下步骤：</p><ul><li>build_mode:将训练数据输入-输出映射；</li><li>fit_model， 使用变分推断拟合模型，抽样计算参数后验分布；</li><li>得到模型预测值；</li><li>evaluate：计算模型评估指标MAPE；</li></ul><figure><img src="./image-20190621104830343.png" alt="image-20190621104830343" /><figcaption aria-hidden="true">image-20190621104830343</figcaption></figure></li><li><p>贝叶斯模型的特点是，引入先验信息，通过概率描述不确定；概率编程则是利用计算机采样的方法进行贝叶斯推断（Bayesian inference），得出未知参数的概率分布，也就是利用贝叶斯公式给定观测数据和先验分布计算参数的后验概率，公式如下： <span class="math display">\[p(\theta \mid X)=\frac{p(\theta) p((X \mid \theta)}{p(X)}\]</span></p></li><li><p>由于后验分布精确求解非常困难，所以使用变分推断（variational inference）算近似分布，将计算后验分布转化最小化ELBO（negative evidence lower bound），得到变分的参数。</p></li><li><p>输出模型参数有</p></li></ol><ul><li>observation_noise_scale： 噪声</li><li>LocalLinearTrend/level_scale：局部线性截距</li><li>LocalLinearTrend/slope_scale：局部线性趋势的斜率</li><li>Seasonal/_drift_scale：季节性</li></ul><h2 id="附录">附录</h2><p>程序运算步骤主要为：用正态分布作为先验分布，使用negative evidence lower bound作为损失函数，通过tfp.sts计算后验。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#本文为使用tensorflow概率建模</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pylab <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_probability <span class="keyword">as</span> tfp</span><br><span class="line"><span class="keyword">from</span> tensorflow_probability <span class="keyword">import</span> distributions <span class="keyword">as</span> tfd</span><br><span class="line"><span class="keyword">from</span> tensorflow_probability <span class="keyword">import</span> sts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制预测与真实值时间序列图</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_forecast</span>(<span class="params">x, y,</span></span></span><br><span class="line"><span class="function"><span class="params">                  forecast_mean, forecast_scale, forecast_samples,</span></span></span><br><span class="line"><span class="function"><span class="params">                  title, x_locator=<span class="literal">None</span>, x_formatter=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Plot a forecast distribution against the &#x27;true&#x27; time series.&quot;&quot;&quot;</span></span><br><span class="line">    colors = sns.color_palette()</span><br><span class="line">    c1, c2 = colors[<span class="number">0</span>], colors[<span class="number">1</span>]</span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">    ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    num_steps = <span class="built_in">len</span>(y)</span><br><span class="line">    num_steps_forecast = forecast_mean.shape[-<span class="number">1</span>]</span><br><span class="line">    num_steps_train = num_steps - num_steps_forecast</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ax.plot(x, y, lw=<span class="number">2</span>, color=c1, label=<span class="string">&#x27;ground truth&#x27;</span>)</span><br><span class="line">    forecast_steps = np.arange(</span><br><span class="line">      x[num_steps_train],</span><br><span class="line">      x[num_steps_train]+num_steps_forecast,</span><br><span class="line">      dtype=x.dtype)</span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    ax.plot(forecast_steps, forecast_samples.T, lw=<span class="number">1</span>, color=c2, alpha=<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment">#绘制预测期望值以及针对最后三个月的100个采样结果</span></span><br><span class="line">    ax.plot(forecast_steps, forecast_mean, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">           label=<span class="string">&#x27;forecast&#x27;</span>)</span><br><span class="line">    ax.fill_between(forecast_steps,</span><br><span class="line">                   forecast_mean-<span class="number">2</span>*forecast_scale,</span><br><span class="line">                   forecast_mean+<span class="number">2</span>*forecast_scale, color=c2, alpha=<span class="number">0.2</span>)</span><br><span class="line">    </span><br><span class="line">    ymin, ymax = <span class="built_in">min</span>(np.<span class="built_in">min</span>(forecast_samples), np.<span class="built_in">min</span>(y)), <span class="built_in">max</span>(np.<span class="built_in">max</span>(forecast_samples), np.<span class="built_in">max</span>(y))</span><br><span class="line">    yrange = ymax-ymin</span><br><span class="line">    ax.set_ylim([ymin - yrange*<span class="number">0.1</span>, ymax + yrange*<span class="number">0.1</span>])</span><br><span class="line">    ax.set_title(<span class="string">&quot;&#123;&#125;&quot;</span>.<span class="built_in">format</span>(title))</span><br><span class="line">    ax.legend()</span><br><span class="line">     </span><br><span class="line">    <span class="keyword">if</span> x_locator <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        ax.xaxis.set_major_locator(x_locator)</span><br><span class="line">        ax.xaxis.set_major_formatter(x_formatter)</span><br><span class="line">        fig.autofmt_xdate()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> fig, ax</span><br><span class="line"></span><br><span class="line"><span class="comment">#建构模型，并计算计算损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_loss</span>(<span class="params">training_data</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置全局默认图形</span></span><br><span class="line">    tf.reset_default_graph()</span><br><span class="line">    <span class="comment">#遵循加法模型，设置趋势</span></span><br><span class="line">    trend = sts.LocalLinearTrend(observed_time_series=observed_time_series)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置季节性</span></span><br><span class="line">    seasonal = tfp.sts.Seasonal(</span><br><span class="line">          num_seasons=<span class="number">12</span>, observed_time_series=observed_time_series)</span><br><span class="line">    <span class="comment">#模型拟合,之所以用sum，而不是我们在建模中常见的fit定义，是因为，</span></span><br><span class="line">    <span class="comment">#模型时间序列为加法模型，有如上文提到的趋势，季节性，周期性等成分相加</span></span><br><span class="line">    <span class="comment">#默认的先验分布为正态（normal）</span></span><br><span class="line">    ts_model = sts.Sum([trend, seasonal], observed_time_series=observed_time_series)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#构建变分损失函数和后验</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">&#x27;sts_elbo&#x27;</span>, reuse=tf.AUTO_REUSE):</span><br><span class="line">        elbo_loss, variational_posteriors = tfp.sts.build_factored_variational_loss(</span><br><span class="line">          ts_model,observed_time_series=training_data)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ts_model,elbo_loss,variational_posteriors</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#模型训练，输出后验分布</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">training_data</span>):</span></span><br><span class="line">    </span><br><span class="line">    ts_model,elbo_loss,variational_posteriors=cal_loss(training_data)</span><br><span class="line">    num_variational_steps = <span class="number">401</span> </span><br><span class="line">    num_variational_steps = <span class="built_in">int</span>(num_variational_steps)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#训练模型，ELBO作为在变分推断的损失函数</span></span><br><span class="line">    train_vi = tf.train.AdamOptimizer(<span class="number">0.1</span>).minimize(elbo_loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#创建会话,并通过上下文管理器方式对张量Tensor对象进行计算</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        sess.run(tf.global_variables_initializer())</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_variational_steps):</span><br><span class="line">            _, elbo_ = sess.run((train_vi, elbo_loss))</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">&quot;step &#123;&#125; -ELBO &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, elbo_))</span><br><span class="line">        <span class="comment">#求解后验参数</span></span><br><span class="line">        q_samples_ = sess.run(&#123;k: q.sample(<span class="number">3</span>)</span><br><span class="line">                             <span class="keyword">for</span> k, q <span class="keyword">in</span> variational_posteriors.items()&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        print(<span class="string">&quot;打印变分推断参数信息:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> ts_model.parameters:</span><br><span class="line">            print(<span class="string">&quot;&#123;&#125;: &#123;&#125; +- &#123;&#125;&quot;</span>.<span class="built_in">format</span>(param.name,</span><br><span class="line">                      np.mean(q_samples_[param.name], axis=<span class="number">0</span>),</span><br><span class="line">                      np.std(q_samples_[param.name], axis=<span class="number">0</span>)))</span><br><span class="line">    </span><br><span class="line">    data_t_dist = tfp.sts.forecast(ts_model,observed_time_series=training_data,\</span><br><span class="line">                                   parameter_samples=q_samples_,num_steps_forecast=num_forecast_steps)</span><br><span class="line">    <span class="keyword">return</span>  data_t_dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#模型预测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forecast</span>(<span class="params">training_data</span>):</span></span><br><span class="line">    data_t_dist=run(training_data)</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        data_t_mean, data_t_scale, data_t_samples = sess.run(</span><br><span class="line">          (data_t_dist.mean()[..., <span class="number">0</span>],</span><br><span class="line">           data_t_dist.stddev()[..., <span class="number">0</span>],</span><br><span class="line">           data_t_dist.sample(num_samples)[..., <span class="number">0</span>]))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> data_t_mean,data_t_scale, data_t_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算回测</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mape</span>(<span class="params">data_t,forecsat</span>):</span></span><br><span class="line">    true_=data_t[-num_forecast_steps:]</span><br><span class="line">    true_=true_.iloc[:,-<span class="number">1</span>]</span><br><span class="line">    true_=true_.reset_index()</span><br><span class="line">    forecsat=pd.DataFrame(forecsat,columns=[<span class="string">&#x27;focecast&#x27;</span>])</span><br><span class="line">    mape_=pd.concat([pd.DataFrame(true_),forecsat],axis=<span class="number">1</span>)</span><br><span class="line">    mape_[<span class="string">&#x27;mape&#x27;</span>]=<span class="built_in">abs</span>(mape_.iloc[:,-<span class="number">2</span>]-mape_.iloc[:,-<span class="number">1</span>])/mape_.iloc[:,-<span class="number">2</span>]*<span class="number">100</span></span><br><span class="line">    <span class="keyword">return</span> mape_</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#读取数据集</span></span><br><span class="line">    </span><br><span class="line">    data_t=pd.read_csv(<span class="string">&quot;../input/ts_sale.csv&quot;</span>)</span><br><span class="line">    data_t=data_t[[<span class="string">&#x27;sale&#x27;</span>,<span class="string">&#x27;ym&#x27;</span>]]</span><br><span class="line">    data_t=data_t.set_index(<span class="string">&#x27;ym&#x27;</span>)</span><br><span class="line">    <span class="comment">#data_t.to_csv(&#x27;/input/ts_sale&#x27;)</span></span><br><span class="line">    print(<span class="string">&#x27;序列长度&#x27;</span>,<span class="built_in">len</span>(data_t))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#设置超参数</span></span><br><span class="line">    num_forecast_steps =<span class="number">3</span> <span class="comment"># 最后三个月作为预测值，以便于计算回测mape</span></span><br><span class="line">    num_samples=<span class="number">100</span>    <span class="comment">#设定采样次数</span></span><br><span class="line">    </span><br><span class="line">    training_data = data_t[:-num_forecast_steps]</span><br><span class="line">    data_dates=np.array(data_t.index,dtype=<span class="string">&#x27;datetime64[M]&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    observed_time_series=training_data</span><br><span class="line">    data_t_mean,data_t_scale, data_t_samples=forecast(training_data)</span><br><span class="line">    </span><br><span class="line">    data_y=pd.Series(data_t[<span class="string">&#x27;sale&#x27;</span>])</span><br><span class="line">    fig, ax = plot_forecast(</span><br><span class="line">    data_dates, data_y,</span><br><span class="line">    data_t_mean,data_t_scale, data_t_samples,title=<span class="string">&quot;forecast&quot;</span>)</span><br><span class="line">    ax.axvline(data_dates[-num_forecast_steps], linestyle=<span class="string">&quot;--&quot;</span>)</span><br><span class="line">    ax.legend(loc=<span class="string">&quot;upper left&quot;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="string">&quot;sale&quot;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="string">&quot;year_month&quot;</span>)</span><br><span class="line">    fig.autofmt_xdate()</span><br><span class="line">    </span><br><span class="line">    mape=get_mape(data_t,data_t_mean)</span><br><span class="line">    print(mape)</span><br><span class="line">    print(<span class="string">&#x27;mape:&#x27;</span>,mape[<span class="string">&#x27;mape&#x27;</span>].mean())</span><br></pre></td></tr></table></figure><h2 id="参考资料">参考资料</h2><ol type="1"><li><a href="https://www.jiqizhixin.com/articles/042202">blog</a></li><li><a href="https://github.com/tensorflow/probability">tfp</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;下面介绍一种基于tensorflow的概率编程框架TensorFlow Probability，可用于对时间序列构建概率模型。&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;2018年谷歌在tf开发者峰会上，宣布了新工具--tensorFlow Probability，</summary>
      
    
    
    
    <category term="时间序列" scheme="https://chiechie.github.io/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    
    <category term="时间序列" scheme="https://chiechie.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    <category term="贝叶斯" scheme="https://chiechie.github.io/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>时间序列 数据合成</title>
    <link href="https://chiechie.github.io/2021/07/26/ts-prepare/"/>
    <id>https://chiechie.github.io/2021/07/26/ts-prepare/</id>
    <published>2021-07-26T14:04:02.000Z</published>
    <updated>2021-07-26T15:25:25.472Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li>蒙特卡洛采样可以生成iid的样本，但是要生成有依赖关系的样本就不行了，可以使用马尔可夫链。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://ipfs.io/ipfs/bafykbzaceajhmnmehz7amkjofpsxmsymk5u6ph4mrzytlp5zq7wf7ouhqkre2?filename=Aileen%20Nielsen%20-%20Practical%20Time%20Series%20Analysis_%20Prediction%20with%20Statistics%20and%20Machine%20Learning-O’Reilly%20Media%20(2019).pdf">practical time series:prediction with statistic &amp; machine learning</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;蒙特卡洛采样可以生成iid的样本，但是要生成有依赖关系的样本就不行了，可以使用马尔可夫链。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;https://ipfs.io/ip</summary>
      
    
    
    
    <category term="时间序列" scheme="https://chiechie.github.io/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    
    <category term="时间序列" scheme="https://chiechie.github.io/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>3个驱动因子</title>
    <link href="https://chiechie.github.io/2021/07/26/reading_notes/reality/force/"/>
    <id>https://chiechie.github.io/2021/07/26/reading_notes/reality/force/</id>
    <published>2021-07-26T01:43:58.000Z</published>
    <updated>2021-07-27T11:41:06.084Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>接下来几十年，三个突出的问题：人口结构、贫富两极化和信息获取平民化。</p></blockquote><h1 id="要点">要点</h1><ol type="1"><li><p>研究历史的一个讽刺（irony）是，我们常常知道一个故事的确切结局，但不知道它什么时候开始的</p></li><li><p>举个例子，是什么导致了金融危机？你必须了解抵押贷款市场（mortgage，market）。是什么塑造了抵押贷款市场? 前30年的利率下降。利率下降的原因是什么? 20世纪70年代的通货膨胀。是什么导致了通货膨胀？20世纪70年代的货币体系和越南战争的后遗症。是什么导致了越南战争? 好吧，二战后西方对共产主义（communism）的恐惧..。如此没有尽头。</p></li><li><p>每一个当前的事件，无论大小，都有父母、祖父母、曾祖父母、兄弟姐妹和堂兄弟姐妹。忽略家谱会混淆你对事件的理解，给人一种错误的印象，比如事情为什么会发生，可能会持续多久，以及在什么情况下它们可能会再次发生。孤立地看待事件，而不去欣赏它们的长期根因（long roots），可以解释预测为什么困难？政治为什么令人讨厌？等等</p></li><li><p>那些根因可以溯源。挖得越深，你就越能接近重大事件: 这些事件是如此的强大，它们影响着一系列看起来毫不相关的话题。这些事件的根原是二次世界大战。</p></li><li><p>从1939年到1945年，世界重置了多少，战争留下的变化有多么深刻，这些都很难夸大，几乎定义了此后发生的一切。</p></li><li><p>青霉素（Penicillin）的存在归功于战争。雷达、喷气式飞机、核能、火箭和直升机也是如此。用消费信贷和可减税的利息补贴消费是战时生产结束后为了保持经济正常运转而采取的深思熟虑的政策。高速公路是为了疏散城市居民和动员军队以防止冷战期间的核弹袭击，而冷战是二战的近亲。互联网也是如此。</p></li><li><p>民权运动——也许是我们这个时代最重要的社会和政治事件——在战争期间真诚地开始了种族融合。</p></li><li><p>战争期间，由于工厂需要妇女，女性劳动力增加了650万。大多数人在战争结束后继续工作，开始了一个趋势，到1990年，女性劳动力参与率翻了一番。这可能是我们一生中最重要的一次经济事件。</p></li><li><p>在2019年找到一些对你重要的东西——社会的，政治的，经济的，无论什么——只要稍微努力一下，你就可以追溯到二战时期。这一规则的例外太少了，这令人震惊。</p></li><li><p>但这不仅仅是令人震惊。这是一个容易被忽视的例子: 如果你不花一点时间去理解二战的起因和结果，你将很难理解为什么过去60年会发生这样的事情。</p></li><li><p>你将努力理解最大的技术是如何起步的，以及最重要的创新是如何诞生于恐慌引起的需求而不是舒适的愿景。或者为什么家庭债务会以现在的速度增长。或者说，为什么欧洲人对社会保障体系的看法与美国人不同。约翰·梅纳德·凯恩斯预测，被战争摧毁的国家会继续“渴望社会和个人安全”，事实也的确如此。历史学家托尼 · 朱特写到战后的欧洲:</p></li></ol><blockquote><p>只有国家才能给广大人民带来希望或拯救（salvation）。在经济萧条、占领和内战之后，国家作为福利、安全和公平的代理人，是社区和社会凝聚力的重要来源。</p></blockquote><ol start="12" type="1"><li><p>今天发生的许多事情，如果不了解75年前的战时部队的实际情况，就不容易理解。对我来说，研究这场战争很有意思，不是因为发生了什么，而是因为它的影响。</p></li><li><p>这就引出了一个问题: 还有什么像第二次世界大战？</p></li><li><p>三个突出的问题: 人口(demographics)、不平等和信息获取。</p></li><li><p>有数百种力量塑造着这个世界，这里没有提到。但我认为，许多，甚至大多数，都是这三者的衍生品。</p></li><li><p>这些大事件中的每一件都将对未来几十年产生深远的影响，因为它们都是变革性的，而且无处不在。它们影响着几乎所有人，尽管方式不同。随之而来的现实是，我们并不确切知道他们的影响将如何展开。在1945年，没有人确切知道二战将如何继续塑造世界，只有在极端的方式。但是我们可以猜测一些最有可能的变化。</p></li><li><p>人口结构的变化( demographic shift)重塑了现代经济。以下是正在发生的事情:</p></li></ol><figure><img src="https://www.collaborativefund.com/uploads/1-9a3ba1.png" alt="1-9a3ba1.png" /><figcaption aria-hidden="true">1-9a3ba1.png</figcaption></figure><p><em>Source: Census Bureau</em></p><p>1960年，0-4岁的美国人是70-74岁的三倍。到2060年，这两个群体的数量基本持平。年轻工人的比例正在下降。老年工人的比例正在上升。退休人员的比例——或者说到了退休年龄的人——正在激增。</p><p>There have been about 100 billion humans born during the 200,000 years we’ve existed.</p><p>在我们存在的20万年间，出生了大约1000亿人。</p><p>For practically all of that time, making more people wasn’t an issue. Keeping them alive is another story. But having lots of babies has been a fundamental part of humanity for tens of thousands of years. This is more than biological; there’s a strong cultural element to reproducing.</p><p>实际上在那段时间里，造人并不是一个问题，让他们活下去就是另一回事了。但是几万年来，生很多孩子一直是人类的基本组成部分。这不仅仅是生物学上的，还有一个强烈的文化因素在复制。</p><p>在《人口冲击的战略效应》（Strategic Effects of Demographic Shocks）一书中，詹姆斯 · 福尔摩斯引用了亚里士多德(Aristotle’s)对古代斯巴达(Sparta)的看法:</p><blockquote><p>立法者希望斯巴达人越多越好，他鼓励公民生育尽可能多的孩子，因为有一条法律规定，有三个儿子的人可以免除[军事]义务，有四个儿子的人可以免除所有税务。</p></blockquote><p>在苏联，约瑟夫 · 斯大林将女英雄奖授予那些有10多个孩子的妇女。</p><p>盖洛普(Gallup)调查了美国人70年来理想的家庭规模数量。1944年，77% 的美国人认为生三个以上的孩子是理想的。女性平均得分为3.4。</p><p>后来事情发生了变化。</p><p>随着女性变得越来越富有，她们生育的孩子也越来越少。</p><p>富裕的家庭也会改变抚养孩子的期望值，降低想要孩子的数量。教育成本尤其造成了一个悖论，你认为你能负担的孩子数量随着你变得富有而减少，过去50年里拥有大学学位的人口比例一路飙升:</p><figure><img src="https://www.collaborativefund.com/uploads/2-d2f6ba.png" alt="2-d2f6ba.png" /><figcaption aria-hidden="true">2-d2f6ba.png</figcaption></figure><p><em>From the book What to Expect When No One’s Expecting</em></p><p>人的寿命更长，婴儿数量更少是一件大事，因为这意味着人口老龄化。当人口老龄化的时候，从经济增长到职场文化，再到国际秩序，一切都会发生变化。</p><p>低生育率是一个全球现象，尤其是在发达国家。随着人口老龄化和人口增长放缓，，人口增长在许多情况下正在转向负增长。</p><p>以下是过去30年发生的事情:</p><figure><img src="https://www.collaborativefund.com/uploads/3-878341.png" alt="3-878341.png" /><figcaption aria-hidden="true">3-878341.png</figcaption></figure><p><em>Source: Census Bureau International Database</em></p><p>下面是未来30年预计会发生的事情:</p><figure><img src="https://www.collaborativefund.com/uploads/4.png" alt="4.png" /><figcaption aria-hidden="true">4.png</figcaption></figure><p><em>Source: Census Bureau International Database</em></p><p>这件事的重要性怎么说都不为过。</p><p>当人们谈论哪个国家将主导下个世纪，他们指向了人工智能和机器学习领域的领导地位，在这两个领域中，中国看起来很有竞争力。但是，当你的下一代人失去了五分之一的劳动力时，经济增长就难得多。中国可以发明一些像下一代互联网一样大的东西，但是当与其人口结构混合在一起时，中国的经济就会混乱不堪。欧洲、日本和韩国的情况相同，甚至更糟。</p><p>人口结构将减缓美国经济的增长，但对其他国家来说，这是一场五级警报。因此，即使假设生产率增长水平相同，仅仅考虑到美国的人口特征，美国也比其他发达国家要富裕得多。在中国、欧洲和日本采取所有正确行动的时候，美国可能会在技术方面犯下错误，而美国仍然可能是一个更大、更强大的经济体。</p><p>人们喜欢谈论新技术和创新，因为很有趣，人口结构就很无趣。但是，在未来几十年里，对于整体经济增长的重要性，人口结构跟大多数创新相比，重要性有过之无不及。</p><p>个人口结构造成的另外一个影响是: 一些国家越来越依赖移民来增加本国人口增长。</p><ol start="2" type="1"><li>四十年来不断扩大的财富不平等已经到了不可避免的转折点。</li></ol><p>不平等是现存的最具争议性的话题之一，因为它让资本主义与公平对立起来，就像是零和游戏，你的收获就是我的损失，等等。这是部落的天性，部落之间的争论可能升级为争斗，因为你觉得你的身份和尊严岌岌可危。</p><p>但在这个故事（narrative）中，你认为不平等是对还是错，是好还是坏，或者我们应该怎么做，都无关紧要。其他人可以处理这些问题。</p><p>重要的是，这件事确实发生了，而且发生得很大。这是一个影响所有其他话题的大事件。</p><p>上世纪50年代，历史学家弗雷德里克•刘易斯•艾伦(Frederick Lewis Allen)在一篇文章中描述了镀金时代(Gilded Age)让位于更为平衡的经济时期所发生的社会革命:</p><blockquote><p>要了解今天的美国，我们不仅必须认识到美国良知的反抗对其发展有多么重要，它向美国人灌输了这样的思想: 你可以修复这个国家的经济和政治机器，使之更好地为大多数人服务，而不必停止这个机器... ..。</p><p>... ... 通过对体系的修订——税法、最低工资法、各种补贴、保障和规章，加上工会的压力和新的管理态度——我们废除了《铁的工资法》。我们实际上实现了收入的自动再分配，把富裕阶层的收入分配给不那么富裕的阶层。这并没有使机器停止运转，反而增强了它的动力。正如个人企业将部分利润投入到改善中时，似乎运转得最好一样，如果将部分国民收入用于改善低收入群体的收入和地位，使他们能够购买更多的商品，从而为所有人扩大市场，那么整个企业体系似乎运转得更好。我们发现了一个新的开拓领域: 穷人的购买力。</p><p>在我看来，这就是美国大发现的精髓所在。这也有它的必然结果: 如果你这样给很多以前处于社会底层的人带来了好处，他们就会抓住机会，总的来说，就会成为负责任的公民。</p></blockquote><p>我指出这一点是为了表明事情进展顺利，他们做得很好。</p><p>但这是一场革命，最高所得税率在三十年内实际上从0% 上升到了94% 。</p><p>简而言之，以下是经济力量的平衡如何在社会两极间切换的历史轨迹:</p><ul><li><p>一个人创造一个伟大的事业，变得富有。</p></li><li><p>人们说，“太棒了! 他们创造了一个伟大的企业。他们应该富有。”真正的钦佩。</p></li><li><p>随着商业的复利效应，财富带来更多的财富。</p></li><li><p>更多的财富掌握了权力，包括监管影响力（regulatory influence）、公司治理缺陷（ governance deficiencies,）和工资谈判杠杆。</p></li><li><p>这些权力创造了超级富豪，低收入的工人开始说，“嘿，你超级富有的原因是，你从仅仅是财富中获得了权力，更像是寻租，而不是创造价值。”</p></li><li><p>人们说，“这是不对的，你不能这么做。”</p></li><li><p>超级富豪说，“太糟糕了，事情就是这样运转的。”</p></li><li><p>这个过程一直在compounding。</p></li><li><p>人们感到士气低落（demoralized），没有尊严（undignified），就好像整个体制都在偏袒少数人一样。</p></li><li><p>他们最终拥有了足够的资源，并且组成了一个强大的群体，足以 force change，特别是通过税收、最低工资和工会。</p></li><li><p>超级富豪说，“这不对，你不能这么做。”</p></li><li><p>人们说，“太糟糕了，事情就是这样运转的。”</p></li></ul><p>再次强调，你认为这是好是坏，或者你站在哪一边都无关紧要。对于这篇文章来说，重要的是它发生了。这种情况在两个方向都发生。到20世纪80年代初，影响力主要来自工人，而不是投资者。然后权力再次转移，来来回回。</p><p>关键在于权力是短暂的。当那些不具备这种能力的人受够了，他们联合起来获得足够的影响力来夺回这种能力时，这种能力就发生了转变。永远不要低估拥有共同目标的一群无能为力的人的力量。</p><p>如果你接受这个前提，那么过去40年发生的事情就是一件大事。</p><p>你们都听说过关于收入最高的1% 家庭的财富增长了多少，收入最高的100个家庭拥有多少财富等等的统计数据。这些数字已经被重复了足够多次，而且它们通常被描述成过多的数字，这又一次激发了部落的战争（ribal war instincts.）本能。</p><p>更有趣的是另一个极端的人。他们的心态是，“这不起作用，这个体系已经被打破，机会对我不利,”将——如果历史有任何指导的话——联合起来，迫使这个体系朝另一个方向发展。</p><p>而且有很多这样的人。关于这个话题最重要的一点是，人们不会凭空判断自己的幸福。他们衡量自己相对于周围人的价值。如果你的收入保持不变，而你周围的人看到他们的收入增长了10% ，你可能会感觉更糟。这通常是微妙的，因为那些拥有更多钱的人的物质财富会挑起你的欲望，经常嘲笑你通过借债来缩小你和他们之间的差距。</p><p>关键在于，我们不能仅仅看到顶部变得多么富有，或者底部停滞不前。正是这两者之间的差距导致了一个群体对另一个群体的反抗。</p><p>这个分裂是近一个世纪以来最大的</p><p>当底部开始向顶部反推时会发生什么？</p><p>其中一部分已经发生了。特朗普、伯尼 · 桑德斯和 Brexit 都代表人们说，“停下来，我们要尝试一些新的东西。如果你不喜欢，那就太糟糕了。这就是事情的运作方式。”</p><p>但是很多事情都会改变。</p><p>几乎可以肯定的是，教育制度将被颠覆。目前的安排是需要大学学位才有机会成为并保持中产阶级，但是如果你没有家庭的帮助，那么承担改变生活的大量债务就不能持久。我不知道结局如何。但是，在30年的时间里，几乎不可能出现这样的情况: “每个人都在18岁时继续接受教育抵押贷款，学费持续上涨，涨幅是通货膨胀率的两倍，一切都很好。”不管怎样，它总会破裂的。</p><p>政治则是另一回事。它已经在改变了。对一端征收关税（Tariffs）和对另一端征收财富税是同一件事的症状: 太多的选民对这个体系的运作方式过于不满。我不知道它在哪里结束，但是1960年的联邦政府与1920年的政府相比已经面目全非了。大萧条和第二次世界大战引发了变化，但是那个时期，持久的社会变化集中在支持低收入群体。在接下来的几代中也可能是类似的情况。</p><p>我们将提出各种各样的解释，来解释为什么这些事情发生了变化。但最有可能的是，2000年代初期的收入不平等是一个大问题，引导了随后的几十年，就像几个世纪以来一样。</p><ol start="3" type="1"><li>获取信息填补了过去用来建立无知的社会盾牌的空白。</li></ol><p>1970年，17岁的 Carole Cole 从德克萨斯州的一家少年感化院逃跑后失踪。</p><p>一年后，在路易斯安那州发现了一具身份不明的尸体。是卡罗尔，但路易斯安那州警方并不知情。他们无法确认她的身份。卡罗尔的失踪和那具身份不明的尸体一样，都成了悬案。</p><p>三十四年后，卡罗尔的妹妹在Craigslist网站上发布消息，寻找妹妹失踪的线索。几乎在同一时间，路易斯安那州的一个治安部门在脸书上发了一个页面，请求帮助辨认34年前发现的无名女尸。</p><p>六天后，有人把这两个帖子联系起来。</p><p>近四十年来困扰侦探们的问题，Facebook 和 Craigslist 在不到一周的时间里就解决了。</p><p>这种事情十年前都没有发生过。我们可能还没有意识到它的全部潜力——好的和坏的。</p><p>上一代人最伟大的创新就是摧毁了信息屏障，这种屏障曾经使陌生人彼此隔绝。</p><p>电话和收音机很接近，但是差别很大。在《The Rise and Fall of American Growth》一书中，罗伯特 · 戈登提醒我们，直到19世纪末，75% 的美国人还生活在“乡村”，既没有电话也没有邮政服务。发生在一个小镇上的事情就像发生在另一个星球上一样。电话和无线电改变了20世纪，打破了这些障碍。但是这个电话是用来和你事先约好的人通话的，而且收音机不允许你和它对话。</p><p>过去20年发生的事情——尤其是过去10年——历史从来没有过。电话消除了你和远亲之间的信息差距，但是互联网缩小了你和世界上每一个陌生人之间的差距。</p><p>这是件大事，也许是二战以来最大的事。</p><p>它是如此之大，以至于我认为没有人知道它将导向何方。但是让我来说明几点。</p><p>TechCrunch 的创始人迈克尔 · 阿灵顿最近写道: “我本以为Twitter 正在将我们分裂，但是我慢慢开始觉得你们中一部分人一直讨厌另一部分，但是直到 Twitter出现，才暴露出来这一点。”这是一个很好的观点，突出了一些容易被忽视的东西:</p><ul><li>1)每个人都属于一个部落（tribe）;</li><li>2)这些部落有时候根本上不同意对方;</li><li>3)如果这些部落保持距离，这很好;</li><li>4)互联网越来越确保他们不会保持距离</li></ul><p>接受不同的观点是好的，也是必要的。但是，当某个部落基本的、不可动摇的观点在向其他部落展示时，人们会震惊地发现，对他们来说神圣的东西并不总是普遍真理。政治观点的范围一直是极端的，但是在过去十年中看到的是，当意识形态的裹脚布被移除后会发生什么。</p><p>另一个转变是推动精英管理（meritocracy）。那些从未拥有过声音的人，几乎一夜之间就拥有了最大的声音。匿名博主杰西•利弗莫尔(Jesse Livermore)提供的投资分析，比顶级投资银行的整个部门能够发表的文章还要睿智。两年前，Nick Maggiulli 还默默无闻，从未在金融领域工作过; 现在，他的投资文章比大多数主要新闻机构获得了更多关注。实际上，文凭主义（credentialism）正在消失。我不在乎你是谁或者你的职位是什么。如果你有什么好主意，我想听听。当然，这种做法的另一面是危险的，因为疯子（maniac）喊得最大声往往会引起注意。但是当你移除了进入门槛，你会发现天赋比你以前想象的更加普遍。成千上万的迈克尔 · 杰克逊、斯蒂芬 · 金斯和托马斯 · 爱迪生的作品将在未来得到认可，而这些作品在任何其他时代都会被忽略。</p><p>第三个转变是，现在更难躲在后面，但更容易传播虚假和误导性信息。我不知道如何调和这种矛盾，但是你在任何地方都能看到这两者。客户评论可以完成Better Business Bureau 永远无法完成的任务，但是虚假评论带来的挑战在二十年前是不存在的。杰夫 · 贝佐斯(Jeff Bezos)曾经说过，随着消费者变得更加见多识广，企业应该把“绝大多数的精力、注意力和金钱投入到创造一个伟大的产品或服务上，而少量投入到宣传和营销中去。”同时，垃圾邮件的存在是因为它works。也许互联网让我们更了解情况，也更容易上当受骗。区分两者是困难的。真实和虚构这两个极端都会对现实造成重大影响。</p><p>你可以继续无休止地讨论这个话题。</p><p>在我看来，在线交友会从根本上改变未来几代人的婚姻。</p><p>在线教育的影响力会增长。</p><p>地缘政治似乎也是一个有趣的矛盾，因为它比以往任何时候都更加脆弱(通过 Twitter 进行外交) ，却更加依赖彼此(全球市场)。还有一个问题是，当两位候选人在高中都有社交媒体时，总统竞选是如何进行的，当每个人都发布他们以后会后悔的东西时。这场戏一定很有意思——既鼓舞人心又令人害怕。</p><hr /><p>世界是由尾部事件（tail event）驱动的。少数因素决定了大多数结果。这是投资中最重要的概念之一，少量的头寸可能占到你一生的大部分回报。</p><p>历史也不例外。第二次世界大战、第一次世界大战和大萧条几乎影响了20世纪的每一个重要事件。工业化和内战在19世纪也是如此。</p><p>人口分布、不平等和信息获取将对未来几十年产生巨大影响。这些大事件的结局是一个有待讲述的故事。但是当这个故事发生了，我们才知道它是从哪里开始的。</p><h1 id="参考">参考</h1><ol type="1"><li><a href="https://www.collaborativefund.com/blog/three-big-things-the-most-important-forces-shaping-the-world/">Morgan Housel 摩根豪斯</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;接下来几十年，三个突出的问题：人口结构、贫富两极化和信息获取平民化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;要点&quot;&gt;要点&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;研究历史的一个讽刺（irony）是，我们常常知道一个故事的确</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="因果关系" scheme="https://chiechie.github.io/tags/%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB/"/>
    
    <category term="趋势" scheme="https://chiechie.github.io/tags/%E8%B6%8B%E5%8A%BF/"/>
    
  </entry>
  
  <entry>
    <title>《Probabilistic Demand Forecasting at Scale》笔记</title>
    <link href="https://chiechie.github.io/2021/07/25/ml-platform-nots/"/>
    <id>https://chiechie.github.io/2021/07/25/ml-platform-nots/</id>
    <published>2021-07-25T03:35:00.000Z</published>
    <updated>2021-07-27T12:10:39.403Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文设计了一个端对端的ml系统,对大规模时序进行预测</p></blockquote><h1 id="要点">要点</h1><ol type="1"><li>对大规模时序预测，工业界一直<strong>研究不足</strong></li><li>一般的模型开发和部署的流程：算法人员：使用一套语言（keras类似）快速实验和进行算法开发，在实验环境。工程人员：将模型重新实现一遍，在生产环境上线。</li><li>难点在于系统层面，又要 稳定 又要 灵活。提升稳定性的代价在于代码复杂度上升，缺少抽象导致没法快速实验。</li><li>本文提出了一个时序预测的框架，并且支持四种建模范式：local(数据并行)/global(最简单)/local with 人工指定分组/global and local(人工不指定分组，给出商品的元信息，让模型去学)</li><li>本文的解决方案--将工程人员的工作沉淀为平台工具，如:</li></ol><ul><li>提供了数据处理的high-leve API：用户只用指定dataflow的数据源，处理的逻辑流，背后真正执行的数据流（一个DAG）会被系统重写（优化计算效率）</li><li>后台支持四种模型训练范式</li><li>后台支持分布式学习</li><li>使用层面：实验阶段 希望快速出结果 ，生产阶段希望自动化地配置各种任务，包括超参搜索</li><li>算法层面：抽象出了路由功能 和 集成功能，使用命令式编程的方式 就可以实现 1. 给每个算法or策略分配 sub group样本用来训练， 2 给每个sub group 分配多个算法，并指定集成的权重）</li></ul><ol start="6" type="1"><li><p>本方法的收益：大规模训练；算法低门槛。</p></li><li><p>可伸缩性(可扩展性)：评价软件系统处理能力的指标，高可伸缩性代表一种弹性，表示通过很少的改动甚至只是添加硬件设备，就能实现整个系统处理能力的线性增长。</p></li><li><p>实际中的需求：</p><ul><li>预测某个类别商品（比如厨具）的销量。</li><li>历史数据缺失比较常见：比如某段时间，商品卖脱销了/有些商品停产了</li><li>圣诞节前几周，销量可能会上升（跟商品自己无关）</li><li>对高销量（看每周的平均销量 在所有商品中的排名）商品，使用混合策略，各自权重为0.5：baseline 模型和GLM模型</li><li>对系统的自动化需求：在生产阶段会用到集群，服务的可用性有严格的标准。自动化的模型选择，自动的模型更新（固定特征集，超参），自动化的模型集成策略。</li></ul></li><li><p>一些最佳实践</p><ul><li>新发布一个模型之前要回测</li><li>面对众多需要预测的商品时，使用二八原则，80%不重要的商品（例如历史数据稀疏），使用cheap解决方案（baseline 模型），20%重要的商品，使用expensive解决方案（nn，集成模型）</li><li>对没有被路由到的商品，使用baseline模型兜底</li><li>如果单个learner失败了，商品预测就出不来了，使用ensemble策略比较好</li><li>在模型开发的整个生命周期：先尝试小范围的baseline模型，后面不断的对特定的商品子类（subset）添加 specialized learners，来提升准确率</li><li>对于批量训练多个local模型的场景，怎么保证准确率？依据经验，将tolerance 设置的很低，将num_iteration设置为一个固定的值</li><li>如果又想要在不同曲线之间迁移，又想保持各自的特点，可以这么做：将共享的向量弄小一点，或者 提供自由度：让每个曲线都可以选择自己的特征。</li><li>开发模型阶段：临时性的需求，在小数据集中适用小规模实验来调试算法和 finetune模型，或者在集群上跑一个算法，来测试这个模型在大数据集上的效果（托管到我们平台），这种需求来自数据科学家，一般是高频手动，主要诉求是：易于执行 &amp;快速出结果</li></ul></li></ol><h1 id="附录">附录</h1><h2 id="问题">问题</h2><ul><li>预测多个时序，使用全局模型和局部模型，系统后台分别是怎么设计的？为什么要这么设计（难点 或者 遇到的问题 是什么？怎么解决的）</li><li>时序预测的后台能否拓展到其他场景，或者更general 的机器学习场景中？</li><li>预处理 和 特征转换 阶段，专门针对时序数据做了哪些改进？提供了哪些算子？</li><li>参数服务器是数据平行还是模型并行？</li></ul><h2 id="概率模型的输出">概率模型的输出</h2><figure><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2Fsg4v0LRFEh.png?alt=media&amp;token=ec469b3d-4912-4f27-9e1d-080f37bb27fa" alt="时序预测需求" /><figcaption aria-hidden="true">时序预测需求</figcaption></figure><ul><li>黑色：观测值</li><li>绿色：训练阶段，0.9 和 0.1 的分位数</li><li>红色：未知数据上推断，0.9 和 0.1 的分位数</li></ul><h2 id="系统架构">系统架构：</h2><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FdxvYHgGI4v.png?alt=media&amp;token=ebc71e8e-6863-42d3-8b2c-e5f8159c2a8d" /></p><h2 id="数据处理api">数据处理API</h2><p>让用户只用关心 数据源，算子组装 逻辑，平台会根据用户的声明式编程语言（declarative ），生成计算图（DAG）和 优化（合并相同计算逻辑，生成缓存节点）</p><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FKE2kXC_eEL.png?alt=media&amp;token=612d833e-359e-44d3-9f86-42d0c152d120" /></p><h1 id="参考">参考</h1><ol type="1"><li><a href="http://www.vldb.org/pvldb/vol10/p1694-schelter.pdf">基于概率的大规模需求预测</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文设计了一个端对端的ml系统,对大规模时序进行预测&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;要点&quot;&gt;要点&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;对大规模时序预测，工业界一直&lt;strong&gt;研究不足&lt;/strong&gt;&lt;/li&gt;
</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="最佳实践" scheme="https://chiechie.github.io/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="时序预测" scheme="https://chiechie.github.io/tags/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B/"/>
    
    <category term="量化交易" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/"/>
    
    <category term="读书笔记" scheme="https://chiechie.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>时间序列1 时间序列技术概况</title>
    <link href="https://chiechie.github.io/2021/07/21/timeseries/timeseries1_basic/"/>
    <id>https://chiechie.github.io/2021/07/21/timeseries/timeseries1_basic/</id>
    <published>2021-07-21T07:23:49.000Z</published>
    <updated>2021-07-26T14:01:42.157Z</updated>
    
    <content type="html"><![CDATA[<h2 id="时间序列技术综述">时间序列技术综述</h2><ol type="1"><li><p>时间序列结构比截面数据的信息量更多</p></li><li><p>时序分析工具可以分析所有的序列数据，不一定是时间序列。</p></li><li><p>时间序列模型包括几种：统计模型，状态空间模型，机器学习/深度学习模型。</p></li></ol><h2 id="时间序列与深度学习">时间序列与深度学习</h2><ol type="1"><li><p>神经网络中专门有一些算子来处理时间序列结构，比如卷积神经网络中的因果卷积（causal conv），空洞因果卷积（Dilated Causal Convolution），空洞卷积（dialted conv）。这些卷积原理上都大同小异，都假设相邻时间内，数据的相关性很强，卷起来可以得到更高层的语义信息。</p></li><li><p>空洞卷积本来是图像领域的概念，希望扩大接受域（ reception field）而不增加计算量。</p></li><li><p>因果卷积类似于自回归算子，对前置窗口中的数据做线性组合。可以说自回归模型是因果卷积的退化版。</p><blockquote><p>arima/sarima可以看成残差网络 + 因果卷积的特例</p></blockquote></li><li><p>膨胀因果卷积：空洞卷积 + 因果卷机的结合</p></li><li><p>TCN网络的结果：多个 膨胀因果卷积层的堆叠，加上了pooling（扔掉后置窗口）+ activation + Dropout（卷完之后的非线性转换+裁剪） + Resnet（残差连接避免梯度消失）</p></li><li><p>时序预测方法的分类：传统时间序列和深度神经网络。</p></li><li><p>传统时间序列模型：arma/arima/sarima/ arima/state space/exponential smoothing。平稳性检验。</p></li><li><p>深度神经网络模型：卷积神经网络/全连接神经网络/循环神经网络/基于Seq2Seq的模型，以及是否基于attention。</p><ol type="1"><li>基于全连接网络的模型：MQ-DNN</li><li>基于卷积的神经网络：TCN/CNN-QR/</li><li>基于隐藏状态的模型：DeepFactor/DeepStateSpaceModel</li><li>基于循环神经网络：SimpleRNN/LSTM/GRU，也可以加入attention层，变成基于重要性的神经网络。</li><li>基于Seq2Seq的模型：DeepAR/Transformer/Bert/GPT，其中Transformer/Bert/GPT是基于attention的。</li></ol></li><li><p>传统时间序列模型只对单个曲线做预测，缺点是要一个个曲线去做模型选择，并且每个样本曲线需要积累大量的历史数据。基于深度学习或机器学习的时序预测技术可以对多个曲线一起建模。</p></li><li><p>其他领域如文本，图像，语音领域的技术都可以应用到时间序列，但是要注意时序场景中有几个特殊的地方</p><ol type="1"><li>实践序列的下游的决策一般依赖输出概率分布，比如要做异常检测，就需要输出上下界。</li><li>预测target为整数时，不能使用常用的归一化方法。</li></ol></li><li><p>时序预测中的一些难点：</p></li></ol><ul><li><p>现实中需要对多条曲线建模，但是单个曲线去建模，人工成本高</p></li><li><p>不同曲线模式不一样（最显而易见的，scale不一样），而学习一个global model对nn来说挑战很大（nn擅长局部建模）</p></li><li><p>预测概率分布</p></li></ul><h2 id="附录">附录</h2><h3 id="标准卷积">标准卷积</h3><figure><img src="https://pic3.zhimg.com/v2-d552433faa8363df84c53b905443a556_b.webp" alt="Standard Convolution with a 3 x 3 kernel (and padding" /><figcaption aria-hidden="true">Standard Convolution with a 3 x 3 kernel (and padding</figcaption></figure><h3 id="空洞卷积">空洞卷积</h3><figure><img src="https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/dilation.gif?raw=true" alt="dilation" /><figcaption aria-hidden="true">dilation</figcaption></figure><h3 id="膨胀因果卷积">膨胀因果卷积</h3><figure><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2FzEwTvSz-ee.png?alt=media&amp;token=c46507da-4eca-4d43-970d-fd1180495d82" alt="膨胀因果卷积" /><figcaption aria-hidden="true">膨胀因果卷积</figcaption></figure><ul><li></li></ul><h3 id="cnnrnn基于attention的模型对于时间序列建模">CNN，RNN，基于attention的模型，对于时间序列建模</h3><p><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2F_n2z_XQqI2.png?alt=media&amp;token=facfccac-e8ac-4895-a84c-7add43cd165a" /></p><h3 id="多步预测-迭代法和直接法">多步预测-迭代法和直接法</h3><ul><li><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frf_learning%2Fcfl7jS1Uqc.png?alt=media&amp;token=39859f26-511a-4d29-840f-8038bcaa824e" /></li></ul><h3 id="wavenet">wavenet</h3><p>wavenet是什么？可视化长什么样？输入输出和参数个数分别是什么？</p><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.zhihu.com/question/54149221/answer/323880412">如何理解空洞卷积（dilated convolution）？ - 刘诗昆的回答 - 知乎</a></li><li><a href="https://github.com/vdumoulin/conv_arithmetic">conv_t</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;时间序列技术综述&quot;&gt;时间序列技术综述&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;时间序列结构比截面数据的信息量更多&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;时序分析工具可以分析所有的序列数据，不一定是时间序列。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;时间序列模型包括几</summary>
      
    
    
    
    <category term="时间序列" scheme="https://chiechie.github.io/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    
    <category term="最佳实践" scheme="https://chiechie.github.io/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="时序预测" scheme="https://chiechie.github.io/tags/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B/"/>
    
    <category term="量化交易" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/"/>
    
  </entry>
  
  <entry>
    <title>金融基础</title>
    <link href="https://chiechie.github.io/2021/07/15/reading_notes/economics/finance-basic/"/>
    <id>https://chiechie.github.io/2021/07/15/reading_notes/economics/finance-basic/</id>
    <published>2021-07-15T14:50:07.000Z</published>
    <updated>2021-07-19T04:04:15.324Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li><p>资产是什么？连续产生现金流。比如公司，股票债券，知识，名声。</p></li><li><p>如何对资产定价？未来所有现金流折现。</p></li><li><p>如何计算net PV？减去初始时刻的投资。</p></li><li><p>按什么折现？无风险利率。</p><blockquote><p>...公认的risk free rate是指美帝的treasury security rate,也就是美国国债的利率。通常而言，根据maturity长短不同，我们有主要三种treasury securities：T-Bill（一年以下），T-Note（两年到十年），和T-Bond（十年以上）。</p></blockquote></li><li><p>复利？不仅仅一年才计息，银行账户每天计利，抵押物每个月计利息，债券半年计利息。</p></li><li><p>有效年利率和年利率</p><ol type="1"><li>有效年利率（EAR effective annual interest rate）是指把各种不同的复利周期（如一年复利12次，或者一年复利4次）换算为以年为一个复利周期时，利率是多少。</li><li>年利率(annual interest rate)是指银行公布的利率，一般需要和公布的复利频率结合起来用，才能知道每一个复利期真正的利率，单独看用处不大。</li></ol></li><li><p>通胀（inflaction）：1美元购买力的变化。（对应物理世界）</p></li><li><p>计算资产的NPV时，实物现金流使用实际利率折现；名义现金流使用名义利率折现。</p></li><li><p>固定收益证券，未来现金流固定的资产。</p></li><li><p>固定收益市场的参与者：证券发行人/承销商/投资人。</p></li><li><p>债券的即期收益率，到期收益率，远期收益率有什么区别？</p><ol type="1"><li><p><strong>YTM主要用于quotation，spot rate主要用于pricing，而forward rate多用于modeling。</strong></p></li><li><p>即期利率与远期利率的区别在于某利率起作用的起点 即期利率通常在即期交易前1-2天报价 远期利率是某一未来时间到另一未来时间的利率.远期利率是用即期利率根据无套利原则推算的</p><figure><img src="https://pic2.zhimg.com/80/8c16de723d1089665bd6d38d94b66738_1440w.jpg?source=1940ef5c" alt="img" /><figcaption aria-hidden="true">img</figcaption></figure></li><li><p>YTM是一种内部收益率（Internal rate of return）， 是净现值NPV=0(即成本与收益现值相等)时的收益率。</p></li><li><p>yield curve也更多是作为市场的一个indicator，而不是分析工具。</p></li></ol></li><li><p>股票定价模型：</p><ol type="1"><li>分红折现模型v1--折现现金流模型（DCF）：假设分红是常数</li><li>分红折现模型v2--gorden增长模型：分红以g的增长率增长</li></ol></li><li><p>期货定价</p><figure><img src="/Users/shihuanzhao/research_space/chiechie.github.io/source/_posts/finance-basi/image-20210716000554865.png" alt="image-20210716000554865" /><figcaption aria-hidden="true">image-20210716000554865</figcaption></figure></li></ol><h2 id="参考">参考</h2><ol type="1"><li>https://ocw.mit.edu/courses/sloan-school-of-management/15-401-finance-theory-i-fall-2008/video-lectures-and-slides/MIT15_401F08_lec02.pdf</li><li>https://www.zhihu.com/question/22562103/answer/21833989</li><li>https://ocw.mit.edu/courses/sloan-school-of-management/15-401-finance-theory-i-fall-2008/video-lectures-and-slides/MIT15_401F08_lec04.pdf</li><li><a href="(https://www.zhihu.com/roundtable/money)">债券的即期收益率，到期收益率，远期收益率有什么区别？</a></li><li>https://ocw.mit.edu/courses/sloan-school-of-management/15-401-finance-theory-i-fall-2008/video-lectures-and-slides/MIT15_401F08_lec07.pdf</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;资产是什么？连续产生现金流。比如公司，股票债券，知识，名声。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如何对资产定价？未来所有现金流折现。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如何计算net PV？减去初始时刻</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>时间序列2 统计分析模型</title>
    <link href="https://chiechie.github.io/2021/07/15/timeseries/timeseries2_classic-prediction/"/>
    <id>https://chiechie.github.io/2021/07/15/timeseries/timeseries2_classic-prediction/</id>
    <published>2021-07-15T00:25:11.000Z</published>
    <updated>2021-07-26T14:04:28.818Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li><p>随机过程，由一系列按照时间排序的随机变量组成。</p></li><li><p>序列的随机行为，由概率密度函数定义，如果能穷举出所有finite时间索引集合的概率分布，就可以确定该随机过程。</p><blockquote><p>随机过程的定义并没有提到平移不变性。</p></blockquote></li><li><p>平移不变性是指，移动一个时间步之后，概率分布保持不变。</p></li><li><p>严格平稳性，表示一个随机过程的所有finite时间索引集合对应的概率分布，都满足平移不变性。</p><blockquote><p>随机过程如果有了平移不变性，就可以用更简洁的pdf来表达。</p></blockquote></li><li><p>弱平稳性，也叫协方差平稳性，表示一个随机过程的所有2维时间索引集合对应的概率分布, 都满足平移不变性。</p></li><li><p>满足弱平稳性的随机过程比仅满足强平稳行的随机过程多的多。</p></li><li><p>满足协方差平稳性的随机过程满足表示定理(wold representation):</p></li><li><p>什么是好的模型？p尽可能小，或者ma中的q尽可能小。</p></li><li><p>弱平稳随机过程<span class="math inline">\({X_t}\)</span>的脉冲响应函数（impulse response function）表示某个时刻的噪声（innovation）怎么影响后面的随机过程，即the impact of the innovation on the process。</p><blockquote><p>脉冲响应函数，有点像这个因子的能量衰减函数，总能量(long-run cumalative response)=1, 每过一段时间，这个因子释放一点能量，从而对观测值造成影响，释放能量随时间逐渐疲乏，趋近于0.</p></blockquote></li><li><p><span class="math inline">\(\psi\)</span>和<span class="math inline">\(\psi^{-1}\)</span>类似收集能量（或者innovation造成的影响）和消除能量（或者innovation造成的影响）。</p></li><li><p>对<span class="math inline">\(X_t\)</span>进行消除能量操作（历史innovation的影响）之后，就只剩下当下时刻的innovation带来的影响了。</p><p>如果<span class="math inline">\(\psi\)</span>的逆存在，那么原始的ma过程等价于ar过程。即一个随机过程，既可以表达为从历史innovation中收集能量的过程，也可以表达为，对历史观测值中剔除能量的过程，观测值的系数就是自回归系数。</p></li><li><p>经典的时序分析模型ARMA(p, q) 表示，对观测变量的多项式滞后操作+对噪声的多项式滞后操作，噪声<span class="math inline">\(\eta_t\)</span>是一个维纳过程</p></li><li><p>随机游走就是一个一阶自回归模型，但是非平稳.</p></li><li><p>自回归模型如果满足，特征方程的p个根（复数），都在单位元外面，该随机过程是平稳的。本质上是对回归函数的逆函数施加的收敛性约束。</p></li><li><p>如何对非平稳随机过程建模？先差分，那几个非平稳的例子验一验，比如随时间线性增长+白噪声，再比如</p></li><li><p>金融数据大部分都是非平稳的，像随机游走，box和jenkins想出来了一种移除非平稳趋势的方法--差分</p></li><li><p>平稳性测试：H0是平稳的，检验方法有KPSS测试</p><p>非平稳性测试，H0假设是非平稳的，常用来检测非平稳性的方法单位根检验方法，例如Dickey-Fuller测试</p></li><li><p>DF测试是一种单位根检测，它的流程是这样的，先假设随机过程服从AR（1）模型，拟合一个AR（1）的模型，然后定义一个根<span class="math inline">\(\phi\)</span>相关的统计量，</p><ol type="1"><li>如果 <span class="math inline">\(\phi=1\)</span>, 那就应该观察到t服从一个DF分布，对应的随机过程就是是随机游走，是一个非平稳的随机过程。</li><li>如果<span class="math inline">\(|\phi|=1\)</span>,那么估计量和真实<span class="math inline">\(\phi\)</span>的差值就近似一个正态分布，以真实<span class="math inline">\(\phi^2\)</span>为方差。</li></ol></li></ol><h2 id="附录">附录</h2><ol type="1"><li><p>相关系数：两个随机变量标准化到均值=0，方差=1之后的，求协方差。</p></li><li><p>wold representation定理</p><figure><img src="./image-20210715091517366.png" alt="wold representation" /><figcaption aria-hidden="true">wold representation</figcaption></figure></li></ol><h3 id="representation定理">representation定理</h3><p>使用滞后算子表述representation定理</p><figure><img src="./image-20210715101032432.png" alt="image-20210715101032432" /><figcaption aria-hidden="true">image-20210715101032432</figcaption></figure><h3 id="representation定理的应用--估计时间序列背后的分布">representation定理的应用--估计时间序列背后的分布</h3><p>表示定义的应用-给定一个时间序列，希望确定背后的分布：</p><ol type="1"><li><p>假设：背后的随机过程由两部分构成，历史信息 + 白噪声，历史信息是过去p段时间的信息的线性变换，白噪声是的平稳的随机过程</p></li><li><p>参数估计：使用最小二乘估计出线形变换</p></li><li><p>模型诊断：基于假设+数据，推断出一些其他的统计量，将这些统计量带回假设，检验一致性。</p><blockquote><p>观测值减去历史信息，就是白噪声的观测值，接下来检测，这个白噪声是否如step1的 假设所描述</p></blockquote><ol type="1"><li>正交性检验：测试白噪声是否跟p个变量的相关性为0，不为0的话，就要将p的值变大，重新做实验。</li><li>检验是否是白噪声 : 不是白噪声的话，要么调整ma模型，要么在线性变换中加入更多的lag项，或者其他的确定性变量</li></ol></li></ol><figure><img src="./image-20210715095528794.png" alt="image-20210715095528794" /><figcaption aria-hidden="true">image-20210715095528794</figcaption></figure><h3 id="arma模型">ARMA模型</h3><figure><img src="./image-20210715140721430.png" alt="image-20210715140721430" /><figcaption aria-hidden="true">image-20210715140721430</figcaption></figure><ol start="3" type="1"><li><p>AR（p）模型的平稳条件：</p><figure><img src="./image-20210715145052508.png" alt="image-20210715145052508" /><figcaption aria-hidden="true">image-20210715145052508</figcaption></figure></li><li><p>yuler walker方程：AR（P）的协方差<span class="math inline">\(\gamma\)</span>和<span class="math inline">\(\phi\)</span>满足的某个方程</p></li><li><p>有了协方差矩阵的估计量，求yuler walker方程，就可以得出AR（p）的p个参数，再就可以算出波动率。</p></li><li><figure><img src="./image-20210715153433604.png" alt="image-20210715153433604" /><figcaption aria-hidden="true">image-20210715153433604</figcaption></figure><ol type="1"><li>使用原始的p阶自回归过程，</li></ol></li></ol><h2 id="参考">参考</h2><ol type="1"><li><p><a href="https://www.youtube.com/watch?v=uBeM1FUk4Ps&amp;t=362s">Time Series Analysis I--youtube</a></p></li><li><p><a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/">Time Series Analysis---slide</a></p></li><li><p><a href="https://ocw.mit.edu/courses/mathematics/18-s096-topics-in-mathematics-with-applications-in-finance-fall-2013/">Topics in Mathematics with Applications in Finance-open course</a></p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;随机过程，由一系列按照时间排序的随机变量组成。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;序列的随机行为，由概率密度函数定义，如果能穷举出所有finite时间索引集合的概率分布，就可以确定该随机过程。&lt;/p&gt;</summary>
      
    
    
    
    <category term="时间序列" scheme="https://chiechie.github.io/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    
    <category term="最佳实践" scheme="https://chiechie.github.io/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    
    <category term="人工智能" scheme="https://chiechie.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    <category term="时序预测" scheme="https://chiechie.github.io/tags/%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B/"/>
    
    <category term="量化交易" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93/"/>
    
  </entry>
  
  <entry>
    <title>数据结构2 非线性数据结构</title>
    <link href="https://chiechie.github.io/2021/07/11/data_structure/ds2-nonelinear-data-structure/"/>
    <id>https://chiechie.github.io/2021/07/11/data_structure/ds2-nonelinear-data-structure/</id>
    <published>2021-07-11T05:20:51.000Z</published>
    <updated>2021-07-13T08:06:37.443Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结">总结</h2><ol type="1"><li>非线形数据结构包括堆，Union Find或者disjoint set。</li></ol><h2 id="堆和优先队列">堆和优先队列</h2><ol type="1"><li><p>优先队列（priority queue）是什么？优先队列是一个抽象数据类型（ADT），跟一般的normal很类似，除了一点，优先队列中的每个元素都有固定的优先级，优先级越高的元素，越先出队（dequeue）。</p></li><li><p>注意，优先队列只能存储可比较的数据。</p></li><li><p>优先队列出队（poll）是如何找到最优先的成员的？借助堆（heap）。</p></li><li><p>优先队列通常是使堆实现，因为对优先队列进行操作时，使用堆构造的优先队列时间复杂度最低。除了堆还有别的数据结构也可以实现优先队列，例如一个无序的链表，但是时间复杂度较高。</p></li><li><p>堆（heap）是什么？ 堆是一个基于树的数据结构，它满足堆不变性质（也叫堆属性）：堆中的所有的父节点的优先级都大于或者孩子节点的value。最大堆（max heap）是指，父节点的value都大于等于孩子节点。最小堆（min heap）是指，小于或者等于。</p><p><img src="./image-20210711093249240.png" /></p></li><li><p>什么时候需要使用优先队列？在图算法中会经常用到</p><ol type="1"><li>最短路径搜索算法--Dijkstra;s</li><li>动态获取下一个最好的或者最差的元素</li><li>huffman编码（无损数据压缩）</li><li>图遍厉中的Best优先搜索算法，例如A*，使用优先队列持续获取下一个最有潜力的节点</li><li>最小生成树（Mininum Spannning Tree， MST）算法中会用到。</li></ol></li><li><p>将最小优先队列转换为最大优先队列：很多编程语言的标准库只提供最小优先队列的抽象数据类型，即按照值越小，优先级越高，但是实际应用中我们也会需要用到最大优先队列。如何使用已有的最小优先队列来满足我们构造最大优先队列的需求呢？将元素的值取相反数，然后使用最小优先队列排序。</p></li><li><p>堆又很多种，binary heap/binomial heap等，最常用的堆是<strong>二叉堆</strong>（binary heap）。二叉堆是一个二叉树，并且支持堆不变性，二叉树中，每个节点都有2个孩子。</p></li><li><p>完全二叉树：除了最后一层，每一层都是完全填充的，并且节点都会尽量往左边排。完全二叉树在数据插入的时候很有用</p><p><img src="./image-20210711100432168.png" /></p></li><li><p>怎么表示二叉堆？--数组。</p></li></ol><p><img src="./image-20210711102017358.png" /></p><ol start="11" type="1"><li><p>找到某个节点的父亲节点和孩子节点，利用左下方的公式计算相应的父节点/子节点的索引，然后去数组查找该索引对应的取值。 <img src="./image-20210711102047154.png" /></p></li><li><p>在二叉堆中添加元素：先将该元素添加到最后一层的，最后一个节点的右边，然后不断的使用冒泡的方法，跟父亲节点互换位置,</p></li><li><p>从二叉堆中删除顶端元素，时间复杂度为O（logn），从二叉堆中删除某个值的元素，时间复杂度为O(n), 因为时间花在找到这个元素上面了。</p></li><li><p>有没有办法可以提升查找二叉堆中某个元素速度的方法呢？hash table，即提前将value和索引pair存到一个table中，要搜索的时候去查这个table就好了。这个表叫哈希表（hashtable）， key是hash（value），value是索引。如果有多个相同的值，就存成一个index set</p><p><img src="./image-20210711104111050.png" /></p></li></ol><h2 id="union-find">Union-Find</h2><ol type="1"><li><p>Union-Find 也叫非连通集合（disjoint set），也是一种数据结构，主要操作是find 合uninion</p><ol type="1"><li><p>find：给定一个element，union find 返回该element所属的group</p></li><li><p>uninon：merge 2 groups，将其中一个group的root变为另外一个group的root的子节点</p><p><img src="./image-20210711110158015.png" /></p></li></ol></li><li><p>union find在哪里会被用到？最小生成树算法--kruskal：</p><p><img src="./image-20210711110757010.png" /></p></li><li><p>Union find这个数据结构可以使用hashtable + 数组实现</p><p><img src="./image-20210711115717168.png" /></p></li><li><p>union find 应用之--path压缩, 每次union的时候，将属于某个pattern的所有节点全部指向root</p></li></ol><h2 id="二叉树-和-二叉查找树">二叉树 和 二叉查找树</h2><ol type="1"><li><p>树是什么？一个无向图，无环的连通图，有N个节点，N-1条边</p></li><li><p>树中任意一个节点都能成为一个root节点。</p></li><li><p>子树（subtrees）可能是一个叶子结点</p></li><li><p>二叉树：是一种特殊的树，树中每个节点最多只有2个子节点。</p></li><li><p>二叉查找树（binary seach tree）是一种特殊的二叉树，树中的所有子树都满足二叉查找树不变性（BST invariant），即左边的树更小，右边的树更大。</p></li><li><p>二叉查找树有什么用？</p><ol type="1"><li>可以实现很多抽象的数据类型。例如map，set</li><li>可以用来实现平衡二叉查找树（balanced binar用search trees）</li><li>实现语法树：编译器和计算机会用到</li><li>Treap--一个基于概率的数据结构，使用了一个随机的二叉搜索树。</li></ol></li><li><p>如何在二叉查找树中插入一个元素？二叉查找树要求元素可比较大小，先查找插入位置，然后插入，注意这是一个贪婪的对此迭代的过程，总共有4种位置以及对应的行动</p><ol type="1"><li>if 插入值&lt; case: recurse down 左子树</li><li>if 插入值&gt; case:recurse down 右子树</li><li>if 插入值== case: do something</li><li>if 无节点可供插入值比较:的创建一个新的节点</li></ol></li><li><p>平均来看，在二叉查找树种插入一个元素需要对数时间，在最坏情况下（如下图， 需要平衡二叉搜索树），插入一个元素退化为线性时间，</p><figure><img src="./image-20210712095559490.png" alt="image-20210712095559490" /><figcaption aria-hidden="true">image-20210712095559490</figcaption></figure></li><li><p>在二叉查找树中删除一个元素的步骤：</p><ol type="1"><li><p>找到元素在树种的位置：</p><ol type="1"><li>使用贪婪算法从根节点点开始持续查找，当我们找到一个null戒电视，迭代结束，意味着这个二叉树中没有这个元素。</li><li>每遍历到一个点，比较当前值和value的大小，当相等时，返回；当value小于该节点时，去左子树继续找；当value=该节点时，去右子树继续找。</li></ol></li><li><p>找到了二叉查找树种想删除节点，要删除该节点了，也面临4种情况：这个节点在是叶子结点；这个节点只有右子树；这个节点只有左子树；既有左子树又有右子树。</p><figure><img src="./image-20210712100625802.png" alt="image-20210712100625802" /><figcaption aria-hidden="true">image-20210712100625802</figcaption></figure><ul><li>叶子节点直接删除，节点只有一个子树的，将子树顶上来</li><li>最复杂的是被删除的节点有两个子树，可以找左子树的最大的节点/右子树最小的节点，将这个值 复制到root（上图中的⭕️），注意 左子树的最大的节点/右子树最小的节点 是左子树最右边路径的叶子，是右子树最左边路径的叶子，删除该节点的操作必然输入case1/2/3的一种，即这个节点最多包含一个子树。</li></ul></li></ol></li></ol><h2 id="fenwick树todo">Fenwick树【todo】</h2><h2 id="平衡二叉查找树todo">平衡二叉查找树【todo】</h2><ol type="1"><li>一个平衡二叉查找树是一个自平衡二叉叉招数，这个树会调整自己的顺序，以保持一个低的层数，允许更快速的操作，例如插入和删除。</li><li>相对二叉查找树，一般情况下，增删改查的平均时间复杂度是对数级别，最坏情况下，二叉查找树时间复杂度是线性的，平衡二叉查找树的时间复杂度还是非线形的。</li><li>平衡二叉树的秘密配方：树不变性；树的翻转（rotation）。</li></ol><p>【如何操作？】</p><h2 id="树遍历算法">树遍历算法</h2><ol type="1"><li><p>树遍历的三个算法：先序遍历(preorder traversal)，中序遍历（inorder traversal）后序遍历（postorder traversal）。递归调用，开始遍历到一个节点，将这个节点入栈，该节点遍历完，出栈。</p></li><li><p>先序遍历(preorder traversal)：先打印当前节点的值，再开始遍历左右节点。top down</p><figure><img src="./image-20210712105721400.png" alt="image-20210712105721400" /><figcaption aria-hidden="true">image-20210712105721400</figcaption></figure></li><li><p>中序遍历（inorder traversal）：把左子树遍历完，打印当前值，开始遍历右子树。bottom up， 块状优先</p><figure><img src="./image-20210712105759814.png" alt="image-20210712105759814" /><figcaption aria-hidden="true">image-20210712105759814</figcaption></figure></li><li><p>后序遍历（postorder traversal）：遍历完子节点后，打印当前节点的值，bottem up的方式。</p><figure><img src="./image-20210712105840283.png" alt="image-20210712105840283" /><figcaption aria-hidden="true">image-20210712105840283</figcaption></figure></li><li><p>level order 遍历，需要广度优先搜索(Breadth First Search) 以top down的方式遍历</p></li><li><p>怎么实现广度优先搜索(Breadth First Search)?</p><ol type="1"><li>构造一个队列，放置当前待访问的节点。初始值是root，</li><li>每访问一个节点，让这个节点出列（dequeue），将该节点的所有子节点入列（enqueue）。</li><li>直到访问到最后一层，只dequeue没有enque，queue变为空时，就访问完成</li></ol></li></ol><h2 id="哈希表">哈希表</h2><ol type="1"><li><p>hash函数是什么？就是一个函数，它把key映射为固定范围内的一个数。key可以是string，list等多种类型</p></li><li><p>hash函数的属性，value不同对应的key一定不相同，key相同对应的value一定相同。</p></li><li><p>key是什么都可以，只要是唯一值就可以了，value可以存任何值，例如存储一篇文章中，所有单词出现的次数。</p></li><li><p>hash函数需要解决哈希冲撞（hash collision）的问题，有两个方法</p><ol type="1"><li><p>separate chaining： 维护一个单独的数据结构例如链表（数组，二叉树，自平衡二叉树都行），把一个value对应的多个key存到一起。separate chaining是最常用的方法。</p></li><li><p>公开地址（open addressing）：需要关注哈希表的负载，需要hash value已经占用的话，就找一个未被占用的slot（怎么找？需要构造一个概率函数），把key存进去</p><blockquote><p>概率函数probing function）有时候会陷入死循环，更合适的做法是找一个值域超过N的函数 作为概率函数。</p></blockquote></li></ol></li><li><p>哈希表是一个数据结构，提供key到value的映射，映射规则是hashing</p></li></ol><h2 id="后缀数组">后缀数组</h2><ol type="1"><li><p>后缀（suffix）一个字符串的尾端的子字符串。</p></li><li><p>后缀数组（suffix array）是一个数组，由一个字符串的所有后缀组成，成员个数为字符串长度。</p></li><li><p>后缀数组比后缀树在空间上更优，功能上比后缀树还多一点信息--LCP数组。</p></li><li><p>最长公共前缀(LongestCommonPrefix, LCP)是一个数组，每个值记录两个相邻（按照首字母排序）后缀子串的有多少个相同的字符。</p><figure><img src="./image-20210713113655458.png" alt="image-20210713113655458" /><figcaption aria-hidden="true">image-20210713113655458</figcaption></figure></li><li><p>有很多方法可以构造LCP向量</p></li><li><p>怎么计算一个字符串包含的所有的字符子串，要去重：</p><figure><img src="./image-20210713122803380.png" alt="image-20210713122803380" /><figcaption aria-hidden="true">image-20210713122803380</figcaption></figure></li><li><p>后缀数组的应用之--查找最长的公共字符子串</p><h2 id="带索引的优先队列todo">带索引的优先队列[todo]</h2><p>Indexed Priority Queue</p></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=RBSGKlAvoiM&amp;t=11600s">Data Structures Easy to Advanced Course - Full Tutorial from a Google Engineer</a></li><li><a href="https://github.com/akzare/Algorithms">Algorithms &amp; data structures project</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;非线形数据结构包括堆，Union Find或者disjoint set。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;堆和优先队列&quot;&gt;堆和优先队列&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;优先队列（</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="编程" scheme="https://chiechie.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>SVD和compression</title>
    <link href="https://chiechie.github.io/2021/07/10/math/svd-and-coding/"/>
    <id>https://chiechie.github.io/2021/07/10/math/svd-and-coding/</id>
    <published>2021-07-10T03:40:31.000Z</published>
    <updated>2021-07-22T00:53:04.020Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>大矩阵怎么存？最简单的方式就是矩阵分块, 然后分chunk存/读/算，下一个chunk覆盖上一个chunk，始终占用一个chunk的内存。</p><p>如果还想去噪，可以用svd，下面推演一下用svd可以节省多少空间</p></blockquote><p>SVD技术可以应用于信号压缩</p><p>SVD是这样的, 随意一个矩阵A可以做如下分解</p><p><span class="math display">\[A = U\Lambda V^T\]</span>==&gt;<span class="math display">\[U^T A = \Lambda V^T  \]</span></p><p>可以把<span class="math inline">\(U^T\)</span>看成是encoding, <span class="math inline">\(U\)</span>看成是decoding, 压缩之后的信号是<span class="math inline">\(\Lambda V^T\)</span></p><figure><img src="./奇异值分解.png" alt="奇异值分解" /><figcaption aria-hidden="true">奇异值分解</figcaption></figure><p>detail</p><p>假设<span class="math inline">\(A \in R^{n*m}, U\in R^{n*n}, \Lambda \in R^{n*m}, V \in R^{m*m}\)</span></p><p><span class="math inline">\(\Lambda\)</span>中的元素从大到小排列，前面k个元素绝对值大于0</p><p>对三个矩阵分块，图中的阴影部分是我们要存储的部分</p><p><span class="math display">\[\Lambda = [\Lambda_k, \mathbf{0_{m-k}}], \Lambda_k \in R^{n * k}, \Lambda_{(m-k)} \in R^{n * (m-k)}\]</span></p><p><span class="math display">\[V = [ \mathbf{v_k},  \mathbf{v_{m-k}}],  \mathbf{v_k} \in R^{m*k},  \mathbf{v_k} \in R^{m*(m-k)} \]</span></p><p><span class="math display">\[\Lambda V^T = [\Lambda_k, \mathbf{0_{m-k}}].[v_k, v_{m-k}]^T = \Lambda_k.v_k^T \]</span></p><p>经过U做encoding之后的信息仅有 <span class="math inline">\(\Lambda_k\)</span>和<span class="math inline">\(v_k\)</span></p><p>其中<span class="math inline">\(\Lambda_k\)</span>可以存为稀疏矩阵，含k个非零元素</p><p><span class="math inline">\(v_k \in R^{m*k}\)</span>占用空间m*k</p><p>U做类似的分解占用空间n*k</p><p>一起需要存储的元素个数为<span class="math inline">\(k + m*k + n*k\)</span></p><p>不做encoding的话，需要存储m * n 个元素</p><p>总结一下:用了压缩算法之后，空间复杂度从O(n*m)降低到O(m)或O(n)</p><p>当m,n很大，又很容冗余信息（k很小），svd分解能大量降低矩阵存储空间</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;大矩阵怎么存？最简单的方式就是矩阵分块, 然后分chunk存/读/算，下一个chunk覆盖上一个chunk，始终占用一个chunk的内存。&lt;/p&gt;
&lt;p&gt;如果还想去噪，可以用svd，下面推演一下用svd可以节省多少空间&lt;/p&gt;
&lt;/blockquo</summary>
      
    
    
    
    <category term="数学" scheme="https://chiechie.github.io/categories/%E6%95%B0%E5%AD%A6/"/>
    
    
    <category term="SVD" scheme="https://chiechie.github.io/tags/SVD/"/>
    
    <category term="信息论" scheme="https://chiechie.github.io/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    
    <category term="效率" scheme="https://chiechie.github.io/tags/%E6%95%88%E7%8E%87/"/>
    
  </entry>
  
  <entry>
    <title>数据结构1 线性数据结构</title>
    <link href="https://chiechie.github.io/2021/07/09/data_structure/ds1_linear-data-structure/"/>
    <id>https://chiechie.github.io/2021/07/09/data_structure/ds1_linear-data-structure/</id>
    <published>2021-07-09T04:13:11.000Z</published>
    <updated>2021-07-12T02:50:05.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="总结">总结</h1><ol type="1"><li>数组（array），链表（linked list），栈（stack），队列（queue）是最常用的线性的数据结构。</li><li>数组是一片连续的存储空间中，链表在物理空间中不是连续地存在一起的。</li></ol><h1 id="通用的数据结构">通用的数据结构</h1><h2 id="数组array">数组(array)</h2><ol type="1"><li><p>数组是一个很基本的数据结构，使用数组和pointer可以构建出所有的数据结构</p></li><li><p>数组分为静态数组（static array）和动态数组（dynamic array）两种.静态数组大小固定，动态数组可以扩展。</p><blockquote><p>wangshusen的视频里面分别叫array和向量vector，下面还是以动/静为标准。</p></blockquote></li><li><p>静态数组(static array)是一个固定长度的容器（container），包含了n个元素，每个元素有一个索引，索引值从[0,n-1]</p></li><li><p>动态数组（dynamic array）的大小可以增加或者减少。</p></li><li><p>indexable是什么意思？数组中的每一个槽位(slot)/索引(index)，都能关联到（be referenced with）一个数字。索引就好像给每个元素取的名字，是一个阿拉伯数字。</p></li><li><p>静态数组是存储在内存中的一片连续的区域。</p></li><li><p>什么时候使用静态数组：</p><ul><li>依次（sequentially）存储元素/读取（accessing）元素</li><li>在读入/输出流式数据的时候，一次性读入数据量太大，所以分chunk读入数据，并且用buffer去读取每个chunk的数据，buffer就是用array实现的</li><li>在lookuptable中，也会用到数组，因为可以按照index读取数据</li><li>如果某个函数只允许返回1个，但是有多个信息需要返回，可以使用array构造一个workaround，将多个信息打包成一个array，然后返回这个array的指针或者reference</li><li>动态规划：用于缓存子问题的answer，例如背包问题（knapsack problem）和 应变变换问题。</li></ul></li><li><p>静态数组和动态数组的时间复杂度</p><ul><li>读取的时间复杂度: 都是O(1)，因为数组是indexable的</li><li>查找的时间复杂度：都是O（n），有可能查找的值找不到</li><li>插入某个元素的时间复杂度：静态数组不允许插入（记住，他是一个长度固定的容器），动态数组插入的时间复杂度是O（n）- 添加的时间复杂度：</li><li>删除：</li></ul></li><li><p>获取静态数组中元素的唯一方式，就是通过index去reference（数组的成员只对外暴露他们的index编号）。</p></li><li><p>operations on 动态数组：静态数组上能做的操作，动态数组都能做，还能做的更多，比如增，删。</p></li><li><p>怎么实现一个动态数组？</p><ul><li>方法1--使用静态数组实现：<ul><li>初始化：创建一个静态数组，有一个初始容量，此后一遍增加元素一遍跟踪容器中元素的个数。</li><li>添加新元素时，如果容器没满，直接加入； 如果容器满了，自动扩容--创建一个新的静态数组，大小为当前容量的2倍，将老的静态数组的元素复制到新的静态数组中，然后加入该元素。</li></ul></li></ul></li></ol><h2 id="链表linked-list">链表(linked list)</h2><ol type="1"><li>链表上相邻的元素在物理存储上并不是相邻的，每个元素的物理未知只存在于他的上下游节点中。</li><li>链表分为单链表（singly linked lists）和双链表(doubly linked lists）。</li><li>按顺序查找链表也很快。</li><li>链表是一种数组的组织形式，将数据组织成一个有序的一系列节点（nodes）的形式，每个节点（node）代表一个数据，每个节点都指向其他代表数据的节点。</li><li>下面是一个单链表（singly linked），每个节点都包含一个数据，同时包含一个指针，指向他的邻居节点。最后一个节点的指针是空的。</li></ol><p><img src="img.png" alt="img.png" /> 6. 在哪里会用到链表？ - 需要实现某个抽象数据类型时会用到链表，比如要实现列表（lists），队列（Queue）和 栈（Stack），因为这些抽象数据类型需要频繁操作adding和remocving，而这两个操作对于链表来说是相当拿手的。 - 链表很容易对现实事物建模，如火车 - 创建循环列表时很有用，可以让链表的最后一个节点的指针指向第一个节点，训练列表对于建模重复事件循环很有用， - 实现哈希表通常使用链表处理冲突的问题。 7. 链表的几个关键元素： - head：指向链表的第一个节点的pointer， - tail：指向表示链表的最后一个节点的pointer， - pointer表示邻居节点的指针， - node：表示一个包含数据和指针的对象。在实现时，每个节点也可以被表示为structures，或者classes 8. 单链表和双链表的区别，单链表的每个节点只存储下一个邻居的pointer，双向链表的每个节点存储两个指针，分别是上一个邻居节点和下一个邻居节点。前者占用的内存是后者的1/2，缺点是不知道当前节点的前一个节点是什么，要找的话，只能从head开始遍历。如果要删除某个元素，双链表的时间复杂度是常数，单链表是线性的，因为他要重新遍历以找到上家，然后修改它的指针。 <img src="img_1.png" alt="单链表vs双链表-优缺点对比" /> 9. 链表中，同时存链表的第一个节点和最后一个节点，是为了更快速的添加和删除元素。 10. 链表中的复杂度分析： - 搜索某个值在链表中的位置：单链表和双链表的复杂度是O(n) - 在链表头部/尾部插入某个元素：单链表和双链表的复杂度是O(1) - 删除头部的元素：单链表和双链表的复杂度是O(1) - 删除尾部的元素：单链表的复杂度O(n)，双链表的复杂度是O(1) - 删除中间元素：单链表的时间复杂度为复杂度O(n)，双链表的复杂度是O(n)</p><h2 id="栈stack">栈（stack）</h2><ol type="1"><li><p>栈是一种线性的数据结构，栈的一端是固定的，跟现实世界中的stack一样，stack有两个主要的操作：入栈（push）和出栈（pop）。</p></li><li><p>栈中有一个top指针指向栈的顶端。以为对栈的操作主要是集中在顶端。</p></li><li><p>数据出栈（pop）和入栈（push）符合后进先出的顺序，也叫LIFO/</p><figure><img src="/Users/shihuanzhao/research_space/chiechie.github.io/source/_posts/data_structure/image-20210711073942878.png" alt="image-20210711073942878" /><figcaption aria-hidden="true">image-20210711073942878</figcaption></figure></li><li><p>可以使用数组或者链表来实现一个栈。</p></li><li><p>什么时候用到栈：括号匹配/撤销操作/汉诺塔/图遍历中的深度优先搜索。（DFS）</p></li></ol><h2 id="队列">队列</h2><ol type="1"><li><p>队列是一个线性的数据结构，有两个主要的操作，入队（enqueue/adding/offering）和出队（dequeue/polling）。入队就是添加数据到队尾添，出队就是删除队头的数据。</p></li><li><p>数据入队和出队，符合后进后出的顺序。（LILO）</p><figure><img src="/Users/shihuanzhao/research_space/chiechie.github.io/source/_posts/data_structure/image-20210711085139955.png" alt="image-20210711085139955" /><figcaption aria-hidden="true">image-20210711085139955</figcaption></figure></li><li><p>queue可以用于对排队场景建模；跟踪最新添加的k个数据；web server请求管理--谁先来就服务谁/图遍历中的广度优先搜索（BFS）。</p></li><li><p>可以用链表来实现队列。</p></li><li><p>使用队列实现BFS。 <img src="./image-20210711091627179.png" alt="image-20210711091627179" /></p></li></ol><h1 id="python中的数据结构">python中的数据结构</h1><ol type="1"><li><p>在python中，list就是一个动态的数组，append有时候效率很低。</p></li><li><p>在python中，collections.deque是一个double-ended queue，两端固定的队列，基于双向链表实现的插入效率更高一些。但是按照序号查找某个元素，效率不高。</p></li><li><p>在python中怎么实现一个栈？</p><ol type="1"><li>使用python内置的对象list，其自带的append和pop方法可以实现push和pop</li><li>使用collections.deque，其自带的append和pop方法可以实现push和pop</li></ol></li></ol><h1 id="参考">参考</h1><ol type="1"><li><a href="https://github.com/akzare/Algorithms">algorithm-python-github</a></li><li><a href="https://www.youtube.com/watch?v=gXgEDyodOJU">youtube</a></li><li><a href="https://www.youtube.com/watch?v=V_TulH374hw">Graph-theoretic Models</a></li><li><a href="https://stackoverflow.com/questions/13965757/what-is-the-difference-between-an-abstract-data-typeadt-and-a-data-structure">the difference-between-ADT和DS</a></li><li><a href="https://www.csie.ntu.edu.tw/~htlin/course/dsa21spring/">数据结构和算法</a></li><li><a href="https://www.youtube.com/watch?v=RBSGKlAvoiM&amp;t=102s">Data Structures Easy to Advanced Course</a></li><li>https://realpython.com/how-to-implement-python-stack/#implementing-a-python-stack</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;数组（array），链表（linked list），栈（stack），队列（queue）是最常用的线性的数据结构。&lt;/li&gt;
&lt;li&gt;数组是一片连续的存储空间中，链表在物理空间中不是连续地存在一起的。&lt;/</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="编程" scheme="https://chiechie.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>数据结构0 总览</title>
    <link href="https://chiechie.github.io/2021/07/08/data_structure/ds0_summary/"/>
    <id>https://chiechie.github.io/2021/07/08/data_structure/ds0_summary/</id>
    <published>2021-07-08T01:17:29.000Z</published>
    <updated>2021-07-09T05:37:50.282Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>数据结构是在计算机中存储数据的方法</p><p>一般情况下，精心挑选的数据结构能产生有效的算法</p></blockquote><h2 id="why-数据结构">why 数据结构？</h2><ol type="1"><li>数据结构是对数据的一种组织形式，以方便后续数据被高效地使用。</li><li>数据结构是创建快速高效算法的必要ingredeints，数据结构可以帮助管理和组织数据；让代码看起来更干净。</li><li>数据结构/抽象数据类/程序的关系就好像，使用乐高搭建一个建筑，层层抽象。</li></ol><h3 id="抽象数据类型和数据结构">抽象数据类型和数据结构</h3><ol start="2" type="1"><li>抽象数据类型(Abstract Data Type, ADT)是对数据结构的一个抽象，它只提供接口（interface），数据结构必须遵循该接口（interface），但是这个接口不涉及任何关于实施或者编程语言相关的细节。</li><li>抽象数据类型的数据结构的关系，举个例子，从一个地方A到另一个地方B有很多种方法，可以骑自行车或者走路或者坐火车，前者是抽象数据类型，后者是该抽象数据类型对应的具体的数据结构。</li><li>一个抽象数据类型之定义了数据结构应该实现什么功能，应该有哪些方法，至于方法的实现细节抽象数据类型是不管的。</li><li>举几个抽象数据类型和数据结构的例子<ul><li>抽象数据类型列表（list）可以使用动态数组或者链表实现，这两个数据结构都能实现add，removing，indexing元素。</li><li>抽象数据类型队列（Queue）可以使用Linked list based Queue/Array based Queue/Stack based Queue。</li><li>抽象数据类型（Map）可以使用Tree Map/Hash Map/Hash Table实现</li></ul></li><li>ADT is a logical description and data structure is concrete.</li><li>ADT is the logical picture of the data and the operations to manipulate the component elements of the data.</li><li>Data structure is the actual representation of the data during the implementation and the algorithms to manipulate the data elements.</li><li>ADT is in the logical level and data structure is in the implementation level.</li></ol><h3 id="计算复杂度分析">计算复杂度分析</h3><ol type="1"><li><p>为了分析我们的数据结构的性能：执行该算法需要花费多少时间和占用多少内存？</p></li><li><p>O(*)表示在worst case的情况下，一个算法复杂度上界是多少，当输入数据变得很大的时候，有助于评估性能, 一般来说有这么几种时间复杂度:</p><ul><li>常数时间: O(1)</li><li>对数时间： O(log(n))</li><li>线性时间： O(n)</li><li>linearithmix时间: O(nlog(n))</li><li>二次时间： O(n^2)</li><li>三次时间: O(n^3)</li><li>指数时间：O（b^n）</li><li>因子时间: O(n!)</li></ul><p>n表示输入的大小复杂度从低到高。</p></li><li><p>因为O（*）只关注当数据变得足够大的时候，算法的表现，所以算法的实际运行时间中的常数项，低阶项都可以省掉，系数都可以扔掉哦。 <span class="math inline">\(O(n + c) = O(n)\)</span> <span class="math inline">\(O(cn ) = O(n)\)</span> <span class="math inline">\(O(n^2 +2*n) = O(n^2)\)</span></p></li><li><p>二分查找是用在一个有序数组上的查找算法，时间复杂度是对数</p></li><li><p>找一个集合的所有子集-时间复杂度是指数O(2^n)</p></li><li><p>找一个字符串的所有排列O(n!)</p></li><li><p>使用合并排序算法来排序，时间复杂度是 O(nlogn)</p></li></ol><h2 id="数据结构有哪几种">数据结构有哪几种？</h2><ol type="1"><li><p>数据结构分为线性数据结构和非线性数据结构</p></li><li><p>线性数据结构包括数组（array），链表（linked list），栈（stack），队列（queue） <img src="b3728c27302a8548fe9e8a87e619ca83.png" alt="线性数据结构" /></p></li><li><p>非线性数据结构包括树和图,树可以认为是有向图的special case <img src="e6d5a8d9a75587abe612dfef9abffc01.png" alt="非线性数据结构" /></p></li><li><p>图分有向图和无向图 <img src="18c651092d22c7204021d10a5a79b0ff.png" alt="有向图vs无向图" /></p></li><li><p>无向图的一个实例是fb的社交网络，边表示好友关系。 <img src="f3fc896014d62fb1ec1c96c93210f7ff.png" alt="社交网络" /></p></li><li><p>基于社交网络这个数据结构有什么应用呢？好友推荐, 推荐朋友的朋友,网络社会科学的小世界</p><blockquote><p>小世界网络的重要性质：“流行病学”、“合作”、“知识”</p></blockquote></li><li><p>有向图的一个实例是万维网： <img src="b9b97250ce6e998045dcbb0d5b379724.png" alt="www" /></p></li><li><p>图还可以分有权图和无权图。无权图可认为是权图的special case，权重都为1。</p></li><li><p>有权图的一个实例是高速公路网,边代表距离 <img src="5b81b50b2d2b048ed3188b71af85a02f.png" alt="公路网" /></p></li><li><p>树的一个实例是家谱，树种，任意一对节点，有且只有一条通路（不存在loop嘛）</p></li><li><p>因果图是一个有向有权图。</p></li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://github.com/williamfiset/Algorithms">algorithm-github</a></li><li><a href="https://www.youtube.com/watch?v=gXgEDyodOJU">youtube</a></li><li><a href="https://www.youtube.com/watch?v=V_TulH374hw">Graph-theoretic Models</a></li><li><a href="https://stackoverflow.com/questions/13965757/what-is-the-difference-between-an-abstract-data-typeadt-and-a-data-structure">the difference-between-ADT和DS</a></li><li><a href="https://www.csie.ntu.edu.tw/~htlin/course/dsa21spring/">数据结构和算法</a></li><li><a href="https://www.youtube.com/watch?v=RBSGKlAvoiM&amp;t=102s">Data Structures Easy to Advanced Course</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;数据结构是在计算机中存储数据的方法&lt;/p&gt;
&lt;p&gt;一般情况下，精心挑选的数据结构能产生有效的算法&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;why-数据结构&quot;&gt;why 数据结构？&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;数据结构是对</summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="图数据" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE/"/>
    
    <category term="编程" scheme="https://chiechie.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>《Advances in Financial Machine Learning》读书笔记3 回测</title>
    <link href="https://chiechie.github.io/2021/07/07/AFML/AFML3/"/>
    <id>https://chiechie.github.io/2021/07/07/AFML/AFML3/</id>
    <published>2021-07-07T03:08:30.000Z</published>
    <updated>2021-07-19T03:51:56.346Z</updated>
    
    <content type="html"><![CDATA[<h2 id="chapter-10-仓位大小">chapter 10 仓位大小</h2><blockquote><p>即使股价预测很准，但是仓位配置的不当，还是会亏钱。</p></blockquote><ol type="1"><li><p>假定三期股价为 [1, 0.5, 1.25]，仓位1: [0.5, 1, 0] &amp; 仓位2: [1, 0.5, 0]，则前者挣钱而后者亏钱。这种情况下，更偏好这样的下注策略：建仓时保留一些现金，如果交易信号加强（股价变为0.5），就追加投资。</p></li><li><p>下图是交易信号(z)和最佳下注大小(m)之间的函数关系：</p><p>横轴的z表示交易信号强弱，纵轴m代表最佳下注大小：<span class="math inline">\(m = x (2Z [z] − 1), m\in{[-1,1]}\)</span></p><p>交易信号z是模型预测结果x的函数，预测结果x越极端，则分母越小，分子绝对值越大， z越接近<span class="math inline">\(+\infty\)</span>或者<span class="math inline">\(-\infty\)</span>，则交易信号越强, 但是可以看到仓位超过一定范围就饱和了。</p><p>总的来说，交易信号越强，下注越大，但是，当交易信号强度超过一定值，就可以不用加仓，最佳持仓水平m可以保持不变，这一点跟直觉是稳和的，价格猛涨多了一段时间之后，再往上走就很难了，这个时候不能追高。</p><figure><img src="./image-20210711134750210.png" alt="image-20210711134750210" /><figcaption aria-hidden="true">image-20210711134750210</figcaption></figure></li><li><p>如果每次预测时，如果交易信号的微小改变就要调仓，那换手率就太高了，作者建议可以对预测结果做滑动平均，或者将下注量离散化（如下图）<img src="./image-20210711140908880.png" alt="image-20210711140908880" /></p></li><li><p>动态BET SIZES 和 限价：当股票的市场价格<span class="math inline">\(p_t\)</span>和预测价格<span class="math inline">\(f_t\)</span>波动时，可用如下方法动态地确定下注量<span class="math inline">\(\hat{q}_{i, t}\)</span>： <span class="math display">\[\hat{q}_{i, t}=\operatorname{int}\left[\frac{x}{\sqrt{w+x^{2}}} \cdot Q\right]\]</span> <span class="math inline">\(x=f_{i}-p_{t}\)</span>为预测价与当前价的差价，如果x绝对值大于0，说明当前市场出现了套利空间，绝对值越大，越要押注，</p></li></ol><p>Q为最大持仓量, <em>𝜔</em>是一个用来控制sigmoid的宽度的系数， <em>𝜔</em>越小，策略就越保守。</p><h2 id="chapter-11-回测有风险">chapter 11 回测有风险</h2><p>回测是量化中最重要但也最容易被误用的工具，本章将介绍回测时容易犯的错误。</p><ol type="1"><li>一个物理实验室可以通过控制变量来探究精确的因果关系，而回测不是实验，它并不能证明一个策略好，只能证明一个策略不好。</li><li>要做好回测极其困难，我们至少会面临这些问题:<ul><li>幸存者偏差：只用现存的股票构建投资组合回测，殊不知过去多少公司倒闭退市了；</li><li>Look-ahead bias：回测时用到的数据在那一刻还没发布；</li><li>事后诸葛亮（各种事后分析都在编故事）；</li><li>手续费：要模拟手续费很难，唯一准确的方式是上实盘；</li><li>空头：实际交易中如何找借方、空头的成本、空头的额度都需要考虑；</li></ul></li><li>即使避免了以上问题，你的回测也可能是错的——在一个数据集上回测了成百上千次才得到的漂亮结果，大概率是假的。如第八章所述，特征重要性分析帮助我们理解 ML 发现的结果，它在回测之前进行，是一种“事前“归因。相反，回测并不能帮我们理解为什么一个策略会盈利。通过回测发现的有效“因子”如同上一期彩票的中奖号码，对下一轮抽奖无益。回测前做好数据结构化、标签、加权比回测本身更重要。</li><li>重复回测带来的过拟合可以认为是一种选择偏差，要避免这种偏差可能是量化中最根本的问题。</li><li>以下步骤可以帮我们减少这种偏差:<ul><li>在多种金融资产上回测：由于金融资产的多样性，如果你发现错误 只存在于债券，那该策略很可能是错的；</li><li>用 bagging 减少过拟合；在完成本书章节1-10 的研究之前别回测；</li><li>记录得到当前结果之前回测了多少次，从而推算出过拟合的可能性；</li><li>假如回测结果没能得到有效的策略，从头开始。千万不要在回测结果的基础上继续研究。 &gt; Backtesting while researching is like drinking and driving. &gt; Do not research under the influence of a backtest.</li></ul></li><li>如果用标准CV回测来选择策略，一些回测路径会重复出现，导致极易过拟合。所以一些随机性非常有必要，例如基于probability of backtest overfitting (PBO) 的回测。</li></ol><h2 id="chapter-12-使用交叉验证做回测">chapter 12 使用交叉验证做回测</h2><p>本章将介绍三种回测方法:向前游走;交叉验证，希望能得到更准确的回测结果。</p><ol type="1"><li><p>向前游走即在回测时，使用历史数据来检验策略的样本外表现，历史数据有两种用法：</p><ol type="1"><li><p>狭义上，模拟策略的历史表现（walk-forward，WF）；</p></li><li><p>广义上，模拟策略在特定市场环境（历史上不一定发生过）中的表现。</p><p>前一种方式更广为人知，但两种方式各有利弊，都应掌握。</p></li></ol></li><li><p>向前游走的优点：</p><ol type="1"><li>有清晰的历史意义，与模拟盘的结果一致；</li><li>测试集在训练集之后，只要正确 purging 后就不存在信息泄露（见第七章）。</li></ol></li><li><p>向前游走的缺点：</p><ol type="1"><li>只有一种情景测试（即历史重演），容易过拟合；</li><li>不足以代表未来的表现，因为回测结果可能受到特定数据的影响而产生偏差；</li><li>回测时数据利用率不高（“most of the information is used by only a small portion of the decisions”）</li></ol></li><li><p>交叉验证（cross-validation）得到一个新策略时，投资者往往想知道这个策略在“非常时期”，如08年金融危机、15年股灾中表现如何。可以将我们希望测试的时期划为测试集，其他时期划为训练集，例如将 2008年作为测试集，2009至今作为训练集。训练集在测试集之后的划分从历史角度来看并不准确（not historically accurate），但通过 CV回测的目的对策略做情景测试（scenarios），从而推断策略在未来的表现。</p></li></ol><blockquote><p>For each period of the backtest, we simulate the performance of a classifier that knew everything except for that period.</p></blockquote><ol start="5" type="1"><li>交叉验证的缺点：<ol type="1"><li>只有一条回测路径（尽管不是历史路径）；</li><li>没有明确的历史意义；</li><li>由于测试集可能位于训练集之前，容易发生信息泄露。</li></ol></li><li>混合purged交叉验证 (CPCV)克服了向前游走和交叉验证的缺点。假定将全数据集分为 N 份，其中 k 份作为测试集，其余作为训练集，则共有<span class="math inline">\(C_N^k\)</span>种划分方案。所有回测路径数 （如下图所示） <img src="./img_2.png" alt="img_2.png" /></li><li>Assignment of testing groups to each of the 5 paths，按照划分依次在训练集上训练、测试集上测试，最后可以计算<span class="math inline">\(\varphi[N, k]\)</span>条路径分别的技术指标（如夏普率），从而更全面地考察模型表现。向前游走和交叉验证，混合purged交叉验证得到的结果（如夏普率）方差小，从而能减少过拟合的可能。</li></ol><h2 id="chapter-13-在合成数据上做回测">chapter 13 在合成数据上做回测</h2><p>本章以 OU 过程为例，说明了如何合成数据并进行回测，也可以尝试其它建模方式。</p><ol type="1"><li><p>使用历史数据生成一个合成数据：先从从真实数据估计得到的分布，然后从分布中采样得到合成数据。</p></li><li><p>使用合成数据去做回测的好处是，可以测试很多次，在unseen的情况下，减少过拟合概率。</p></li><li><p>交易策略假定市场不是有效的，它们用基本面 / 技术面分析试图找到套利机会。</p></li><li><p>交易策略千变万化，但交易规则大同小异：比如策略的信号强于阈值则买入，达到盈利或止损点则卖出，这里的阈值、盈利止损点就是交易规则。如果用合成数据回测来确定交易规则，则过拟合的风险将大大减小。</p></li><li><p>用离散OU过程（discrete O-U process）对资产价格建模，给定资产i当前价格和未来预测价格，其在 t 次交易后的盈亏<span class="math inline">\(\pi_{i,t}\)</span>服从正态分布。可以此为依据模拟价格走势进行实验，得到最佳交易规则，而无需用真实历史数据回测。</p><blockquote><p>OU过程有下面的<a href="https://zh.wikipedia.org/wiki/隨機微分方程">随机微分方程</a></p><p><span class="math display">\[{\displaystyle dx_{t}=-\theta \,x_{t}\,dt+\sigma \,dW_{t}}\]</span></p></blockquote></li><li><p>总而言之，通过探究导致价格波动的随机过程，而不是在真实历史数据上回测，尽管这样得到的交易规则可能不是最优的，但也远好于过拟合的结果。</p></li></ol><h2 id="chapter-14-回测统计">chapter 14 回测统计</h2><ol type="1"><li><p>回测的三种范式：</p><ul><li>历史模拟，向前游走</li><li>情景模拟：交叉验证</li><li>在合成数据上做simulation</li></ul></li><li><p>回测统计量（Backtest statistics）应该帮助揭露策略的弊端（如可能的风险）、帮助投资者比较不同策略。</p></li><li><p>一般统计量（general characteristics）能告诉我们回测的大致特性：时间范围（回测起讫时间）、资产规模（Average AUM） ，策略的资金容量（Capacity）、杠杆率（Leverage）、平均持仓时间（Average holding period）、换手率（Annualized turnover），Maximum dollar position size/Ratio of longs/Frequency of bets</p></li><li><p>衡量策略表现（performance）的统计量包括：盈亏（PnL, Profit and Loss）、多头盈亏（PnL from long positions）、年化回报率（Annualized rate of return）、命中率（hit ratio）、命中回报率（Average return from hits）、失误回报率（Average return from misses）……</p></li><li><p>策略的回报率往往在一段时间内连续为正 / 负，称之为“周期”（Runs）。周期的存在增加了策略回撤的风险，所以需要一些统计量来衡量，包括：Returns Concentration（衡量回报的集中程度）、drawdown（回撤）、time under water。</p></li><li><p>某些策略错误地估计交易费用导致失败，这些需要考虑的统计量包括：Broker fees per turnover、Average slippage per turnover……</p></li><li><p>回测通常看以下指标：</p><ol type="1"><li>绝对收益：净损失/收益（Net Profit/Loss），投资收益率</li><li>剔除通货膨胀的收益：风险调整之后的收益率（risk-adjusted return），市场敞口，波动性（最大回测）</li></ol></li><li><p>一些考虑到风险的统计量包括：夏普率（Sharpe Ratio，SR）、概率夏普比率（Probabilistic SR， PSR）、DSR（Deflated SR）、信息率（Information ratio）……</p><blockquote><p>夏普率衡量的是一项投资在对其调整风险后，相对于无风险资产的表现。</p><p>夏普率 = (投资收益 - 无风险收益)/投资标准差(or波动率）。</p><p>夏普率代表投资者额外承受的每一单位风险所获得的额外收益。</p></blockquote><figure><img src="./image-20210712151844519.png" alt="image-20210712151844519" /><figcaption aria-hidden="true">image-20210712151844519</figcaption></figure><ul><li>Usually, any <strong>Sharpe ratio</strong> greater than 1.0 is considered acceptable to good by investors.</li><li>A <strong>ratio</strong> higher than 2.0 is rated as very good.</li><li>A <strong>ratio</strong> of 3.0 or higher is considered excellent.</li><li>A <strong>ratio</strong> under 1.0 is considered sub-optimal. &gt; Every backtest result must be reported in conjunction with all the trials involved in its production. Absent that information, it is impossible to assess the backtest’s “false discovery“ probability. —— MARCOS’ THIRD LAW OF BACKTESTING</li></ul></li><li><p>基金经理往往希望对模型的收益进行归因（performance attribution），可以参考多因子模型（Barra’s multi-factor method）。</p></li></ol><h2 id="chapter-15-了解策略风险">chapter 15 了解策略风险</h2><ol type="1"><li><p>所有策略都有盈利点和止损点，所以可以对策略的收益建模，检验策略对一些参数的敏感程度。</p></li><li><p>假定一个策略每年进行 n次 IID 决策，每一次有p的概率盈利<span class="math inline">\(\pi\)</span>，1-p的概率盈利<span class="math inline">\(-\pi\)</span>，则该策略的年化夏普比率为：</p><p><span class="math display">\[\theta[p, n]=\frac{2 p-1}{2 \sqrt{p(1-p)}} \sqrt{n}\]</span></p></li><li><p>低频交易：根据上面的公式，如果交易频率n不高，则需要较大的p才能达到高夏普比率。</p></li><li><p>高频交易:：即使p略大于 0.5，只要n足够大，夏普比率也可以很大，这是的思路。</p></li><li><p>策略风险（Strategy risk）和资产组合风险（portfolio risk）,假定<span class="math inline">\(p_{\theta}\)</span>为依照上面公式计算得到的盈亏平衡点</p><ol type="1"><li>策略风险指<span class="math inline">\(P\left[p&lt;p_{\theta}\right]\)</span>,n很大时，p的小幅波动会带来夏普比率的很大改变。比如，p降低 1%可能就会抹去所有盈利。策略风险过大时，即使投资标的的风险不大，这个策略也有较大概率无法超过业绩标准。所以策略研发者需要想办法减小<span class="math inline">\(p_{\theta}\)</span>，比如调节 <span class="math inline">\(\left\{\pi_{+}, \pi_{-}, n\right\}\)</span></li><li>资产组合风险是市场中存在的风险，由首席风险官监控。。</li></ol></li></ol><h2 id="chapter-16-基于机器学习资产配置">chapter 16 基于机器学习资产配置</h2><p>本章提出了基于层次聚类的资产配置方法--层次风险平价方法（Hierarchical Risk Parity ，HRP），稳定性上优于传统的基于二次规划的CLA算法。</p><ol type="1"><li><p>不稳定的传统投资组合方法：马科维茨提出了CLA算法（Critical Line Algorithm），用于求解不等式约束下的二次规划问题，尤其是资产组合优化问题。CLA 的缺点是鲁棒性不高，因为需要对资产间协方差矩阵取逆，资产组合中相关资产（多重共线性）越多，结果越不稳定，这便是 Markowitz’s curse。此外资产越多，用于估计协方差矩阵所需要的数据也越多。</p></li><li><p>层次风险平价方法（HRP）：一种层次聚类的算法，根据资产间相关性将所有资产建构成树状图。</p><blockquote><p>当我们决定投资摩根大通时，更可能考虑增/减持高盛的股票而不是一家地产公司的股票，因为摩根和高盛同属金融企业。<img src="./image-20210719114039467.png" alt="image-20210719114039467" /></p><figure><img src="./image-20210719114115246.png" alt="image-20210719114115246" /><figcaption aria-hidden="true">image-20210719114115246</figcaption></figure></blockquote></li><li><p>实验中 HRP 构建的投资组合比 CLA 更分散，风险也更低，同时HRP 不需要计算逆矩阵，更稳定。</p></li><li><p>HRP 不仅可以用于在不同资产上配置资金，还可用于在不同策略上配置资金。</p></li></ol><h2 id="参考">参考</h2><ol type="1"><li>《Advances in Financial Machine Learning》</li><li>https://blog.csdn.net/weixin_38753422/article/details/100179559</li><li>https://zhuanlan.zhihu.com/p/29208399</li><li>https://zhuanlan.zhihu.com/p/109934805</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;chapter-10-仓位大小&quot;&gt;chapter 10 仓位大小&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;即使股价预测很准，但是仓位配置的不当，还是会亏钱。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;假定三期股价为 [1, 0</summary>
      
    
    
    
    <category term="AFML" scheme="https://chiechie.github.io/categories/AFML/"/>
    
    
    <category term="量化" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>《Advances in Financial Machine Learning》读书笔记1 数据分析</title>
    <link href="https://chiechie.github.io/2021/07/06/AFML/AFML1/"/>
    <id>https://chiechie.github.io/2021/07/06/AFML/AFML1/</id>
    <published>2021-07-06T11:50:44.000Z</published>
    <updated>2021-07-12T00:57:59.690Z</updated>
    
    <content type="html"><![CDATA[<h2 id="chapter-2-金融数据结构">chapter 2 金融数据结构</h2><ol type="1"><li><p>金融数据经常分为4类，基本面数据，市场交易数据，分析数据，另类数据（Alternative） <img src="image.png" alt="img.png" /></p></li><li><p>基本面数据包括公司每个季度发布的会计报告，要注意发布时间和统计时间段的区别。</p></li><li><p>另类数据（Alternative）包括个人数据，商业过程数据，卫星，天气数据。</p></li><li><p>数据处理，为了让ml方法可用，需要将原始数据处理为表数据（bars）。两种处理方法，标准bar methods和信息驱动的方法。第二种在实践中用的多。</p></li><li><p>标准bars方法：将不等间隔处理成等间隔数据，很多数据厂商都是提供这种格式。标准bars方法包括Time Bars，Tick Bars，Volume Bars，Dollar Bars</p><blockquote><p>一个tick表示一次成交事件</p></blockquote></li><li><p>【Tick Bars】每隔多少笔交易采样一次，属于一种基于信息的采样方法，其理论依据是：固定时间内的价格变化服从方差无限大的Paretian分布；固定交易笔数内的价格变化服从高斯分布。</p><blockquote><p>Price changes over a fixed number of transactions may have a Gaussian distribution. Price changes over a fixed time period may follow a stable Paretian distribution, whose variance is infinite. Since the number of transactions in any time period is random, the above statements are not necessarily in disagreement --Mandelbrot and Taylor</p></blockquote></li><li><p>上面的假设很重要，因为很多统计方法的依赖于假设--样本来自IID高斯过程。</p></li><li><p>【Tick Bars】构造tick bars要留意异常点，很多交易所在看盘前和收盘后都有竞价（auction），这段时间，order book 积累 bids 和 offers单，并不撮合（match）。当竞价结束，有一笔数量很大的交易会公开，这一笔交易可等价于成千上万个ticks，虽然现实的是一个tick。</p></li><li><p>【Volume Bars】tick bars的缺陷在于，真实情况下，我们下的一笔单子会被拆分成多笔交易去成交。因此看到的tick比我们实际下的tick变多了。Volume bars可以解决这个问题，他是按照一定证券价值变动的时间段，进行抽样。举个例子，we could sample prices every time a futures contract exchanges 1,000 units, regardless of the number of ticks involved.</p></li><li><p>【Dollar Bars】每隔一段时间，市场上交易价值达到某个给定值（bar size），就进行抽样，the bar size could be adjusted dynamically as a function of the free-floating market capitalization of a company (in the case of stocks), or the outstanding amount of issued debt (in the case of fixed-income securities)</p></li><li><p>tick bars， volumn bars， dollar bars 三者对比： If you compute tick bars and volume bars on E-mini S&amp;P 500 futures for a given bar size, the number of bars per day will vary wildly over the years. That range and speed of variation will be reduced once you compute the number of dollar bars per day over the years, for a constant bar size. 结论是前面两者每天的变动范围和变动速度，要远高于dollar bars <img src="./img_1.png" alt="img_1.png" /></p></li><li><p>信息驱动的bars，目的在于，当有信息到达时，采样更频繁。信息驱动bars有几种方法：Tick Imbalance Bars，Volume/Dollar Imbalance Bars，Tick Runs Bars，Volume/Dollar Runs Bars</p></li><li><p>【Tick Imbalance Bars】背后的想法是只要tick数据超过我们的期望，就去采样。这样设置index，累计的交易信号超过某个阈值，没看懂</p></li><li><p>【Volume/Dollar Imbalance Bars】？</p></li><li><p>【Tick Runs Bars】？</p></li><li><p>【Volume/Dollar Runs Bars】？</p></li><li><p>处理多产品序列：The ETF Trick、PCA Weights，Single Future Roll <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pcaWeights</span>(<span class="params">cov,riskDist=<span class="literal">None</span>,riskTarget=<span class="number">1.</span></span>):</span></span><br><span class="line">    <span class="comment"># Following the riskAlloc distribution, match riskTarget</span></span><br><span class="line">    eVal,eVec = np.linalg.eigh(cov) <span class="comment"># must be Hermitian              </span></span><br><span class="line">    indices = eVal.argsort()[::-<span class="number">1</span>] <span class="comment"># arguments for sorting eVal desc</span></span><br><span class="line">    eVal,eVec=eVal[indices],eVec[:,indices]</span><br><span class="line">    <span class="keyword">if</span> riskDist <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        riskDist=np.zeros(cov.shape[<span class="number">0</span>])</span><br><span class="line">        riskDist[-<span class="number">1</span>]=<span class="number">1.</span> </span><br><span class="line">    loads=riskTarget*(riskDist/eVal)**<span class="number">.5</span> </span><br><span class="line">    wghts=np.dot(eVec,np.reshape(loads,(-<span class="number">1</span>,<span class="number">1</span>))) </span><br><span class="line">    <span class="comment">#ctr= (loads/riskTarget)**2*eVal # verify riskDist </span></span><br><span class="line"><span class="comment"># return wghts</span></span><br></pre></td></tr></table></figure></p></li><li><p>直接让ml预测涨跌很难， after certain catalytic conditions算法会更容易表现好。</p></li><li><p>对特征进行采样的方法-Event-Based Sampling，其中一种方法叫The CUSUM Filter，利用CUSUM可以构造交易策略（Fama and Blume [1966]的filter trading strategy），同事也可以用来采样：当累计收益<span class="math inline">\(S_t\)</span>超过某个阈值时，进行采样，并将<span class="math inline">\(S\)</span>置为0，</p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTEvents</span>(<span class="params">gRaw,h</span>):</span> </span><br><span class="line">    <span class="comment"># gRaw： raw time series</span></span><br><span class="line">    <span class="comment"># h: thresh</span></span><br><span class="line">    tEvents,sPos,sNeg=[],<span class="number">0</span>,<span class="number">0</span> </span><br><span class="line">    diff=gRaw.diff()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> diff.index[<span class="number">1</span>:]:</span><br><span class="line">        sPos,sNeg=<span class="built_in">max</span>(<span class="number">0</span>,sPos+diff.loc[i]),<span class="built_in">min</span>(<span class="number">0</span>,sNeg+diff.loc[i]) </span><br><span class="line">        <span class="keyword">if</span> sNeg&lt;-h:</span><br><span class="line">            sNeg=<span class="number">0</span></span><br><span class="line">            tEvents.append(i) </span><br><span class="line">        <span class="keyword">elif</span> sPos&gt;h:</span><br><span class="line">            sPos=<span class="number">0</span></span><br><span class="line">            Events.append(i) </span><br><span class="line">    <span class="keyword">return</span> pd.DatetimeIndex(tEvents)</span><br></pre></td></tr></table></figure><ol start="19" type="1"><li><span class="math inline">\(S_t\)</span>可以是structural break statistics, entropy, or market microstructure measurement。比如，我们可以定义一个时间，之哟啊r SADF远离之前的取值足够远。</li><li>使用event-based的方法获得了一个子集之后，可以让ml算法来分析，这些特殊事件有没有蕴含一些有值得决策的信息。</li></ol><h2 id="chapter-3-标记">chapter 3 标记</h2><p>在监督学习中，需要输入label，那么在金融领域，如何定义label？ 固定时间范围方法不够准确（可用动态阈值来改进），同时未考虑价格变化的路径，更好的方法是三边界法；此外，元标签能结合各种先验知识，是基金公司做模型、裁员工必备工具。</p><h3 id="固定时间段方法">固定时间段方法</h3><ol type="1"><li>大部分论文都是采用的这个方法，即固定的一段时间收益率是否超过/低于某个取值。 <img src="./img_2.png" alt="img_2.png" /></li><li>虽然大部分人这么用，但是这个方法跟固定时间段采样有一样的毛病，就是固定时间段内的样本并不服从gaussian分布。第二个缺陷是，这个阈值是固定的，无视当前市场波动率的变化，可能会导致错失很多有价值的正样本。</li><li>有更优的标记方法：动态阈值（类似异常检测）和 volume /dollar bars（波动率更固定），</li><li>即使改进了fixed time 和 fixed thresh，还有一个很显现实的问题就是，要考虑到价格路径，如果在半路触发margin call，那么预测得再准也没有用。</li></ol><h3 id="三边界方法the-triple-barrier-method">三边界方法（THE TRIPLE-BARRIER METHOD）</h3><ol type="1"><li>简单说，固定一个窗口，价格先达到上沿就标记1，先达到下沿就标记-1，到窗口结束都被碰到就标记0。</li><li>具体说，首先设置2个水平障碍和1个垂直障碍。2个水平障碍是基于变动的日波动率算出来的，1个垂直障碍是说，离上一次position take，经过了bars的个数。</li><li>如果upper障碍最先触发，返回1；如果lower障碍最先触发，返回-1；如果垂直的障碍触发，返回-1/+1，或者0，具体情况具体分析.三重障碍方法是路径依赖的标记方法。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">applyPtSlOnT1</span>(<span class="params">close,events,ptSl,molecule</span>):</span></span><br><span class="line">    <span class="comment"># apply stop loss/profit taking, if it takes place before t1 (end of event)</span></span><br><span class="line">    events_=events.loc[molecule] </span><br><span class="line">    out=events_[[<span class="string">&#x27;t1&#x27;</span>]].copy(deep=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> ptSl[<span class="number">0</span>]&gt;<span class="number">0</span>:</span><br><span class="line">        pt=ptSl[<span class="number">0</span>]*events_[<span class="string">&#x27;trgt&#x27;</span>] </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pt=pd.Series(index=events.index) <span class="comment"># NaNs</span></span><br><span class="line">    <span class="keyword">if</span> ptSl[<span class="number">1</span>]&gt;<span class="number">0</span>:</span><br><span class="line">        sl=-ptSl[<span class="number">1</span>]*events_[<span class="string">&#x27;trgt&#x27;</span>] </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sl=pd.Series(index=events.index) <span class="comment"># NaNs</span></span><br><span class="line">    <span class="keyword">for</span> loc,t1 <span class="keyword">in</span> events_[<span class="string">&#x27;t1&#x27;</span>].fillna(close.index[-<span class="number">1</span>]).iteritems():</span><br><span class="line">        df0=close[loc:t1] <span class="comment"># path prices df0=(df0/close[loc]-1)*events_.at[loc,&#x27;side&#x27;] # path returns out.loc[loc,&#x27;sl&#x27;]=df0[df0&lt;sl[loc]].index.min() # earliest stop loss. out.loc[loc,&#x27;pt&#x27;]=df0[df0&gt;pt[loc]].index.min() # earliest profit taking.</span></span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure> 3 根据需要，三边界方法也可以有其他合理变体：下边界+右边界：我们会在一定时间后平仓，除非触发止损点提前平仓；上边界+下边界：如果没有触发盈利点和止损点，则一直持有股票；（见下图） <img src="img_4.png" alt="img_4.png" /> 这部分讨论了三边界方法的代码实现，即如何给样本打标签使得 ML 算法可以同时学习到一笔交易的方向和规模</li></ol><h3 id="同时学习方向和规模learning-side-and-size">同时学习方向和规模（LEARNING SIDE AND SIZE）</h3><ol type="1"><li>这种标记可以让ml算法从side和size中学习到一些信息</li><li>如果没有side信息，我们没法区分profit-taking 障碍 和 stop-loss 障碍。</li></ol><h3 id="meta-labeling">META-LABELING</h3><p>假设你有个模型能决定交易方向，你只需要确定交易的规模（包括不交易，即规模为0）。这是金融从业者经常需要考虑的问题，我们确定要买或者卖，唯一的问题是这笔交易值得冒多大风险；同时，我们不需要 ML 模型学习交易方向，只需要它告诉我们合适的交易规模是多少。</p><p>假如有一个基于金融理论的模型，告诉我们交易方向，那我们的标签就变成了 [公式] （ML模型只需要决定是否执行这个操作），而不是 [公式] （ML模型同时决定交易方向和规模）</p><blockquote><p>元标签的含义:</p><p>金融中用ML的另一常见错误是同时学习仓位的方向和大小（据我所知很多论文仅对买/卖方向做决策，每笔交易的金额/股数是固定的）。具体而言，方向决策（买/卖）是最基本的决策，仓位大小决策（size decision）是风险管理决策，即我们的风险承受能力有多大，以及对于方向决策有多大信心。我们没必要用一个模型处理两种决策，更好的做法是分别构建两个模型：</p><ul><li>第一个模型来做方向决策，</li><li>第二个模型来预测第一个模型预测的准确度。很多ML模型表现出高精确度（precision）和低召回率（recall），这意味着这些模型过于保守，大量交易机会被错过。F1-score 综合考虑了精确度和召回率，是更好的衡量指标，元标签（META-LABELING）有助于构建高 F1-score 模型。首先（用专家知识）构建一个高召回率的基础模型，即对交易机会宁可错杀一千，不可放过一个。随后构建一个ML模型，用于决定我们是否应该执行基础模型给出的决策。元标签+ML有以下4个优势：1. 大家批评ML是黑箱，而元标签+ML则是在白箱（基础模型）的基础上构建的，具有更好的可解释性；2. 元标签+ML减少了过拟合的可能性，即ML模型仅对交易规模决策不对交易方向决策，避免一个ML模型对全部决策进行控制；3. 元标签+ML的处理方式允许更复杂的策略架构，例如：当基础模型判断应该多头，用ML模型来决定多头规模；当基础模型判断应该空头，用另一个ML模型来决定空头规模；4. 赢小输大会得不偿失，所以单独构建ML模型对规模决策是有必要的</li></ul></blockquote><blockquote><p>label就是交易信号，表示买或者卖, 两个label 如果是基于相同时间段的收益率 计算出来的，就说是concurrent的.</p></blockquote><h3 id="量化-基本面方法">量化 + 基本面方法</h3><p>THE QUANTAMENTAL WAY</p><p>很多对冲基金——包括一些老牌基金——正在拥抱量化方法。元标签正是这些公司需要的：假设你有了一系列有预测力的特征，你既可以同时预测交易方向和规模；也可以用元标签方法。元标签方法中确定方向的基础模型可以是 ML模型、计量公式、交易规则、基本面分析，也可以是人类基于直觉的预测结果，可见元标签方法的普适性。</p><p>举个例子，元标签方法可能会发现基金经理能及时预测市场风格转换，但无法在疲倦、压力下准确预测。由于基金经理必然会受生理心理等因素影响，元标签方法能评价基金经理的预测能力。综上所述，元标签方法为基金公司的量化之路指明了方向（做模型 &amp; 评价基金经理），它应该成为基金公司的基本工具。</p><h3 id="丢掉不必要的label">丢掉不必要的label</h3><p>it is preferable to drop extremely rare labels and focus on the more common outcomes. 当标签很多且类别不均衡（imbalance）时，一些ML模型表现不好。这种情况下，最好丢掉非常罕见的标签并专注于更常见的结果。这样做有另一个原因，即用bagging方法时罕见的标签可能无法采集到，这是 sklearn 的一个bug，短期难以解决，建议读者写自己的 class，扩展 sklearn的功能。</p><h2 id="chapter-4-样本权重">chapter 4 样本权重</h2><p>训练ML 模型需要抽取样本，本章我们会考虑抽样时如何给样本加权，以更好地训练模型。</p><ol type="1"><li><p>大部分ML算法都是基于IID假设，而金融时序不是IID的，所以大部分ml应用直接套用到金融场景会失败。</p></li><li><p>很多时候数据难免出现交叉（如三标签方法一段数据结束时间不确定），当两段数据出现交叉，标签序列就不再是IID了。这种场景经常出现在非time bars中。 <img src="img_3.png" alt="img_3.png" /></p></li><li><p>对此我们有三种解决方案：一是丢弃重复数据，这会造成信息损失，不推荐；二是根据独特性加权抽样——一段数据与其他数据交叉越少，独特性越高，应该给予更多权重；三是 Sequential Bootstrap，即序列有放回抽样，每抽出一个样本，相应地减少与该样本有重叠的样本被抽取的概率，这样抽取的样本比普通 Bootstrap 更接近 IID。</p></li><li><p>此外，绝对收益率（absolute return）大的样本应该给予更多权重，原因是对 ML 算法来说，绝对收益率小的样本不好预测，作为训练样本价值不大。</p><blockquote><p>The “neutral” case is unnecessary, as it can be implied by a “−1” or “1” prediction with low confidence.</p></blockquote></li><li><p>市场是常为新的，越新的数据与当前市场相关度越高，价值越大。</p><blockquote><p>Markets are adaptive systems (Lo [2017]). As markets evolve, older examples are less relevant than the newer ones.</p></blockquote></li><li><p>最后，我们还应该考虑类别权重。金融中不均衡数据集很常见，而且这些罕见的标签往往非常重要。在 sklearn 等科学计算包中可以设置为 class_weight='balanced' 。</p></li><li><p>label表示 买/卖 信号, 两个label 如果是基于相同时间段的收益率 计算出来的，就说是 concurrent的.</p></li><li><p>对样本使用bootstrap方法抽样，以期得到iid样本。</p></li><li><p>基于uniqueness和absolute return对样本赋予权重。绝对收益高的的labels应该被给予更高的权重；收益取值越unique的也要给予更高的权重</p></li><li><p>市场是演化着的，所以我们希望给新忘本更多的权重，给老样本更少的权重。</p></li><li><p>怎么量化这个事件衰减效应？设计一个时间衰减因子（所有元素加起来为1），用这个因子乘以样本权重，</p></li><li><p>使用机器学习做分类时，有的稀有事件（比如金融危机）出现次数很少，为了保证ml算法能重视这类事件，可以调整sample_weight</p></li><li><p>具体来说，在scikit learn中，设置class_weight='balanced'，或者在bagging trees中设置class_weight='balanced_subsample'，小心<a href="https://github.com/scikit-learn/scikit-learn/issues/4324">bug</a></p></li></ol><h2 id="chapter-5-分数差分">chapter 5 分数差分</h2><p>分数差分--Fractionally Differentiated Features</p><p>如何兼顾平稳性（adf）和 记忆性（跟price的相关性）？--分数差分</p><h3 id="stationarity-vs.-memory的两难问题">STATIONARITY VS. MEMORY的两难问题</h3><ol type="1"><li>金融序列大部分非平稳，且有很低信噪比，标准的平稳变换，例如差分变换，会丢失信息。</li><li>价格序列有记忆，但是差分后的序列没有记忆了。</li><li>接下来理论家们会从剩下的残差信号中使用各种fancy的工具去提取信息。</li><li>金融序列不平稳的原因是，它有很长的记忆.所以要使用传统的方法的话要做invariant processes，例如看价格的收益率或者取对数差，波动性变化</li><li>在信号处理中，我们是不希望所有的记忆都被抹除的，因为记忆是信号模型的basis。例如，均衡平稳模型需要一些记忆，来获取截止目前为止，结果偏离长期预测值多远，来预测。矛盾在于，收益是平稳的，但是没有记忆。价格有记忆，但是不是平稳的。 那么问题就来了：最小的差分阶数是什么？既能满足一个价格序列平稳，又能保留尽可能多的信息？</li><li>协整（cointergration）方法可以使用记忆来建模。</li><li>平稳性只是ml算法的必要不充分条件，但是通过差分变换的方法虽然获得了平稳性却丢失了记忆性，会导致ml基本上没有什么记忆能力。</li></ol><p>下面会介绍一些转换方法，在保留记忆的同时，又能实现平稳变换。</p><h3 id="分数差分方法">分数差分方法</h3><ol type="1"><li>如何解决平稳和记忆两难的问题？Hosking [1981]提出了分数差分的方法。 <img src="fd.png" alt="img.png" /></li><li>使用迭代法计算权重向量 <img src="fd1.png" alt="img.png" /> <img src="fd2.png" alt="img_1.png" /></li><li>在SP500上面做实验，当差分d=0.35时，跟原始价格序列的相关性仍然很高, 0.995，d=1时候，相关性只有0.03, 基本上丢失了记忆。从adf上看，d=0.35时, 序列的黏稠度也不高，adf约等于 –2.8623， 原始的adf是–0.3387,d=1对应的adf是–46.9114。</li><li>Expanding Window 和 固定宽度窗口分数差分方法(Fixed-Width Window Fracdiff)</li></ol><h2 id="参考">参考</h2><ol type="1"><li>《Advances in Financial Machine Learning》</li><li>https://blog.csdn.net/weixin_38753422/article/details/100179559</li><li>https://zhuanlan.zhihu.com/p/69231390</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;chapter-2-金融数据结构&quot;&gt;chapter 2 金融数据结构&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;金融数据经常分为4类，基本面数据，市场交易数据，分析数据，另类数据（Alternative） &lt;img src=&quot;image.png&quot; alt</summary>
      
    
    
    
    <category term="AFML" scheme="https://chiechie.github.io/categories/AFML/"/>
    
    
    <category term="量化" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>《Advances in Financial Machine Learning》读书笔记0 为什么金融领域的机器学习项目经常失败？</title>
    <link href="https://chiechie.github.io/2021/07/05/AFML/AFML0/"/>
    <id>https://chiechie.github.io/2021/07/05/AFML/AFML0/</id>
    <published>2021-07-05T01:49:02.000Z</published>
    <updated>2021-07-08T02:55:20.196Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概览">概览</h1><ol type="1"><li><p>市场上关于投资的书籍大致分为两类：一类是理论家写的，自己都没有实践过；一类是实践家写的，他们误用了数学工具。</p></li><li><p>金融市场上现在鱼龙混扎，小散受到到不良媒体的诱导会冲动投资，造成市场动荡。量化工具可以减少这种套利机会，肃清这种风气。</p></li><li><p>常见的陷阱： <img src="img1.png" alt="img.png" /></p><figure><img src="img.png" alt="img.png" /><figcaption aria-hidden="true">img.png</figcaption></figure></li><li><p>是否意味着有了ai就没有human投资者的空间了？不是，可以人+ai</p></li></ol><h1 id="pitfall-1-西西弗斯模式">Pitfall 1: 西西弗斯模式</h1><blockquote><p>Pitfall 1: 西西弗斯模式（THE SISYPHUS PARADIGM）</p><p>Solution 1: 元策略模式（THE META-STRATEGY PARADIGM）</p></blockquote><ol type="1"><li>自由基金经理（Discretionary portfolio managers～DPM）的投资理念比较玄学，不会遵循特定的理论，这样的一群人开会时往往漫无目的、各执一词。DPMs天然地不能组成一个队伍：让50个DPM一起工作，他们的观点会相互影响，结果是老板发了50份工资，只得到一个idea。他们也不是不能成功，关键是要让他们为同一个目标工作，但尽量别交流。</li><li>很多公司采用DPM模式做量化/ML 项目：让50个PhD分别去研究策略，结果要么得到严重过拟合的结果，要么得到烂大街&amp;低夏普率的多因子模型。即使有个别PhD研究出有效的策略，这种模式的投入产出比也极低。这便是所谓让每个员工日复一日搬石头上山的西西弗斯模式。</li><li>量化是一项系统工程，包括数据、高性能计算设备、软件开发、特征研究、模拟交易系统……如果交给一个人做，无异于让一个工人造整辆车——这周他是焊接工，下周他是电工，下下周他是油漆工，尝试---&gt;失败---&gt;尝试---&gt;失败，循环往复。</li><li>好的做法是将项目清晰地分成子任务，分别设定衡量质量的标准，每个quant在保持全局观的同时专注一个子任务，项目才能得以稳步推进。这是所谓元策略模式（THE META-STRATEGY PARADIGM）。</li></ol><h1 id="pitfall-2-根据回测结果做研究">Pitfall 2: 根据回测结果做研究</h1><blockquote><p>Pitfall 2: 根据回测结果做研究（RESEARCH THROUGH BACKTESTING）</p><p>Solution 2: 特征重要性分析（FEATURE IMPORTANCE ANALYSIS）</p></blockquote><ol type="1"><li>金融研究中很普遍的错误是在特定数据上尝试ML模型，不断调参直到得到一个比较好看的回测结果——这显然是过拟合,学术期刊往往充斥面向测试集调参。</li><li>考虑一个ML任务，我们可以构建一个分类器，在交叉检验集上评估其泛化误差。假定结果很好，一个自然的问题是：哪些特征对结果的贡献最大？“好的猎人不会对猎狗捕获的猎物照单全收”，回答了这个问题，我们可以增加对提高分类器预测力的特征，减少噪声特征。</li><li>需关注ml发现的跟特征相关的模式：什么特征最重要、这些特征的重要性会随时间改变么、这种改变能否被识别和预测。</li><li>总之，特征驱动的分析比回测结果驱动的分析更重要。</li></ol><h1 id="pitfall-3-按时间采样">Pitfall 3: 按时间采样</h1><blockquote><p>Pitfall 3: 按时间采样（CHRONOLOGICAL SAMPLING）</p><p>Solution 3: 交易量钟（THE VOLUME CLOCK）</p></blockquote><ol type="1"><li>Bars：表格数据的一行或者说一个样本，叫一个bar。</li><li>Time Bars:以固定的时间区间对数据进行取样（如每分钟一次）后得到的数据。</li><li>Time bars使用广泛，但是有两个不足：第一，市场交易信息的数量在时间上的分布并不是均匀的。开盘后的一小时内交易通常会比午休前的一小时活跃许多。因此，使用Time bars 会导致交易活跃的时间区间的欠采样，以及交易冷清的时间区间的过采样。第二，根据时间采样的序列通常呈现出较差的统计特征，包括序列相关、异方差等。</li><li>Tick bars 是指每隔固定的（如1000次）交易次数提取上述的变量信息。一些研究发现这一取样方法得到的数据更接近独立正态同分布 [Ane and Geman 2000]。 使用Tick Bars 还需注意异常值 (outliers) 的处理。一些交易所会在开盘和收盘时进行集中竞价，在竞价结束后以统一价格进行撮合。</li><li>Volume Bars &amp; Dollar Bars：Volume Bars 是指每隔固定的成交量提取上述的变量信息。Dollar Bars 则使用了成交额。 使用 Dollar Bars更有优势的。假设一只股票在一定时间区间内股价翻倍，期初10000元可以购买的股票将会是期末10000元可购买股票手数的两倍。在股价有巨大波动的情况下，Tick Bars以及Volume Bars每天的数量都会随之有较大的波动。除此之外，增发、配股、回购等事件也会导致Tick Bars以及Volume Bars每天数量的波动</li></ol><h1 id="pitfall-4-整数差分">Pitfall 4: 整数差分</h1><blockquote><p>Pitfall 4: 整数差分（INTEGER DIFFERENTIATION）</p><p>Solution #4: 非整数差分（FRACTIONAL DIFFERENTIATION）</p></blockquote><p>我们需要在数据平稳性和保留数据信息之间做取舍，非整数/分数差分就是一个较好的解决方案</p><h1 id="pitfall-5-固定时间范围标签">Pitfall 5: 固定时间范围标签</h1><blockquote><p>Pitfall 5: 固定时间范围标签（FIXED-TIME HORIZON LABELING）</p><p>Solution 5: 三边界方法（THE TRIPLE-BARRIER METHOD）</p></blockquote><ol type="1"><li>固定时间范围标签方法应用广泛, 但是有若干不足：time bars 的统计性质不好;常数阈值不顾波动性是不明智的;可能被强制平仓.</li><li>三边界方法（THE TRIPLE-BARRIER METHOD）考虑到平仓的触发条件，是更好的处理方式，其包括上下水平边界和右边的垂直边界。水平边界需要综合考虑盈利和止损，其边界宽度是价格波动性的函数（波动大边界宽，波动小边界窄）；垂直边界考虑到建仓后 bar 的流量，如果不采用 time bars，垂直边界的宽度就不是固定的（翻译太艰难了，附上原文）</li><li>如果未来价格走势先触及上边界，可以取1；先触及下边界，则取-2；先触及右边界，可以 0，或者根据盈利正负，取1或者-1 。</li></ol><h1 id="pitfall-6-同时学出方向和规模">Pitfall 6: 同时学出方向和规模</h1><blockquote><p>Pitfall 6: 同时学出方向和规模（LEARNING SIDE AND SIZE SIMULTANEOUSLY）</p><p>Solution #6: 元标签（META-LABELING）</p></blockquote><ol type="1"><li>金融中用ML的另一常见错误是同时学习仓位的方向和规模。</li><li>具体而言，方向决策（买/卖）是最基本的决策，规模决策（size decision）是风险管理决策，即我们的风险承受能力有多大，以及对于方向决策有多大信心。</li><li>我们没必要用一个模型处理两种决策，更好的做法是分别构建两个模型：第一个模型来做方向决策，第二个模型来预测第一个模型预测的准确度。</li><li>很多ML模型表现出高精确度（precision）和低召回率（recall）。这意味着这些模型过于保守，大量交易机会被错过。</li><li>F1-score 综合考虑了精确度和召回率，是更好的衡量指标，元标签（META-LABELING）有助于构建高 F1-score 模型。首先（用专家知识）构建一个高召回率的基础模型。随后构建一个ML模型，用于决定我们是否应该执行基础模型给出的决策。</li><li>元标签+ML有以下4个优势：<ol type="1"><li>元标签+ML则是在白箱（基础模型）的基础上构建的，具有更好的可解释性；</li><li>元标签+ML减少了过拟合的可能性，即ML模型仅对交易规模决策不对交易方向决策，避免一个ML模型对全部决策进行控制；</li><li>元标签+ML的处理方式允许更复杂的策略架构，例如：当基础模型判断应该多头，用ML模型来决定多头规模；当基础模型判断应该空头，用另一个ML模型来决定空头规模；</li><li>赢小输大会得不偿失，所以单独构建ML模型对规模决策是有必要的。</li></ol></li></ol><blockquote><p>achieving high accuracy on small bets and low accuracy on large bets will ruin you</p></blockquote><h1 id="pitfall-7-非iid样本加权">Pitfall 7: 非IID样本加权</h1><blockquote><p>Solution #7: （UNIQUENESS WEIGHTING AND SEQUENTIAL BOOTSTRAPPING）</p></blockquote><p>样本不是iid的，比如按照volumn bars，到达1000的成交量才采集一个样本。</p><p>如果实际数据中，交易发生拥堵，都集中在了t=10，那么： - t=1要到t=10才达到1000， - t=2其实也是到t=10达到1000， - t=3其实也是到t=10达到1000，</p><p>因此，t=10这个样本就被用了很多次（最多9次），当然time bars是没有这个问题的。</p><p>为了缓解这个样本重复出现的问题，作者定义了一个衰减因子即<span class="math inline">\(1/c_t\)</span>, <span class="math inline">\(c_t\)</span>表示t时刻的行情被用了多少次，所以t时刻的行情对应的return应该除以这个次数。</p><p>这些只对那种按成交量或者其他非等时间划分样本的方法有意义 (1) labels are decided by outcomes; (2) outcomes are decided over multiple observations; (3) because labels overlap in time, we cannot be certain about what observed features caused an effect.</p><h1 id="pitfall-8-交叉检验集泄露信息cross-validation-leakage">Pitfall 8: 交叉检验集泄露信息（CROSS-VALIDATION LEAKAGE）</h1><blockquote><p>Pitfall 8: 交叉检验集泄露信息（CROSS-VALIDATION LEAKAGE）</p><p>Solution #8: 清理和禁止（PURGING AND EMBARGOING）</p></blockquote><ol type="1"><li>金融中需要警惕在训练集 / CV 集中引入未来信息。</li><li>好的做法应该是在训练集和CV集之间设定一个间隔</li></ol><h1 id="pitfall-9-前向回测">Pitfall 9: 前向回测</h1><blockquote><p>Pitfall 9: 前向回测（WALK-FORWARD / HISTORICAL BACKTESTING）</p><p>Solution #9: CPCV（COMBINATORIAL PURGED CROSS-VALIDATION）</p></blockquote><ol type="1"><li>常用的回测方法是前向回测（Walk-forward Backtesting）：根据当前时刻以前的数据做决策。这种方式容易解读同时也很直观，但存在几点不足：<ol type="1"><li>前向回测只测试了单个场景，容易过拟合；</li><li>前向回测的结果未必能代表未来的表现。 2.作者提出了一种切分方法：将所有数据分为 N 份（注意避免信息泄露），从中任意取 k份作为测试集，剩下作为训练集，总共有很多种取法。这种方法最大的优势是允许我们得到某策略在不同时期的夏普率分布，而不是计算一个夏普率值。</li></ol></li></ol><h1 id="pitfall-10-回测过拟合">Pitfall 10: 回测过拟合</h1><blockquote><p>Pitfall 10: 回测过拟合（BACKTEST OVERFITTING）</p><p>Solution 10: 保守夏普率（THE DEFLATED SHARPE RATIO）</p></blockquote><ol type="1"><li>假设 <span class="math inline">\({y_i}\)</span> 独立同分布，可证明<span class="math inline">\(E\left[\max \left\{y_{i}\right\}_{i=1, \ldots, I}\right] \leq \sigma \cdot \sqrt{2 \log (I)}\)</span>。</li><li>若<span class="math inline">\(y_i\)</span> 代表一系列回测结果的夏普率，则只要回测次数足够多，或者每次回测结果方差足够大，从中都能选出任意高的结果，尽管有可能 <span class="math inline">\(E(y_i)=0\)</span> 。</li><li>这提醒我们要考虑到回测次数过多会造成过拟合，一种解决方案是保守夏普率（THE DEFLATED SHARPE RATIO，DSR），其思想是给定一系列对夏普率SR的估计值，通过统计检验的方法估计能否推翻零假设 SR=0 。</li></ol><h2 id="参考">参考</h2><ol type="1"><li>《Advances in Financial Machine Learning》</li><li>https://blog.csdn.net/weixin_38753422/article/details/100179559</li><li>https://zhuanlan.zhihu.com/p/69231390</li><li>https://zhuanlan.zhihu.com/p/29208399</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;概览&quot;&gt;概览&lt;/h1&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;市场上关于投资的书籍大致分为两类：一类是理论家写的，自己都没有实践过；一类是实践家写的，他们误用了数学工具。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;金融市场上现在鱼龙混扎，小散受到到不良媒体的诱导会冲动投</summary>
      
    
    
    
    <category term="AFML" scheme="https://chiechie.github.io/categories/AFML/"/>
    
    
    <category term="量化" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>投资、投机与套利</title>
    <link href="https://chiechie.github.io/2021/07/04/reading_notes/investment/quant/"/>
    <id>https://chiechie.github.io/2021/07/04/reading_notes/investment/quant/</id>
    <published>2021-07-04T07:10:19.000Z</published>
    <updated>2021-07-09T00:29:06.181Z</updated>
    
    <content type="html"><![CDATA[<ol type="1"><li>巴菲特希望通过分析公司基本面来做精准判断，通过每次投资的长期持有获得收益，而西蒙斯用机器算法来发现短期胜率，通过短期胜率超过50%加上大数定律（law of large numbers）来保证长时间的盈利</li><li>人在做投资决策的时候都会根据自己的经历和知识储备选取合适的策略。</li><li>从交易的方式来看，投资的策略有三种形式：投资（investment）、投机（speculation）和套利（arbitrage），三种形式都可以用量化的方法来提高胜率。</li><li>1949年，格雷厄姆在《聪明的投资者》里写到：“投资者与投机者最实际的区别在于他们对股市运动的态度上：投机者的兴趣主要在参与市场波动并从中谋取利润，投资者的兴趣主要在以适当的价格取得和持有适当的股票。”</li><li>所谓价值投资其实是“价值和价格之差”投资，然后低买高卖。他说投资的秘诀是“不要赔钱”。</li><li>在金融市场里，如果看不清30年这么长的时间线，分析交易量、交易价格和其它技术和基本面的数据，对股票未来短期内的变化，可以在日或周这样的时间线上找到机会。这样的投机行为并不关心股票未来的成长，但是只要在短期内做到足够好的判断，则可以成功地投机获利。</li><li>如果把时间线再缩短，就会有套利的机会。套利背后的逻辑是低买高卖</li><li>很多高频交易的策略，在市场的大量卖单和买单中找到规律，用一个较低的价格买回股票，然后找到下一个买家用高一点的价格卖出去。</li><li>从投资到投机再到套利，随着交易速度的提升，超额收益会越来越高，但是这样的速度提升也有缺点，那就是随着交易速度的提升，机会的窗口就比较小，盈利的容量会越来越小。如果把股市比作赌场，随着交易速度的提升，赢钱的概率会提高，但是能赢的钱的总量却是在下降的。</li><li>高频的量化投资有点像从沙子里捞金子，每捞一次在付出成本的同时都有一个概率找到金子，捞金子的收益可以从两方面得到，一是捞金子的成功率，这个可以通过优化算法加强预测准确率来得到；二是交易频率，可以通过增加单位时间的交易次数来达到。总收益大致和正确率与交易次数平方根的乘积是成正比的。这个原理叫主动管理基本定律The Fundamental Law of Active Management。</li><li>机器学习做交易策略的一个误区。大家一上来就在想办法预测股价，这个思路是最直接的，从数据分析的层面看，这并没有错，很多对算法很熟悉的人都非常厉害，可以迅速的找到一些算法（例如xgboost）来做非常好的样本内预测。但是一旦在实际股市中使用的时候就会发现预测准确度远远不如历史数据所做出来的。</li><li>问题不是机器学习的算法不够好，而是所有的预测模型都假设底层的市场逻辑没有变化，这样的假设是错误的，导致了过度拟合</li><li>如今的市场上，找一个会用厉害的算法做预测的码农并不难，难的是管理者和投资决策者需要知道如何从最底层理解金融市场的量化思维并发挥出算法的优势。</li></ol><h2 id="参考">参考</h2><ol type="1"><li>https://zhuanlan.zhihu.com/p/362383721</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;巴菲特希望通过分析公司基本面来做精准判断，通过每次投资的长期持有获得收益，而西蒙斯用机器算法来发现短期胜率，通过短期胜率超过50%加上大数定律（law of large numbers）来保证长时间的盈利&lt;/li&gt;
&lt;li&gt;人在做投资决策的时候</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="量化" scheme="https://chiechie.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
    <category term="投资" scheme="https://chiechie.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>《巫师唐望》读书笔记</title>
    <link href="https://chiechie.github.io/2021/07/03/reading_notes/zhexue/wushitangwang/"/>
    <id>https://chiechie.github.io/2021/07/03/reading_notes/zhexue/wushitangwang/</id>
    <published>2021-07-03T07:30:45.000Z</published>
    <updated>2021-07-15T05:57:29.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="停顿世界">停顿世界</h2><blockquote><p>stopping the world。</p><p>丢掉自我重要感 和 抹掉个人历史</p></blockquote><ol type="1"><li>抹掉一切个人历史，免得我们受别人思想的牵绊。</li><li>"他们一旦知道你，你就被视为理所当然的，从那一刻开始，你就没有办法打破他们思想的束缚。我个人很喜欢那种（抹掉个人历史带来的）不为人知的终极自由。没有人能确切地了解我，像人们了解你一样"。</li><li>“如果一个人没有个人历史，不论他说什么，都不会被当成谎言，而你的麻烦是你一定得向每个人说明每一件事，同时又希望保持行为的新鲜感。可是在说明所做的一切之后，你没法再兴奋，为了能好好活下去，你只好撒谎。</li><li>“从现在开始，你必须只让人知道你愿意让人知道的，但是不必说明你是怎样做到的。”</li><li>我们只有两条路；或者把一切都当成确定的、真实的：或者不这么做。如果走第一条路，最后会对自己以及世界感到厌倦至死。如果走第二条路，抹去个人历史，我们就在自己周围制造出一层雾，那是一种让人刺激而且神秘的状态，没有人知道兔子会从哪里冒出来，甚至连自己也不知道。</li><li>在没有一样事情是确定时，我们会一直保持警觉，会永远小心翼翼，不知道兔子藏在哪丛灌木后面，要远比假装知道一切来得刺激。</li><li>“你把自己看得太重了，”他慢条斯理地说，“在你心里，你把你自己看得太该死的重要。一定要改！你是如此该死的重要，使你觉得可以理直气壮地对每件事恼火。你是如此该死的重要，所以事情只要不如你的意，你可以掉头就走。你大概以为那样表示你有个性。胡扯！你是又软弱，又自命不凡！”.他指出，因为我加在身上这种夸大的重要感，使我这辈子一事无成。</li><li>“自我重要感是另一件必须丢弃的东西，就像个人历史。”</li><li>我喜欢他这种如谜般的谈话，神秘而带挑战性。不过，我无法判断这些是深奥难懂还是一派胡言。</li><li>我们现在所关心的是丢掉自我重要感。只要你还是感觉你是世界上最重要的事物，就不能真正欣赏周围的世界，就好像一匹戴着眼罩的马只能看到一个远离一切事物的自己</li><li>死亡是我们永恒的伴侣，”唐望以最严肃的语气说，“它永远在我们的左边，一臂之遥。在你监视白鹰时，它也在监视你，它在你耳边低语，于是你感觉到了它的寒意，就像今天一样。死亡永远在监视你，直到有一天它轻轻碰触你。</li><li>“你这个男孩，偷偷地潜行追踪猎物，也知道耐心等待，就像死亡的等待。你非常清楚死亡就在我们的左边，就像你在白鹰的左边那样。”</li><li>“如果我们知道死亡正在潜猎我们，又怎能感觉自己如此重要呢？”他问。</li><li>“当你不耐烦时，”他继续说，“你应该转向左边，向死亡寻求忠告。如果死亡对你打个手势，或你瞥见了它，或者你只要感觉它在那儿守望你，你就可以抛弃许多令人心烦的琐事。”</li><li>死亡是我们仅有的明智忠告者。当你觉得一切都不顺利，一切就要完蛋的时候，转身问问死亡事实是否如此。你的死亡会告诉你，你错了；除了它的触摸之外，一切都无关紧要。它会告诉你：‘我还没有碰你呢！’</li><li>不知为什么，他的笑声不再像过去那样无礼而令人讨厌。我不认为笑的声调、大小、笑意和过去有什么不同，不同的是我的心情。从死亡随时会降临的观点看，我的恐惧与恼火都失去了意义。</li><li>猎人知道他会一次又一次地把猎物引进陷阱里，因此他不忧虑。他忧虑的话，就会被得到，不知不觉地被得到。一旦你开始忧虑，你就会因为绝望而抓住任何东西；一旦你抓住东西不放，就会为之耗尽你的力量，或耗尽你所抓住的人或东西。</li><li>把你的注意力集中在你和死亡的联系上，没有反悔、悲伤或忧虑。集中心思去想，你已经没有时间了，然后让你的行动自然发生，让你的一举一动都成为你在世上的最后一战。只有在这种情况下，你的行动才有正当的力量。否则，你穷尽一生所为，也不过是个胆怯的人而已</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://weread.qq.com/web/reader/7c332a60717d350b7c30d04">唐王三部曲-微信读书</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;停顿世界&quot;&gt;停顿世界&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;stopping the world。&lt;/p&gt;
&lt;p&gt;丢掉自我重要感 和 抹掉个人历史&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;抹掉一切个人历史，免得我们受别人思想的牵</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="哲学" scheme="https://chiechie.github.io/tags/%E5%93%B2%E5%AD%A6/"/>
    
    <category term="自我中心主义" scheme="https://chiechie.github.io/tags/%E8%87%AA%E6%88%91%E4%B8%AD%E5%BF%83%E4%B8%BB%E4%B9%89/"/>
    
  </entry>
  
  <entry>
    <title>图的最大流和最小割算法</title>
    <link href="https://chiechie.github.io/2021/07/02/data_structure/ds3-1_graph-basic/min-cut/"/>
    <id>https://chiechie.github.io/2021/07/02/data_structure/ds3-1_graph-basic/min-cut/</id>
    <published>2021-07-02T00:48:14.000Z</published>
    <updated>2021-07-03T06:16:12.561Z</updated>
    
    <content type="html"><![CDATA[<h2 id="最大流">最大流</h2><h3 id="最大流问题">最大流问题</h3><p>在一个网络中，求从起点、source到目标点，经过的最大的流量，每条边的权重等于该管道的最大流量，求整个路径的最大流量。</p><p><img src="img_3.png" /></p><p>残差 = 容量 - 真实流量 <img src="img_4.png" /></p><h3 id="最大流算法">最大流算法</h3><p>最简单的方法，但是未必能找到最大流</p><figure><img src="img_5.png" alt="img_5.png" /><figcaption aria-hidden="true">img_5.png</figcaption></figure><p>通过多次迭代，先找可达路径，计算残差图，移走空闲量=0的边，进入第二次循环。</p><h2 id="最小割">最小割</h2><h3 id="最小割问题">最小割问题</h3><p>最小割要解决的问题和最大流是一样的</p><p>输入：方向有权图 目标：割的容量最小 输出：某个S-T cut，</p><blockquote><p>最大流最小割定理（Max-Flow Min-Cut Theorem）</p><p>在一个网络流量中，从s到t的最大流量等于，最小s-t cut的容量。</p><p>--L. R. Ford and D. R. Fulkerson. Flows in Networks. Princeton University Press, (1962 .)</p></blockquote><p><img src="img_1.png" /></p><h3 id="寻找最小割的方法">寻找最小割的方法</h3><ol type="1"><li>使用最大流算法获得residual graph， 移走其中反向的边</li><li>在residual graph中，从起点s出发，找到所有能达到的节点，并记为集合S，把其他所有节点记做T（s到不了的节点）。</li><li>将{S, T}记做最小割。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.youtube.com/watch?v=6DFWUgV5Osc&amp;t=774s">图的最大流和</a></li><li><a href="https://www.youtube.com/watch?v=Ev_lFSIzNh4&amp;t=128s">图的最小割算法-youtube</a></li><li><a href="https://github.com/wangshusen/AdvancedAlgorithms">图的最小割算法-slide</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;最大流&quot;&gt;最大流&lt;/h2&gt;
&lt;h3 id=&quot;最大流问题&quot;&gt;最大流问题&lt;/h3&gt;
&lt;p&gt;在一个网络中，求从起点、source到目标点，经过的最大的流量，每条边的权重等于该管道的最大流量，求整个路径的最大流量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;img_3.png&quot; </summary>
      
    
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="数据结构" scheme="https://chiechie.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    <category term="图算法" scheme="https://chiechie.github.io/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/"/>
    
    <category term="图" scheme="https://chiechie.github.io/tags/%E5%9B%BE/"/>
    
    <category term="最小割" scheme="https://chiechie.github.io/tags/%E6%9C%80%E5%B0%8F%E5%89%B2/"/>
    
  </entry>
  
  <entry>
    <title>基于Ray的融合计算框架</title>
    <link href="https://chiechie.github.io/2021/06/30/reading_notes/computer/fenbushi/"/>
    <id>https://chiechie.github.io/2021/06/30/reading_notes/computer/fenbushi/</id>
    <published>2021-06-30T06:39:39.000Z</published>
    <updated>2021-07-01T11:56:15.297Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>看到阿里在2021发表的一个演讲--《新一代的计算基础设施-对于Ray的融合计算》，做一些笔记</p></blockquote><ol type="1"><li>举一个复杂的业务的例子，用户支付流程：</li></ol><ul><li>先选择支付场景--线上/线下/，</li><li>选择支付方式--</li><li>选择交易网络--银联/第三方</li><li>选择银行</li></ul><figure><img src="./img_1.png" alt="img_1.png" /><figcaption aria-hidden="true">img_1.png</figcaption></figure><p>整个流程需要秒级响应。</p><ol start="2" type="1"><li>要是大家都开始用统一的计算平台，AIOps也可以用同一套方案了</li></ol><figure><img src="./img_2.png" alt="img_2.png" /><figcaption aria-hidden="true">img_2.png</figcaption></figure><ol start="3" type="1"><li>业务需求之一是，复杂的业务逻辑计算存在单机性能瓶颈，需要支持分布式无范式的分布式开发。</li><li>现在的基础设计在单一用途的组件上，已经做的比较成熟了，专门做流式计算的计算引擎有flink，专门做深度学习的计算引擎有tensorflow，专门做批处理的有spark。</li><li>但是，考虑到一个复杂的应用场景，完成1个任务需要用到多种计算模式，统一计算平台 能够让这几种计算模式实现状态共享，中间结果共享。在这种场景下，统一计算平台，相较于多个独立的计算组件 效率更高。</li><li>要不要搞统一计算平台，取决于需求的复杂性，如果是一个很pure很纯粹的任务，搞这个的意义就不大。但是可以作为预研嘛，万一以后业务变得越来越复杂，也有准备。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://www.bilibili.com/video/BV1gh411Y7qf?t=1">Ray Forward Meetup 2021-面向金融决策场景的在线计算系统-bilibili</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;看到阿里在2021发表的一个演讲--《新一代的计算基础设施-对于Ray的融合计算》，做一些笔记&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;举一个复杂的业务的例子，用户支付流程：&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="读书笔记" scheme="https://chiechie.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    <category term="计算机原理" scheme="https://chiechie.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%9F%E7%90%86/"/>
    
    <category term="分布式计算" scheme="https://chiechie.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"/>
    
    <category term="大数据" scheme="https://chiechie.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>零知识量证明</title>
    <link href="https://chiechie.github.io/2021/06/29/reading_notes/qukuailian/zkp/"/>
    <id>https://chiechie.github.io/2021/06/29/reading_notes/qukuailian/zkp/</id>
    <published>2021-06-29T15:54:57.000Z</published>
    <updated>2021-07-05T03:28:18.664Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基本概念">基本概念</h2><ol type="1"><li><p>零知识证明(ZKP)的定义为：证明者（prover）能够在不向验证者（verifier）提供任何有用的信息的情况下，使验证者（verifier）相信某个论断是正确的。</p></li><li><p>零知识证明具有三个重要的性质：</p><ul><li>完备性（Completeness）：只要证明者拥有相应的知识，那么就能通过验证者的验证，即证明者有足够大的概率使验证者确信。---验证者的问题是可解的。</li><li>可靠性（Soundness）：如果证明者没有相应的知识，则无法通过验证者的验证，即证明者欺骗验证者的概率可以忽略。---验证者的问题是有难度的。</li><li>零知识性（Zero-Knowledge）：证明者在交互过程中仅向验证者透露是否拥有相应知识的陈述，不会泄露任何关于知识的额外信息。---验证者是无不要知道解答过程的，它只在另外一个问题空间验证。</li></ul></li><li><p>零知识证明是一种基于概率的验证方式，验证者（verifier）向证明者（prover)提出多个随机问题，如果证明者都能给出正确回答，则说明证明者大概率拥有他所声称的“知识”。零知识证明并不是数学意义上的证明，因为它存在小概率的误差，欺骗的证明者有可能通过虚假的陈诉骗过验证者，但是，可通过技术手段将误差降低到可以忽略的值。</p></li></ol><h2 id="应用场景">应用场景</h2><p>零知识证明在区块链上的两大应用场景：隐私和扩容。</p><p>隐私：在隐私场景中，我们可以借助零知识证明的“不泄露信息”特性，在不泄漏交易的细节（接收方，发送方，交易余额）的情况下证明区块链上的资产转移是有效的。</p><p>扩容：在扩容场景中，我们不太需要关注零知识证明技术的“不泄露信息”这个特性，我们的关注重点是它的“证明论断有效”这个特性，由于链上资源是有限的，所以我们需要把大量的计算迁移到链下进行，因此需要有一种技术能够证明这些在链下发生的动作是可信的，零知识证明正好可以帮助我们做链下可信计算的背书。</p><p>目前，使用零知识证明技术的应用有隐私币(例如zcash)，以太坊上的混币合约，链下扩容技术zkRollup。</p><h3 id="隐私">隐私</h3><h4 id="为什么需要隐私币">为什么需要隐私币？</h4><ol type="1"><li><p>举个生活中的例子：游客向庙里功德箱中仍香火钱，所有的游客仍的都是同一个年份的一元硬币，这时有一个第三方在一旁观察，他可以知道谁在什么时间扔进去多少个硬币。但是当小沙弥从功德箱中取钱的时候，他无法分别取出的硬币是由谁扔进去的。这里功德箱就起到一个混币的功能.同理，为了保证区块链上交易的隐私性，也可以进行混币。</p></li><li><p>混币的目的是切断加密货币交易中发送方与接受方的联系，发送方利用混币系统将自己的钱与其他人的钱进行混合，接受方(Verifier)利用零知识证明来证明有某一个混币的所有权，从而进行转账交易。</p></li><li><p>需要隐私币的第一个理由：隐私币能实现匿名且不可追踪。</p><ul><li>目前公链（比特币）的匿名只起到假名的作用，例如现实生活中的人可以生成任意多的公私钥对，用这些公钥在链上发送或接受每笔交易，这些公钥就充当他们的假名。如果外界不知道你和公钥的关系，他们就无法把你和你的交易历史关联起来，只要有人能把你跟公钥联系起来，就可以顺藤摸瓜找到你过去的交易历史。目前不没有办法阻止第三方将我们和我们的公钥联系起来。</li></ul></li><li><p>需要隐私币的第二个理由：由于隐私币无法查看货币的交易记录，所以减少了货币不可互换的问题。</p><ul><li>流通性使货币具有了内在可互换性,但是加密货币具有极度透明性，我们可以追踪到与某一特定货币的所有相关历史交易，这样一来，人们一旦发现某个货币是“污点”货币（俗称“黑钱”）就可以拒绝接受这种货币。如果这种情况大规模发生，加密货币将不再是可互换的因为“干净”的货币比“污点”货币具有更大价值。</li><li>不可互换的货币会给用户带来额外的负担，用户为了避免不小心买入“污点”货币，那么用户就会被迫检查他们购买的每笔货币的交易历史。</li></ul></li><li><p>下图是使用零知识证明的一般过程，在circuit中会执行一些约束，这些约束是与要解决的问题是相关的。Private input的值只有Prover自己知道,Public input的值是Prover与Verifier共享的。该过程可以总结为，Prover在不揭露Private input 的情况下向Verifier证明自己知道一个值能满足（x+3=5)。</p><figure><img src="./img.png" alt="基于circuit的零知识证明" /><figcaption aria-hidden="true">基于circuit的零知识证明</figcaption></figure></li></ol><h4 id="zk-snark的流程图">zk-SNARK的流程图</h4><p>下图是zk-SNARK的流程图，zk-SNARK不能直接用于解决计算问题，必须先把问题转换成正确的“形式”（即"quadratic arithmetic problem"，QAP)，在转换为QAP的同时，可以用Private input和Public input创建一个对应的解，称为QAP的witness。只有Prover用这个witness来生成proof。</p><figure><img src="./img_1.png" alt="zk-Snark流程图" /><figcaption aria-hidden="true">zk-Snark流程图</figcaption></figure><p>整个过程如下：</p><ul><li>首先得有一个计算问题，这个问题一般是NP问题</li><li>然后将计算问题做一个等价转换变成QAP，步骤如下：<ul><li>将计算问题拍平（flatten）变成circuit</li><li>把circuit转化成 R1CS(rank-1 constraint system，一阶约束系统)。R1CS 是一个由三向量组 (a,b,c) 组成的序列，R1CS 有个解向量s（就是witness），s 必须满足符号表示向量的内积运算 a.s * b.s - c.s = 0</li><li>将R1CS转化成QAP形式，这两者的区别是QAP使用多项式来代替点积运算，他们所实现的逻辑完全相同。</li></ul></li><li>trusted setup会生成两个值PK，VK，truseted setup的目的是实现零交互验证，它生成的PK，VK相当于是一个“上帝”,由它来帮我们验证Prover。</li><li>Prover用PK生成一个Proof交给Verifier</li><li>Verifier拿到这个Proof会用VK做校验，这一步发生在链上，由链上的节点或智能合约来做校验。 &gt; PK就像一个query word，VK是该query word对应的answer，CRS相当于是一个生成了一个&lt;question，answer&gt;，拿Prover的答案跟正确的已知的答案进行对比，从而验证Prover是qualified</li></ul><h3 id="扩容">扩容</h3><ol type="1"><li>17年出现了一款非常火爆的Dapp应用叫加密猫，加密猫曾造成以太坊主网大规模的拥堵，造成拥堵的原因是以太坊当时的TPS只有15，这意味着以太坊每秒只能处理15笔交易，如此低的TPS严重限制了区块链应用的大规模落地，所以有人开始研究区块链扩容的问题，目的就是为了提高链上的TPS。</li><li>但区块链扩容受到Vitalik提出的不可能三角的限制(区块链系统设计无法兼顾可扩展性，去中心化和安全性).但我们必须知道，一切事物都有自己的边界，公链不应该做所有的事情，公链应该做它该做的事情：“公链是以最高效率达成共识的工具，能够以最低成本来构建信任”。</li><li>作为共识的工具，信任的引擎，公链不应该为了可扩展性放弃去中心化与安全性。那么公链的TPS这么低，该怎么使用呢？可以将大量的工作放到链下去解决，仅仅将最重要的数据提交到区块链主链上，让所有节点都能够验证这些链下的工作都是准确可靠的.</li><li>社会的发展带来的是更精细化的分工，区块链的技术发展也是如此，在底层区块链（Layer1）上构建一个扩展层（Layer2)，Layer1来保证安全和去中心化，绝对可靠、可信；它能做到全球共识，并作为“加密法院”，通过智能合约设计的规则进行仲裁，以经济激励的形式将信任传递到Layer2上，而Layer2追求极致的性能，它只能做到局部共识，但是能够满足各类商业场景的需求。</li></ol><h2 id="发展历史">发展历史</h2><ol type="1"><li>1985 年，零知识证明Zero-Knowledge Proof - 由 S.Goldwasser、 S.Micali 及 C.Rackoff 首次提出。</li><li>2010年，Groth实现了首个基于椭圆曲线双线性映射全能的，常数大小的非交互式零知识证明协议。后来这个协议经过不断优化，最终成为区块链著名的零知识证明协议SNARKs。</li><li>2013年，Pinocchio协议实现了分钟级别证明，毫秒级别验证，证明大小不到300字节，将零知识证明从理论带到了应用。后来Zcash使用的SNARKs正是基于Pinocchio的改进版。</li><li>2014 年，名为Zerocash的加密货币则使用了一种特殊的零知识证明工具zk-SNARKs （ Zero-Knowledge Succinct Non-interactive Arguments of Knowledge ) 实现了对交易金额、交易双方的完全隐藏，更注重于隐私，以及对交易透明的可控性。</li><li>2017 年， Zerocash 团队提出将 zk-SNARKs 与智能合约相互结合的方案，使交易能在众目睽睽下隐身，打造保护隐私的智能合约。</li></ol><h2 id="参考">参考</h2><ol type="1"><li><a href="https://zhuanlan.zhihu.com/p/152065162">零知识证明介绍-zhihu</a></li><li><a href="https://www.notboring.co/p/zero-knowledge">Zero Knowledge, from not boring</a></li><li><a href="https://mp.weixin.qq.com/s/_IrI8SJLo1Ht51nJfI4V_Q">十分钟开发一个混币-原理篇</a></li><li><a href="https://mp.weixin.qq.com/s/8OkwqNXIkUz2PBURoghRJQ">十分钟开发零知识证明之混币</a></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;基本概念&quot;&gt;基本概念&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;零知识证明(ZKP)的定义为：证明者（prover）能够在不向验证者（verifier）提供任何有用的信息的情况下，使验证者（verifier）相信某个论断是正确的。&lt;/p&gt;&lt;/li&gt;
&lt;l</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="加密货币" scheme="https://chiechie.github.io/tags/%E5%8A%A0%E5%AF%86%E8%B4%A7%E5%B8%81/"/>
    
    <category term="零知识量证明" scheme="https://chiechie.github.io/tags/%E9%9B%B6%E7%9F%A5%E8%AF%86%E9%87%8F%E8%AF%81%E6%98%8E/"/>
    
  </entry>
  
  <entry>
    <title>几个思维模型</title>
    <link href="https://chiechie.github.io/2021/06/28/reading_notes/reality/10-mental-model/"/>
    <id>https://chiechie.github.io/2021/06/28/reading_notes/reality/10-mental-model/</id>
    <published>2021-06-28T04:50:00.000Z</published>
    <updated>2021-06-28T05:47:15.061Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>基于剃刀原则的几个思维模型，from Sahil Bloom的twitter</p></blockquote><h2 id="the-steve-jobs-quality-razor">The Steve Jobs Quality Razor</h2><p>When building, take pride in carrying the quality all the way through.Would you be proud for your work to be seen from every angle and perspective? If not, keep working.</p><h2 id="the-eli5-razor">The ELI5 Razor</h2><ul><li>Complexity and jargon are often used to mask a lack of true understanding.</li><li>If you can’t explain it to a 5-year-old, you don’t really understand it.</li><li>If someone uses a lot of complexity and jargon to explain something to you, they probably don’t understand it.</li></ul><h2 id="mungers-rule-of-opinions">Munger’s Rule of Opinions</h2><p>“I never allow myself to have an opinion on anything that I don’t know the other side’s argument better than they do.” - Charlie Munger</p><p>Opinions aren’t free. You have to work to earn the right to have them.</p><h2 id="the-bezos-regret-minimization-framework">The Bezos Regret Minimization Framework</h2><p>The goal is to minimize the number of regrets in life.</p><p>When faced with a difficult decision: (1) Project yourself into the future (2) Look back on the decision (3) Ask "Will I regret not doing this?" (4) Take action</p><h2 id="buffetts-rule-of-holes">Buffett’s Rule of Holes</h2><p>“The most important thing to do if you find yourself in a hole is to stop digging." - Warren Buffett</p><p>When things aren’t working, change course and try something different.</p><p>When you find yourself at the bottom of a hole, stop digging and climb out of it.</p><h2 id="pgs-crazy-idea-razor">PG's Crazy Idea Razor</h2><p>If someone proposes a crazy idea, ask:</p><ol type="1"><li>Are they a domain expert?</li><li>Do I know them to be reasonable?</li></ol><p>If yes on (1) and (2), you should take the idea seriously, as it may be an asymmetric bet on the future.</p><h2 id="the-boasters-razor">The Boaster’s Razor</h2><p>Truly successful people rarely feel the need to boast about their success.</p><p>If someone regularly boasts about their income, wealth, or success, it’s fair to assume the reality is a fraction of what they claim.</p><h2 id="the-circle-of-competence">The Circle of Competence</h2><p>Be ruthless in identifying your circle of competence (and its boundaries).</p><p>When faced with a big decision, ask yourself whether you are qualified to handle it given your circle.</p><p>If yes, proceed. If no, outsource it to someone who is.</p><h2 id="the-duck-test">The Duck Test</h2><p>If it looks like a duck, swims like a duck, and quacks like a duck, it’s probably a duck.</p><p>You can determine a lot about a person by regularly observing their habitual characteristics.</p><h2 id="buffetts-juicy-pitch">Buffett’s Juicy Pitch</h2><p>“You don't have to swing at everything - you can wait for your pitch." - Warren Buffett</p><p>Life doesn’t reward you for the number of swings you take.</p><p>Slow down and focus on identifying the juiciest pitch.</p><p>When it comes, swing hard and don’t miss it.</p><h2 id="occams-razor">Occam’s Razor</h2><p>The simplest explanation is often the best one.</p><p>Simple assumptions &gt; complex assumptions.</p><p>Simple is beautiful.</p><h2 id="the-buffett-reputation-razor">The Buffett Reputation Razor</h2><p>“It takes 20 years to build a reputation and five minutes to ruin it. If you think about that, you'll do things differently.” - Warren Buffett</p><p>Remember that quote and act accordingly.</p><p>Your character is your fate.</p><h2 id="hanlons-razor">Hanlon’s Razor</h2><p>Never attribute to malice that which can be adequately explained by stupidity.</p><p>In assessing someone's actions, we should not assume negative intent if there is a viable alternative explanation, such as different beliefs, incompetence, or ignorance.</p><p>汉隆的剃刀</p><p>永远不要把可以用愚蠢充分解释的事情归咎于恶意。</p><p>在评估某人的行为时，如果有可行的替代解释，例如不同的信念、无能或无知，我们不应假设消极意图。</p><h2 id="nntalebs-the-look-the-part-razor">nntaleb's The “Look the Part” Razor</h2><p>If forced to choose between two options of seemingly equal merit, choose the one that doesn’t look the part.</p><p>The one who doesn’t look the part has had to overcome much more to achieve its status than the one who fit in perfectly.</p><p>如果被迫在看似同等价值的两个选项之间做出选择，请选择一个看起来不合适的选项。</p><p>与完美契合的人相比，看起来不合群的人必须克服更多才能获得地位。</p><h2 id="newtons-flaming-laser-sword">Newton’s Flaming Laser Sword</h2><p>If something cannot be settled by experiment or observation, it is not worth debating.</p><p>This will save you from wasting a lot of time on pointless arguments.</p><p>牛顿的火焰激光剑</p><p>如果一些事情不能通过实验或观察来解决，那就不值得争论了。</p><p>这将使您免于在无意义的争论上浪费大量时间。</p><h2 id="machiavellis-razor">Machiavelli’s Razor</h2><p>Never attribute to malice that which can be adequately explained by self-interest.</p><p>In assessing someone's actions, we should not assume negative intent if there is a viable alternative explanation that they are acting on rooted self-interest.</p><p>马基雅维利的剃刀</p><p>永远不要将可以用自身利益充分解释的事情归咎于恶意。</p><p>在评估某人的行为时，如果有一个可行的替代解释表明他们是根据根深蒂固的自身利益行事，我们不应该假设消极意图。</p><h2 id="hitchens-razor">Hitchens’ Razor</h2><p>What can be asserted without evidence can also be dismissed without evidence.</p><p>The burden of proof regarding a claim lies with the one who makes the claim. If unmet, no argument is required to dismiss it.</p><h2 id="sagans-standard">Sagan’s Standard</h2><p>“Extraordinary claims require extraordinary evidence.”</p><p>The more crazy and outrageous the claim, the more crazy and outrageous the body of evidence must be in order to prove it.</p><p>萨根的标准</p><p>“非凡的主张需要非凡的证据。”</p><p>声称越疯狂和越离谱，为了证明它，证据主体就必须越疯狂和离谱。</p><h2 id="the-eisenhower-decision-matrix">The Eisenhower Decision Matrix</h2><p>When faced with a task, ask: “Is this urgent? Is this important?”</p><p>An "urgent" task is one that requires immediate attention. An "important" task is one that promotes or furthers your long-term goals.</p><p>Place it on a 2x2 matrix and act accordingly.</p><h2 id="the-steve-jobs-settling-razor">The Steve Jobs Settling Razor</h2><p>“The only way to do great work is to love what you do. If you haven’t found it yet, keep looking. Don’t settle.” - Steve Jobs</p><p>It’s Monday morning. Did you wake up with energy or with dread?</p><p>Your answer will tell you if you’re settling.</p><h2 id="the-career-razor">The Career Razor</h2><p>When deciding on a new job, choose the one that will challenge you the most (intellectually, physically, or emotionally).</p><p>Challenge and discomfort forces growth.</p><p>(P.S. Check out the job board below for challenging new roles!)</p><h2 id="decisions">Decisions</h2><p>• If you can’t decide, the answer is no.</p><p>• If two equally difficult paths, choose the one more painful in the short term (pain avoidance is creating an illusion of equality).</p><p>• Choose the path that leaves you more equanimous in the long term."</p><h2 id="参考">参考</h2><ol type="1"><li>https://pallet.xyz/list/thebloomboard/jobs</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;基于剃刀原则的几个思维模型，from Sahil Bloom的twitter&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;the-steve-jobs-quality-razor&quot;&gt;The Steve Jobs Quality Razor&lt;</summary>
      
    
    
    
    <category term="阅读" scheme="https://chiechie.github.io/categories/%E9%98%85%E8%AF%BB/"/>
    
    
    <category term="决策" scheme="https://chiechie.github.io/tags/%E5%86%B3%E7%AD%96/"/>
    
  </entry>
  
</feed>
