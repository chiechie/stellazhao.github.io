<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"chiechie.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.7.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"æœç´¢...","empty":"æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœç´¢ç»“æœï¼š${query}","hits_time":"æ‰¾åˆ° ${hits} ä¸ªæœç´¢ç»“æœï¼ˆç”¨æ—¶ ${time} æ¯«ç§’ï¼‰","hits":"æ‰¾åˆ° ${hits} ä¸ªæœç´¢ç»“æœ"}}</script><script src="/js/config.js"></script>
<meta name="description" content="Transformeræ€»ç»“  Transformeræ˜¯google2016å¹´åœ¨ã€Šattention is all you needã€‹æå‡ºçš„ä¸€ä¸ªæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„seq2seqæ¶æ„ã€‚ Transformerçš„äº®ç‚¹åœ¨äºå°†attentionå’Œself-attentionå®Œå…¨å‰¥ç¦»å¼€ä¹‹å‰rnnçš„ç»“æ„ï¼Œåªè·Ÿdenseå±‚ç»„åˆã€‚ Transformerè·ŸRNNæ²¡æœ‰å…³ç³», åªæœ‰attentionå’Œå…¨è¿æ¥å±‚">
<meta property="og:type" content="article">
<meta property="og:title" content="è‡ªç„¶è¯­è¨€å¤„ç†6 Transformer">
<meta property="og:url" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/index.html">
<meta property="og:site_name" content="Chiechie&#39;s Mini World">
<meta property="og:description" content="Transformeræ€»ç»“  Transformeræ˜¯google2016å¹´åœ¨ã€Šattention is all you needã€‹æå‡ºçš„ä¸€ä¸ªæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„seq2seqæ¶æ„ã€‚ Transformerçš„äº®ç‚¹åœ¨äºå°†attentionå’Œself-attentionå®Œå…¨å‰¥ç¦»å¼€ä¹‹å‰rnnçš„ç»“æ„ï¼Œåªè·Ÿdenseå±‚ç»„åˆã€‚ Transformerè·ŸRNNæ²¡æœ‰å…³ç³», åªæœ‰attentionå’Œå…¨è¿æ¥å±‚">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_embeddings.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_encoder_with_tensors.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_positional_encoding_vectors.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_positional_encoding_example.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_6.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_7.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_attention_heads_qkv.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_attention_heads_z.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_2.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_3.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_self-attention-matrix-calculation.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_self-attention-matrix-calculation-2.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_attention_heads_weight_matrix_o.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_multi-headed_self-attention-recap.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_9.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_10.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_resideual_layer_norm.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_resideual_layer_norm_2.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_resideual_layer_norm_3.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_11.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_17.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_18.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_1.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_5.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_8.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_13.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_decoding_1.gif">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_decoding_2.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_12.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/Transformer_decoder.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_decoder_output_softmax.gif">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_14.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_15.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_encoders_decoders.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_encoder_decoder_stack.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/output_target_probability_distributions.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_output_trained_model_probability_distributions.png">
<meta property="og:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/img_20.png">
<meta property="article:published_time" content="2021-04-24T16:04:13.000Z">
<meta property="article:modified_time" content="2021-08-12T09:52:22.862Z">
<meta property="article:author" content="Chiechie">
<meta property="article:tag" content="attention">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="ç¥ç»ç½‘ç»œ">
<meta property="article:tag" content="æ¨¡å‹å¯è§†åŒ–">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="Bert">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/transformer_embeddings.png">


<link rel="canonical" href="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/","path":"2021/04/25/nlp/nlp_6-transformer/","title":"è‡ªç„¶è¯­è¨€å¤„ç†6 Transformer"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>è‡ªç„¶è¯­è¨€å¤„ç†6 Transformer | Chiechie's Mini World</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="Chiechie's Mini World" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ " role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Chiechie's Mini World</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">åœ¨æˆ‘ä»¬ç¦»å¼€çš„æ—¶å€™ï¼Œè¿™ä¸ªä¸–ç•Œè¿˜æ˜¯é‚£ä¹ˆæ„šè ¢å’Œé‚ªæ¶ï¼Œè·Ÿæˆ‘ä»¬åˆšçš„æ—¶å€™å¹¶æ— äºŒè‡´ã€‚---ä¼å°”æ³°</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»</a></li>
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>å…³äº</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#transformer%E6%80%BB%E7%BB%93"><span class="nav-number">1.</span> <span class="nav-text">Transformeræ€»ç»“</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-number">2.</span> <span class="nav-text">é™„å½•</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BE%93%E5%85%A5%E5%92%8C%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="nav-number">2.1.</span> <span class="nav-text">è¾“å…¥å’Œä½ç½®ç¼–ç </span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%A4%B4self-attention"><span class="nav-number">2.2.</span> <span class="nav-text">å¤šå¤´self attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dense%E5%B1%82"><span class="nav-number">2.3.</span> <span class="nav-text">denseå±‚</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#encoder-block-%E5%A4%9A%E5%A4%B4self-attention-dense-layer"><span class="nav-number">2.4.</span> <span class="nav-text">encoder block &#x3D; å¤šå¤´self-attention + dense layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5%E5%92%8Clayer-normalization"><span class="nav-number">2.5.</span> <span class="nav-text">æ®‹å·®è¿æ¥å’Œlayer-normalization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#encoder-network-6-encoder-block"><span class="nav-number">2.6.</span> <span class="nav-text">encoder network &#x3D; 6 * encoder block</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%A4%B4attention"><span class="nav-number">2.7.</span> <span class="nav-text">å¤šå¤´attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#decoder-block-%E5%A4%9A%E5%A4%B4self-attention-%E5%A4%9A%E5%A4%B4attention-dense-layer"><span class="nav-number">2.8.</span> <span class="nav-text">decoder block &#x3D; å¤šå¤´self-attention + å¤šå¤´attention + dense layer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#decoder-network-6-decoder-block"><span class="nav-number">2.9.</span> <span class="nav-text">decoder network &#x3D; 6 * decoder block</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#transformer-encoder-network-decoder-network"><span class="nav-number">2.10.</span> <span class="nav-text">Transformer &#x3D; encoder network+ decoder network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-number">2.11.</span> <span class="nav-text">è®­ç»ƒ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E7%9A%84%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="nav-number">2.12.</span> <span class="nav-text">åº”ç”¨çš„ä¸€ä¸ªä¾‹å­</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">3.</span> <span class="nav-text">å‚è€ƒ</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chiechie</p>
  <div class="site-description" itemprop="description">a reader & thinker</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">180</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">205</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>



          </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="è¿”å›é¡¶éƒ¨">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chiechie.github.io/2021/04/25/nlp/nlp_6-transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chiechie">
      <meta itemprop="description" content="a reader & thinker">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chiechie's Mini World">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          è‡ªç„¶è¯­è¨€å¤„ç†6 Transformer
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">å‘è¡¨äº</span>

      <time title="åˆ›å»ºæ—¶é—´ï¼š2021-04-25 00:04:13" itemprop="dateCreated datePublished" datetime="2021-04-25T00:04:13+08:00">2021-04-25</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">æ›´æ–°äº</span>
        <time title="ä¿®æ”¹æ—¶é—´ï¼š2021-08-12 17:52:22" itemprop="dateModified" datetime="2021-08-12T17:52:22+08:00">2021-08-12</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">åˆ†ç±»äº</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="transformeræ€»ç»“">Transformeræ€»ç»“</h1>
<ul>
<li>Transformeræ˜¯google2016å¹´åœ¨ã€Šattention is all you needã€‹æå‡ºçš„ä¸€ä¸ªæœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå…¸å‹çš„seq2seqæ¶æ„ã€‚</li>
<li>Transformerçš„äº®ç‚¹åœ¨äºå°†attentionå’Œself-attentionå®Œå…¨å‰¥ç¦»å¼€ä¹‹å‰rnnçš„ç»“æ„ï¼Œåªè·Ÿdenseå±‚ç»„åˆã€‚</li>
<li>Transformerè·ŸRNNæ²¡æœ‰å…³ç³», åªæœ‰attentionå’Œå…¨è¿æ¥å±‚</li>
<li>Transformeræ¯”æ‰€æœ‰çš„rnn+attentionæ•ˆæœéƒ½è¦å¥½ï¼Œæœºå™¨ç¿»è¯‘çš„ç‹è€…</li>
<li>Transformeræ˜¯ä¸€ä¸ªç¿»è¯‘æ¨¡å‹ï¼Œåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œegå¾·è¯‘è‹±ï¼Œè¾“å…¥ä¸€ä¸ªå¾·æ–‡å¥å­ï¼Œè¾“å‡ºåä¸€å¥è‹±æ–‡ã€‚</li>
<li>Transformerç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šencoderså’Œdecoders</li>
<li>encodersç”±6ä¸ªencoderå †å è€Œæˆï¼Œdecodersç”±6ä¸ªdecoderå †å è€Œæˆï¼Œä¸€ä¸ªencoderæˆ–ä¸€ä¸ªdecoderå«åšä¸€ä¸ªblockã€‚</li>
<li>encodersçš„æ¯ä¸ªblockæœ‰2å±‚ï¼šself-attentionå’Œdenseï¼Œæ¯ä¸ªblockç»“æ„ç›¸åŒï¼Œä½†ä¸å…±äº«æƒé‡ã€‚</li>
<li>decodersçš„æ¯ä¸ªblockæœ‰3å±‚ï¼šself-attentionï¼Œattentionå’Œdenseï¼Œå…¶ä¸­attentonç”¨æ¥å…³æ³¨encoderçš„è¾“å‡ºï¼Œ</li>
<li>attentionæŠ€æœ¯çš„æ¼”è¿›ï¼šattention + åŸºäºrnnçš„seq2seq --&gt; self-attention + lstm --&gt; attention/self attention + dense.</li>
<li>"å¤šå¤´"æ³¨æ„æœºåˆ¶æ‰©å±•äº†æ¨¡å‹å…³æ³¨ä¸åŒä½ç½®çš„èƒ½åŠ›, ç»™äºˆattentionå±‚å¤šä¸ª"è¡¨ç¤ºå­ç©ºé—´", æ¯ä¸ªå¤´æœ‰è‡ªå·±çš„ä¸€ç»„query / key / value æƒé‡çŸ©é˜µï¼Œå½“äºå®¡è§†å¤šæ¬¡ä¸Šä¸‹æ–‡ï¼Œ</li>
</ul>
<h1 id="é™„å½•">é™„å½•</h1>
<h2 id="è¾“å…¥å’Œä½ç½®ç¼–ç ">è¾“å…¥å’Œä½ç½®ç¼–ç </h2>
<ol type="1">
<li>å’Œä¸€èˆ¬çš„NLPä»»åŠ¡ä¸€æ ·ï¼Œç”¨embedding algorithmå°†æ¯ä¸ªè¾“å…¥å•è¯è½¬åŒ–ä¸ºè¯å‘é‡ä¹‹åï¼Œæ‰èƒ½ä½œä¸ºTransformerçš„è¾“å…¥ä½¿ç”¨ã€‚</li>
<li>å¦‚ä¸‹å›¾ï¼Œ3ä¸ªå•è¯è¢«embeddedä¸º3ä¸ª512ç»´çš„å‘é‡ <img src="./transformer_embeddings.png"></li>
<li>æ¥ä¸‹æ¥ï¼Œå°†è¿™3ä¸ª512ç»´çš„è¯å‘é‡ä¼ å…¥self-attentionå’Œdenseå±‚ <img src="./transformer_encoder_with_tensors.png"></li>
<li>ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰è¡¨ç¤ºåºåˆ—çš„é¡ºåº, ä¸ºäº†è®©æ¨¡å‹å­¦ä¹ åˆ°è¯çš„é¡ºåºå…³ç³»ï¼Œtransformerå‘æ¯ä¸ªè¾“å…¥embeddingå‘é‡ï¼ˆx1ï¼‰åˆåŠ ä¸Šä¸€ä¸ªä½ç½®ç¼–ç å‘é‡ï¼ˆt1ï¼‰ã€‚ <img src="./transformer_positional_encoding_vectors.png" alt="img"></li>
<li>å‡è®¾embeddingçš„ç»´åº¦æ˜¯4ï¼Œé‚£ä¹ˆå®é™…çš„ä½ç½®ç¼–ç çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„: <img src="./transformer_positional_encoding_example.png" alt="img"></li>
</ol>
<h2 id="å¤šå¤´self-attention">å¤šå¤´self attention</h2>
<ol type="1">
<li>æ¯ä¸ªå•å¤´self-attentionå±‚æœ‰ä¸‰ä¸ªå‚æ•°çŸ©é˜µï¼Œå•å¤´çš„context vectoræ˜¯ä¸€ä¸ªd * mç»´çš„çŸ©é˜µ <img src="./img_6.png" alt="å•å¤´self-attention"></li>
<li>å¤šå¤´attentionå±‚å°±æœ‰3<em>lä¸ªå‚æ•°çŸ©é˜µï¼ˆlä»£è¡¨å¤´çš„ä¸ªæ•°ï¼‰ï¼Œå¤šå¤´çš„context vectoræ˜¯ä¸€ä¸ª(dl) </em>mç»´çš„çŸ©é˜µ <img src="./img_7.png" alt="å¤šå¤´self-attention"> <img src="./transformer_attention_heads_qkv.png" alt="img"></li>
<li>ç±»ä¼¼ä¸Šé¢æåˆ°çš„å•å¤´self-attentionè®¡ç®—ï¼Œæˆ‘ä»¬ç°åœ¨åªæ˜¯ç”¨8ä¸ªä¸åŒçš„æƒé‡çŸ©é˜µç®—äº†8æ¬¡ï¼Œå¹¶ä¸”å¾—åˆ°äº†8ä¸ªä¸åŒçš„ z çŸ©é˜µ <img src="./transformer_attention_heads_z.png" alt="img"></li>
<li>å½“è§£è¯»ä¸€ä¸ªå¥å­ä¸­çš„ä¸€ä¸ªwordæ—¶ï¼Œ Transformeä¸­çš„encoderé€šè¿‡self-attentionæ¥å›é¡¾ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ‰¾å‡ºè¾“å…¥åºåˆ—ä¸­çš„é‡è¦çš„wordï¼Œä»è€Œæ›´å…³æ³¨é‡è¦ä¿¡æ¯ï¼Œå¹¶ä¸”ä¼šæŠŠé‡è¦wordçš„value vectorç¼–ç åˆ°è‡ªå·±çš„å‘é‡é‡Œé¢å»ã€‚ RNNé€šè¿‡hidden stateç­–ç•¥ï¼Œä½¿å¾—å®ƒå°†å½“å‰è¯ä¸ä¸Šä¸‹æ–‡ï¼ˆå‡†ç¡®æ¥è¯´åªæœ‰ä¸Šæ–‡ï¼‰çš„ä¿¡æ¯è¿›è¡Œèåˆã€‚</li>
<li>self-attentionçš„è¾“å…¥æ˜¯mä¸ªè¯å‘é‡ï¼Œè¾“å‡ºæ˜¯mä¸ªcontext vectorï¼Œvectorè¡¨ç¤ºèåˆäº†ä¸Šä¸‹æ–‡ä¹‹åï¼Œå¯¹wordå†æ¬¡ç¼–ç ã€‚ <img src="./img_2.png" alt="img_2.png"> <img src="./img_3.png" alt="img_3.png"></li>
<li>å¦‚ä½•å®ç°self-attention layerï¼Ÿå³å¦‚ä½•å®ç°è®¡ç®—context vectorï¼Ÿ</li>
</ol>
<ul>
<li>step1: å¯¹äºæ¯ä¸ªè¾“å…¥çš„wordçš„æ­¤å‘é‡åˆ†åˆ«è®¡ç®—3ä¸ªè¡¨ç¤ºå‘é‡ï¼š
<ul>
<li>Query vectorï¼š <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="1.749ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 773 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(479,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>, to match othersï¼›</li>
<li>Key vectorï¼š<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="1.918ex" height="1.927ex" role="img" focusable="false" viewBox="0 -694 848 851.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mi" transform="translate(554,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span>, to be matchedï¼›</li>
<li>Value vectorï¼š<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="1.837ex" height="1.359ex" role="img" focusable="false" viewBox="0 -443 812 600.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(518,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span> to be weighted averaged ã€‚</li>
<li>è¿™äº›å‘é‡æ˜¯é€šè¿‡å°†è¾“å…¥çš„è¯å‘é‡åšä¸‰æ¬¡çº¿æ€§å˜æ¢å¾—åˆ°çš„ï¼Œå½“ç„¶å¯¹åº”çš„ä¸‰ä¸ªçŸ©é˜µæ˜¯éœ€è¦å­¦ä¹ çš„ã€‚</li>
<li>è¯·æ³¨æ„ï¼Œå¾—åˆ°çš„æ–°å‘é‡çš„ç»´åº¦ï¼ˆ64ï¼‰æ¯”embeddingï¼ˆ512ï¼‰å°ã€‚è¿™ä¹ˆè®¾è®¡ä¸ºäº†ä¿è¯ï¼ŒåŠ å…¥å¤šå¤´self-attentionä¹‹åï¼Œencoderçš„è¾“å‡ºå’Œè¾“å…¥ç»´åº¦ï¼ˆ512ï¼‰è¿˜èƒ½ä¿æŒä¸€è‡´ã€‚ &gt; 8å¤´ * 64 = 512</li>
</ul></li>
<li>step2: è®¡ç®—æƒé‡åˆ†æ•°, ç›®çš„æ˜¯é‡åŒ–å…¶ä»–å•è¯åº”è¯¥è¢«å…³æ³¨çš„ç¨‹åº¦ã€‚
<ul>
<li>è®¡ç®—å½“å‰å•è¯çš„query vectorå’Œå…¶ä»–å•è¯çš„key vectorçš„å†…ç§¯</li>
</ul></li>
<li>step3: æƒé‡åˆ†æ•°å½’ä¸€åŒ–ã€‚å°†ä¸Šä¸€æ­¥ç®—å‡ºæ¥çš„æƒé‡å¾—åˆ†å‘é‡ï¼ˆé•¿åº¦ä¸ºmï¼‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œç›®çš„æ˜¯è®©æƒé‡ä¸è¦å—åˆ°key vectorçš„é•¿åº¦ï¼ˆpaperé‡Œé¢æ˜¯64ï¼‰çš„å½±å“ï¼Œè¿™æ ·ç®—æ¢¯åº¦å°±æ›´ç¨³å®šã€‚</li>
<li>step4ï¼šå°†å½’ä¸€åŒ–çš„æƒé‡å¾—åˆ†å‘é‡ï¼ˆé•¿åº¦ä¸ºmï¼‰é€å…¥softmaxï¼Œç›®çš„æ˜¯å¾—åˆ°ä¸€ä¸ªæ¦‚ç‡å‘é‡ï¼Œæ‰€æœ‰æ•°å€¼åŠ èµ·æ¥ä¸º1ã€‚ç¤ºæ¯ä¸ªå•è¯åº”è¯¥è¢«å½“å‰å•è¯å…³æ³¨çš„ç¨‹åº¦ï¼Œå€¼è¶Šå¤§è¶Šåº”è¯¥è¢«å…³æ³¨ã€‚ã€‚</li>
<li>step5ï¼šè®¡ç®—contect vectorã€‚å°†æ¯ä¸ªå•è¯çš„value vectorä½¿ç”¨æƒé‡æ¦‚ç‡å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œä½œä¸ºå½“å‰å•è¯çš„self-attentionè¡¨è¾¾ï¼ˆè¾“å‡ºé•¿åº¦ä¸º64 * 8ä¸ªå¤´ = 512ï¼‰ã€‚</li>
</ul>
<ol start="6" type="1">
<li>æŠŠåˆšåˆšçš„è¿‡ç¨‹å†åŠ å…¥ä¸€ä¸ªç»´åº¦ï¼Œä¹Ÿå°±æ˜¯ä»ä¸€ä¸ªå•è¯ å˜æˆ å¤šä¸ªå•è¯ï¼Œè®¡ç®—ä»–ä»¬å„è‡ªçš„self-attentionè¡¨ç¤ºï¼Œç”¨çŸ©é˜µè¡¨è¾¾è¯¥è®¡ç®—æµç¨‹ï¼š</li>
</ol>
<ul>
<li>ç¬¬ä¸€æ­¥æ˜¯è®¡ç®— Queryã€ Key å’Œ Value çŸ©é˜µï¼š
<ul>
<li>æˆ‘ä»¬å°†embeddingså¡åˆ°ä¸€ä¸ªçŸ©é˜µxï¼šè¡Œæ•°è¡¨ç¤ºå•è¯ä¸ªæ•°ï¼Œåˆ—è¡¨ç¤ºembeddingçš„é•¿åº¦</li>
<li>æƒé‡çŸ©é˜µ(WQã€ WKã€ WVï¼‰ï¼šè¡Œä»£è¡¨embeddingå‘é‡çš„é•¿åº¦ï¼Œåˆ—åˆ†åˆ«ä»£è¡¨queryç©ºé—´ï¼Œkeyç©ºé—´ï¼Œvalueç©ºé—´çš„ç»´åº¦</li>
<li>Xåˆ†åˆ«å’Œè¿™å‡ ä¸ªçŸ©é˜µç›¸ä¹˜ <img src="./transformer_self-attention-matrix-calculation.png"></li>
</ul></li>
<li>ç¬¬äºŒæ­¥ï¼Œåˆ©ç”¨ç¬¬ä¸€æ­¥çš„ç»“æœæ¥è®¡ç®—attentionçš„è¾“å‡ºï¼Œç”¨ä¸€ä¸ªçŸ©é˜µè®¡ç®—æ¥è¡¨è¾¾ï¼Œç®€æ´ä¼˜é›… <img src="./transformer_self-attention-matrix-calculation-2.png"></li>
</ul>
<h2 id="denseå±‚">denseå±‚</h2>
<ol type="1">
<li>åé¢æ€ä¹ˆè·Ÿdenseå±‚è¿›è¡Œè¡”æ¥å‘¢ï¼Ÿ1. å°†è¿™8ä¸ªzçŸ©é˜µè¿›è¡Œåˆ—æ‹¼æ¥ï¼ˆconcatï¼‰ï¼›2. æ‹¼æ¥åçš„çŸ©é˜µå¤§å°ä¸ºm<em>(8</em>64) = m *512ï¼Œä¸¢å…¥denseå±‚ <img src="./transformer_attention_heads_weight_matrix_o.png" alt="img"></li>
<li>è¿™å°±æ˜¯multi-headed self-attentionçš„å¤§éƒ¨åˆ†å†…å®¹ã€‚æŠŠæ•´ä¸ªè¿‡ç¨‹æ”¾åœ¨ä¸€ä¸ªå›¾ä¸­æè¿°ï¼š <img src="./transformer_multi-headed_self-attention-recap.png" alt="img"></li>
</ol>
<h2 id="encoder-block-å¤šå¤´self-attention-dense-layer">encoder block = å¤šå¤´self-attention + dense layer</h2>
<ol type="1">
<li>encoder block â‰ˆ å¤šå¤´self-attention + denseã€‚encoder blockçš„è¾“å…¥ç»´åº¦æ˜¯512Ã—ğ‘šï¼Œè¾“å‡ºç»´åº¦æ˜¯512Ã—ğ‘š.</li>
<li>ä»¥ä¸€ä¸ªçŸ­å¥ä¸ºä¾‹,çœ‹çœ‹encoderçš„å¤„ç†æµç¨‹:
<ol type="1">
<li>å°†[x1ï¼Œ...,xm]è¾“å…¥å¤šå¤´self-attentionå±‚, å¾—åˆ°mä¸ªcontext vector</li>
<li>å°†mä¸ªcontext vectorè¾“å…¥dense + reluï¼Œå¾—åˆ°mä¸ªé‡æ–°ç¼–ç åçš„å‘é‡[u1,...,um]ï¼Œdenseå±‚å¯¹mä¸ªwordç”Ÿæ•ˆã€‚</li>
<li>å°†[u1,...,um]ä¼ é€’ç»™ä¸‹ä¸€ä¸ªç¼–ç å™¨encoder2ä½œä¸ºè¾“å…¥ã€‚ <img src="./img_9.png" alt="img_9.png"> <img src="./img_10.png" alt="img_10.png"></li>
</ol></li>
</ol>
<h2 id="æ®‹å·®è¿æ¥å’Œlayer-normalization">æ®‹å·®è¿æ¥å’Œlayer-normalization</h2>
<ol type="1">
<li>æ¯ä¸ªencoder blockä¸­ï¼Œself-attentionå’Œdenseéƒ½æœ‰ä¸€ä¸ªæ®‹å·®è¿æ¥ï¼Œç„¶åæ¥ä¸€ä¸ªå±‚æ ‡å‡†åŒ–ï¼ˆlayer-normalizationï¼‰ã€‚ <img src="./transformer_resideual_layer_norm.png" alt="img"></li>
<li>å¦‚æœæˆ‘ä»¬å°†æ®‹å·®è¿æ¥å’Œlayer normalizationç”¨çŸ©é˜µè¡¨ç¤ºï¼Œå°±æ˜¯ä¸‹å›¾ï¼š <img src="./transformer_resideual_layer_norm_2.png" alt="img"></li>
<li>decoderçš„sub-layers ä¹ŸåŒæ ·ç”¨åˆ°äº†add &amp; normalizationçš„è®¾è®¡ã€‚ ä¸‹å›¾æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆçš„Transformeræ¶æ„ï¼šç”±2ä¸ªstacked encoderå’Œ2ä¸ªstacked decoderç»„æˆã€‚ <img src="./transformer_resideual_layer_norm_3.png" alt="img"></li>
<li>æ›´å‡†ç¡®æ¥è¯´ encoder block = positional codeing + å¤šå¤´self-attention + add &amp; normalizatioin + dense layer + add &amp; normalizatioin</li>
</ol>
<h2 id="encoder-network-6-encoder-block">encoder network = 6 * encoder block</h2>
<p>encoder network is a stack of 6 encoder blocks.</p>
<figure>
<img src="./img_11.png" alt="img_11.png"><figcaption aria-hidden="true">img_11.png</figcaption>
</figure>
<h2 id="å¤šå¤´attention">å¤šå¤´attention</h2>
<ol type="1">
<li>å•å¤´attentionå±‚ï¼Œè¦è®¡ç®—3ä¸ªå‘é‡ï¼Œå…ˆè®¡ç®—qè·Ÿæ¯ä¸ªkçš„ç›¸å…³æ€§ï¼ˆæ±‚å†…ç§¯ï¼‰ï¼Œç„¶ååšsoftmaxå˜æ¢å¾—åˆ°æƒé‡å¾—åˆ†ï¼Œå¯¹æ‰€æœ‰çš„vä½¿ç”¨è¯¥æƒé‡æ±‚å’Œï¼Œå¾—åˆ°decoderçš„è¿™ä¸ªè¯ç›¸å¯¹encoderçš„è¡¨ç¤ºï¼Œä¹Ÿå°±æ˜¯context vectorã€‚ <img src="./img.png" alt="å•å¤´atttion"></li>
<li>decoderä¸­çš„attentionï¼Œqæ¥è‡ªä¸¤éƒ¨åˆ†ï¼šä¸‹é¢çš„decoderçš„è¾“å‡ºå’Œæœ€ä¸Šé¢encoderä¸­çš„KeysçŸ©é˜µå’ŒValuesçŸ©é˜µ ã€‚ <img src="img_17.png" alt="img_17.png"> <img src="img_18.png" alt="img_18.png"></li>
<li>Attention å±‚çš„Queries</li>
</ol>
<p><img src="./img_1.png" alt="img_1.png"> <img src="./img_5.png" alt="img_5.png"><br>
<img src="./img_8.png" alt="img_8.png"></p>
<h2 id="decoder-block-å¤šå¤´self-attention-å¤šå¤´attention-dense-layer">decoder block = å¤šå¤´self-attention + å¤šå¤´attention + dense layer</h2>
<p><img src="./img_13.png" alt="img_13.png"> 1. 1ä¸ªdecoder block â‰ˆ å¤šå¤´self-attention + å¤šå¤´attention + denseã€‚decoder blockçš„è¾“å…¥æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯encoderçš„è¾“å‡ºï¼ˆ512Ã—mï¼‰ï¼Œ ä¸€ä¸ªæ¥è‡ªdecoderå½“å‰çš„çš„è¾“å‡ºï¼ˆ512Ã—t ï¼‰. 2. encodingé˜¶æ®µï¼ˆphaseï¼‰å®Œæˆåï¼Œæˆ‘ä»¬å¼€å§‹decodingé˜¶æ®µï¼Œdecodingçš„æ¯ä¸ªstepæè¿°å¦‚ä¸‹ï¼š <img src="./transformer_decoding_1.gif" alt="img"> <img src="./transformer_decoding_2.png" alt="img"> 1. æ¯ä¸ªæ—¶åˆ»ï¼Œè¾“å…¥ç¬¬6ä¸ªencoderäº§ç”Ÿçš„mä¸ªkeys vectorså’Œvalue vectorsï¼Œè¾“å‡ºä¸€ä¸ªelementçš„æ¦‚ç‡åˆ†å¸ƒpdfã€‚ 2. ä»pdfä¸­æŠ½æ ·å‡ºwordï¼ˆæˆ–è€…ç›´æ¥é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„wordï¼‰ï¼Œä½œä¸ºdecoderçš„è¾“å…¥ã€‚ 3. é‡å¤step1ï¼Œç›´åˆ°äº§ç”Ÿç»“æŸç¬¦ã€‚ 3. decoderä¹Ÿä¼šç”¨åˆ°ä½ç½®ç¼–ç . 4. decoderä¸­çš„self attention layers:ä¸encoderçš„è¿ä½œæ–¹å¼ç•¥æœ‰ä¸åŒ,åœ¨decoderä¸­ï¼Œself-attention layeråªèƒ½æ¥è§¦åˆ°è¾“å‡ºåºåˆ—ä¸­çš„å‰åŠéƒ¨åˆ†ã€‚æ€ä¹ˆåšåˆ°å‘¢ï¼Ÿåœ¨softmaxæ“ä½œä¹‹å‰ï¼Œmaskingåºåˆ—ååŠéƒ¨åˆ†(è®¾ä¸º -inf)</p>
<h2 id="decoder-network-6-decoder-block">decoder network = 6 * decoder block</h2>
<ol type="1">
<li><p>Decoder network is a stack of 6 decoder blocks.</p>
<p><img src="./img_12.png"> <img src="./Transformer_decoder.png"></p></li>
<li><p>stack decodersè¾“å‡ºä¸€ä¸ªæ•°å€¼å‘é‡ã€‚ æˆ‘ä»¬æ€ä¹ˆæŠŠå®ƒå˜æˆä¸€ä¸ªè¯å‘¢ï¼Ÿ è¿™æ˜¯æœ€åçš„denseå±‚+softmaxåœ¨åšçš„äº‹æƒ…ã€‚å®ƒå°†stack of decodersçš„è¾“å‡ºæ˜ å°„ä¸ºä¸€ä¸ªæƒé‡å‘é‡ã€‚ï¼ˆé•¿åº¦å°±æ˜¯è¾“å‡ºè¯æ±‡è¡¨çš„å¤§å°ï¼‰</p></li>
<li><p>è¿™ä¸ªå›¾ä»åº•éƒ¨å¼€å§‹ï¼Œç”Ÿæˆä¸€ä¸ªvectorä½œä¸ºdecoder stackçš„è¾“å‡ºã€‚ ç„¶åå®ƒè¢«è½¬æ¢æˆä¸€ä¸ªè¾“å‡ºå•è¯ã€‚ <img src="./transformer_decoder_output_softmax.gif" alt="img"></p></li>
</ol>
<h2 id="transformer-encoder-network-decoder-network">Transformer = encoder network+ decoder network</h2>
<p><img src="./img_14.png" alt="img_14.png"> <img src="./img_15.png" alt="img_15.png"> <img src="./transformer_encoders_decoders.png" alt="Transformer=encoders+decoders"> <img src="./transformer_encoder_decoder_stack.png"></p>
<h2 id="è®­ç»ƒ">è®­ç»ƒ</h2>
<p>å­¦ä¹ çš„ç›®æ ‡ï¼Ÿ å°†æ¨¡å‹è¾“å‡ºä¸ç›®æ ‡è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œç„¶åä½¿ç”¨åå‘ä¼ æ’­æ–¹æ³•è°ƒæ•´æ¨¡å‹çš„æƒé‡ï¼Œä½¿æ¨¡å‹è¾“å‡ºæ›´æ¥è¿‘ç›®æ ‡è¾“å‡ºã€‚</p>
<p>å¦‚ä½•æ¯”è¾ƒä¸¤ç§æ¦‚ç‡åˆ†å¸ƒï¼Ÿ å¯æŸ¥çœ‹ <a target="_blank" rel="noopener" href="https://colah.github.io/posts/2015-09-Visual-Information/">cross-entropy</a>å’Œ <a target="_blank" rel="noopener" href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained">Kullback-Leibler</a>. ã€‚</p>
<p>ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒï¼š</p>
<figure>
<img src="./output_target_probability_distributions.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>æ¨¡å‹è¾“å‡ºï¼š</p>
<figure>
<img src="./transformer_output_trained_model_probability_distributions.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="åº”ç”¨çš„ä¸€ä¸ªä¾‹å­">åº”ç”¨çš„ä¸€ä¸ªä¾‹å­</h2>
<figure>
<img src="img_20.png" alt="img_20.png"><figcaption aria-hidden="true">img_20.png</figcaption>
</figure>
<h1 id="å‚è€ƒ">å‚è€ƒ</h1>
<ol type="1">
<li>Bahdanau, Cho, &amp; Bengio. Neural machine translation by jointly learning to align and translate. In ICLR, 2015.</li>
<li>Cheng, Dong, &amp; Lapata. Long Short-Term Memory-Networks for Machine Reading. In EMNLP, 2016.</li>
<li>Vaswani et al. Attention Is All You Need. In NIPS, 2017.</li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=aJRsr39F4dI">Transformeræ¨¡å‹(2/2): ä»Attentionå±‚åˆ°Transformerç½‘ç»œ</a></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/attention/" rel="tag"># attention</a>
              <a href="/tags/NLP/" rel="tag"># NLP</a>
              <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag"># ç¥ç»ç½‘ç»œ</a>
              <a href="/tags/%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96/" rel="tag"># æ¨¡å‹å¯è§†åŒ–</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
              <a href="/tags/Bert/" rel="tag"># Bert</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/04/24/nlp/nlp_5-word2vec/" rel="prev" title="è‡ªç„¶è¯­è¨€å¤„ç†5 Word2vec">
                  <i class="fa fa-chevron-left"></i> è‡ªç„¶è¯­è¨€å¤„ç†5 Word2vec
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2021/04/25/reading_notes/investment/pork-and-beef/" rel="next" title="ç‰›è‚‰æ˜¯ä¸æ˜¯æœªæ¥çš„è¶‹åŠ¿ä¹‹ä¸€ï¼Ÿ">
                  ç‰›è‚‰æ˜¯ä¸æ˜¯æœªæ¥çš„è¶‹åŠ¿ä¹‹ä¸€ï¼Ÿ <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chiechie</span>
</div>
  <div class="powered-by">ç”± <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> å¼ºåŠ›é©±åŠ¨
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  





</body>
</html>
